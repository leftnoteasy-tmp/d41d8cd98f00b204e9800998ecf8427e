/* Generated by the protocol buffer compiler.  DO NOT EDIT! */

/* Do not generate deprecated warnings for self */
#ifndef PROTOBUF_C_NO_DEPRECATED
#define PROTOBUF_C_NO_DEPRECATED
#endif

#include "yarn_protos.pb-c.h"
void   hadoop__yarn__serialized_exception_proto__init
                     (Hadoop__Yarn__SerializedExceptionProto         *message)
{
  static Hadoop__Yarn__SerializedExceptionProto init_value = HADOOP__YARN__SERIALIZED_EXCEPTION_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__serialized_exception_proto__get_packed_size
                     (const Hadoop__Yarn__SerializedExceptionProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__serialized_exception_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__serialized_exception_proto__pack
                     (const Hadoop__Yarn__SerializedExceptionProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__serialized_exception_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__serialized_exception_proto__pack_to_buffer
                     (const Hadoop__Yarn__SerializedExceptionProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__serialized_exception_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__SerializedExceptionProto *
       hadoop__yarn__serialized_exception_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__SerializedExceptionProto *)
     protobuf_c_message_unpack (&hadoop__yarn__serialized_exception_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__serialized_exception_proto__free_unpacked
                     (Hadoop__Yarn__SerializedExceptionProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__serialized_exception_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__application_id_proto__init
                     (Hadoop__Yarn__ApplicationIdProto         *message)
{
  static Hadoop__Yarn__ApplicationIdProto init_value = HADOOP__YARN__APPLICATION_ID_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__application_id_proto__get_packed_size
                     (const Hadoop__Yarn__ApplicationIdProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_id_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__application_id_proto__pack
                     (const Hadoop__Yarn__ApplicationIdProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_id_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__application_id_proto__pack_to_buffer
                     (const Hadoop__Yarn__ApplicationIdProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_id_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ApplicationIdProto *
       hadoop__yarn__application_id_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ApplicationIdProto *)
     protobuf_c_message_unpack (&hadoop__yarn__application_id_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__application_id_proto__free_unpacked
                     (Hadoop__Yarn__ApplicationIdProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_id_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__application_attempt_id_proto__init
                     (Hadoop__Yarn__ApplicationAttemptIdProto         *message)
{
  static Hadoop__Yarn__ApplicationAttemptIdProto init_value = HADOOP__YARN__APPLICATION_ATTEMPT_ID_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__application_attempt_id_proto__get_packed_size
                     (const Hadoop__Yarn__ApplicationAttemptIdProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_attempt_id_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__application_attempt_id_proto__pack
                     (const Hadoop__Yarn__ApplicationAttemptIdProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_attempt_id_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__application_attempt_id_proto__pack_to_buffer
                     (const Hadoop__Yarn__ApplicationAttemptIdProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_attempt_id_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ApplicationAttemptIdProto *
       hadoop__yarn__application_attempt_id_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ApplicationAttemptIdProto *)
     protobuf_c_message_unpack (&hadoop__yarn__application_attempt_id_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__application_attempt_id_proto__free_unpacked
                     (Hadoop__Yarn__ApplicationAttemptIdProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_attempt_id_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__container_id_proto__init
                     (Hadoop__Yarn__ContainerIdProto         *message)
{
  static Hadoop__Yarn__ContainerIdProto init_value = HADOOP__YARN__CONTAINER_ID_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__container_id_proto__get_packed_size
                     (const Hadoop__Yarn__ContainerIdProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_id_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__container_id_proto__pack
                     (const Hadoop__Yarn__ContainerIdProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_id_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__container_id_proto__pack_to_buffer
                     (const Hadoop__Yarn__ContainerIdProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_id_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ContainerIdProto *
       hadoop__yarn__container_id_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ContainerIdProto *)
     protobuf_c_message_unpack (&hadoop__yarn__container_id_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__container_id_proto__free_unpacked
                     (Hadoop__Yarn__ContainerIdProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_id_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__resource_proto__init
                     (Hadoop__Yarn__ResourceProto         *message)
{
  static Hadoop__Yarn__ResourceProto init_value = HADOOP__YARN__RESOURCE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__resource_proto__get_packed_size
                     (const Hadoop__Yarn__ResourceProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__resource_proto__pack
                     (const Hadoop__Yarn__ResourceProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__resource_proto__pack_to_buffer
                     (const Hadoop__Yarn__ResourceProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ResourceProto *
       hadoop__yarn__resource_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ResourceProto *)
     protobuf_c_message_unpack (&hadoop__yarn__resource_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__resource_proto__free_unpacked
                     (Hadoop__Yarn__ResourceProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__priority_proto__init
                     (Hadoop__Yarn__PriorityProto         *message)
{
  static Hadoop__Yarn__PriorityProto init_value = HADOOP__YARN__PRIORITY_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__priority_proto__get_packed_size
                     (const Hadoop__Yarn__PriorityProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__priority_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__priority_proto__pack
                     (const Hadoop__Yarn__PriorityProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__priority_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__priority_proto__pack_to_buffer
                     (const Hadoop__Yarn__PriorityProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__priority_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__PriorityProto *
       hadoop__yarn__priority_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__PriorityProto *)
     protobuf_c_message_unpack (&hadoop__yarn__priority_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__priority_proto__free_unpacked
                     (Hadoop__Yarn__PriorityProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__priority_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__container_proto__init
                     (Hadoop__Yarn__ContainerProto         *message)
{
  static Hadoop__Yarn__ContainerProto init_value = HADOOP__YARN__CONTAINER_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__container_proto__get_packed_size
                     (const Hadoop__Yarn__ContainerProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__container_proto__pack
                     (const Hadoop__Yarn__ContainerProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__container_proto__pack_to_buffer
                     (const Hadoop__Yarn__ContainerProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ContainerProto *
       hadoop__yarn__container_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ContainerProto *)
     protobuf_c_message_unpack (&hadoop__yarn__container_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__container_proto__free_unpacked
                     (Hadoop__Yarn__ContainerProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__urlproto__init
                     (Hadoop__Yarn__URLProto         *message)
{
  static Hadoop__Yarn__URLProto init_value = HADOOP__YARN__URLPROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__urlproto__get_packed_size
                     (const Hadoop__Yarn__URLProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__urlproto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__urlproto__pack
                     (const Hadoop__Yarn__URLProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__urlproto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__urlproto__pack_to_buffer
                     (const Hadoop__Yarn__URLProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__urlproto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__URLProto *
       hadoop__yarn__urlproto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__URLProto *)
     protobuf_c_message_unpack (&hadoop__yarn__urlproto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__urlproto__free_unpacked
                     (Hadoop__Yarn__URLProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__urlproto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__local_resource_proto__init
                     (Hadoop__Yarn__LocalResourceProto         *message)
{
  static Hadoop__Yarn__LocalResourceProto init_value = HADOOP__YARN__LOCAL_RESOURCE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__local_resource_proto__get_packed_size
                     (const Hadoop__Yarn__LocalResourceProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__local_resource_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__local_resource_proto__pack
                     (const Hadoop__Yarn__LocalResourceProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__local_resource_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__local_resource_proto__pack_to_buffer
                     (const Hadoop__Yarn__LocalResourceProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__local_resource_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__LocalResourceProto *
       hadoop__yarn__local_resource_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__LocalResourceProto *)
     protobuf_c_message_unpack (&hadoop__yarn__local_resource_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__local_resource_proto__free_unpacked
                     (Hadoop__Yarn__LocalResourceProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__local_resource_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__application_resource_usage_report_proto__init
                     (Hadoop__Yarn__ApplicationResourceUsageReportProto         *message)
{
  static Hadoop__Yarn__ApplicationResourceUsageReportProto init_value = HADOOP__YARN__APPLICATION_RESOURCE_USAGE_REPORT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__application_resource_usage_report_proto__get_packed_size
                     (const Hadoop__Yarn__ApplicationResourceUsageReportProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_resource_usage_report_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__application_resource_usage_report_proto__pack
                     (const Hadoop__Yarn__ApplicationResourceUsageReportProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_resource_usage_report_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__application_resource_usage_report_proto__pack_to_buffer
                     (const Hadoop__Yarn__ApplicationResourceUsageReportProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_resource_usage_report_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ApplicationResourceUsageReportProto *
       hadoop__yarn__application_resource_usage_report_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ApplicationResourceUsageReportProto *)
     protobuf_c_message_unpack (&hadoop__yarn__application_resource_usage_report_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__application_resource_usage_report_proto__free_unpacked
                     (Hadoop__Yarn__ApplicationResourceUsageReportProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_resource_usage_report_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__application_report_proto__init
                     (Hadoop__Yarn__ApplicationReportProto         *message)
{
  static Hadoop__Yarn__ApplicationReportProto init_value = HADOOP__YARN__APPLICATION_REPORT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__application_report_proto__get_packed_size
                     (const Hadoop__Yarn__ApplicationReportProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_report_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__application_report_proto__pack
                     (const Hadoop__Yarn__ApplicationReportProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_report_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__application_report_proto__pack_to_buffer
                     (const Hadoop__Yarn__ApplicationReportProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_report_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ApplicationReportProto *
       hadoop__yarn__application_report_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ApplicationReportProto *)
     protobuf_c_message_unpack (&hadoop__yarn__application_report_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__application_report_proto__free_unpacked
                     (Hadoop__Yarn__ApplicationReportProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_report_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__node_id_proto__init
                     (Hadoop__Yarn__NodeIdProto         *message)
{
  static Hadoop__Yarn__NodeIdProto init_value = HADOOP__YARN__NODE_ID_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__node_id_proto__get_packed_size
                     (const Hadoop__Yarn__NodeIdProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_id_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__node_id_proto__pack
                     (const Hadoop__Yarn__NodeIdProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_id_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__node_id_proto__pack_to_buffer
                     (const Hadoop__Yarn__NodeIdProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_id_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__NodeIdProto *
       hadoop__yarn__node_id_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__NodeIdProto *)
     protobuf_c_message_unpack (&hadoop__yarn__node_id_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__node_id_proto__free_unpacked
                     (Hadoop__Yarn__NodeIdProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_id_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__node_report_proto__init
                     (Hadoop__Yarn__NodeReportProto         *message)
{
  static Hadoop__Yarn__NodeReportProto init_value = HADOOP__YARN__NODE_REPORT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__node_report_proto__get_packed_size
                     (const Hadoop__Yarn__NodeReportProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_report_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__node_report_proto__pack
                     (const Hadoop__Yarn__NodeReportProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_report_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__node_report_proto__pack_to_buffer
                     (const Hadoop__Yarn__NodeReportProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_report_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__NodeReportProto *
       hadoop__yarn__node_report_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__NodeReportProto *)
     protobuf_c_message_unpack (&hadoop__yarn__node_report_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__node_report_proto__free_unpacked
                     (Hadoop__Yarn__NodeReportProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__node_report_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__resource_request_proto__init
                     (Hadoop__Yarn__ResourceRequestProto         *message)
{
  static Hadoop__Yarn__ResourceRequestProto init_value = HADOOP__YARN__RESOURCE_REQUEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__resource_request_proto__get_packed_size
                     (const Hadoop__Yarn__ResourceRequestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_request_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__resource_request_proto__pack
                     (const Hadoop__Yarn__ResourceRequestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_request_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__resource_request_proto__pack_to_buffer
                     (const Hadoop__Yarn__ResourceRequestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_request_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ResourceRequestProto *
       hadoop__yarn__resource_request_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ResourceRequestProto *)
     protobuf_c_message_unpack (&hadoop__yarn__resource_request_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__resource_request_proto__free_unpacked
                     (Hadoop__Yarn__ResourceRequestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_request_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__preemption_message_proto__init
                     (Hadoop__Yarn__PreemptionMessageProto         *message)
{
  static Hadoop__Yarn__PreemptionMessageProto init_value = HADOOP__YARN__PREEMPTION_MESSAGE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__preemption_message_proto__get_packed_size
                     (const Hadoop__Yarn__PreemptionMessageProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_message_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__preemption_message_proto__pack
                     (const Hadoop__Yarn__PreemptionMessageProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_message_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__preemption_message_proto__pack_to_buffer
                     (const Hadoop__Yarn__PreemptionMessageProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_message_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__PreemptionMessageProto *
       hadoop__yarn__preemption_message_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__PreemptionMessageProto *)
     protobuf_c_message_unpack (&hadoop__yarn__preemption_message_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__preemption_message_proto__free_unpacked
                     (Hadoop__Yarn__PreemptionMessageProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_message_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__strict_preemption_contract_proto__init
                     (Hadoop__Yarn__StrictPreemptionContractProto         *message)
{
  static Hadoop__Yarn__StrictPreemptionContractProto init_value = HADOOP__YARN__STRICT_PREEMPTION_CONTRACT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__strict_preemption_contract_proto__get_packed_size
                     (const Hadoop__Yarn__StrictPreemptionContractProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__strict_preemption_contract_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__strict_preemption_contract_proto__pack
                     (const Hadoop__Yarn__StrictPreemptionContractProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__strict_preemption_contract_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__strict_preemption_contract_proto__pack_to_buffer
                     (const Hadoop__Yarn__StrictPreemptionContractProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__strict_preemption_contract_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__StrictPreemptionContractProto *
       hadoop__yarn__strict_preemption_contract_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__StrictPreemptionContractProto *)
     protobuf_c_message_unpack (&hadoop__yarn__strict_preemption_contract_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__strict_preemption_contract_proto__free_unpacked
                     (Hadoop__Yarn__StrictPreemptionContractProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__strict_preemption_contract_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__preemption_contract_proto__init
                     (Hadoop__Yarn__PreemptionContractProto         *message)
{
  static Hadoop__Yarn__PreemptionContractProto init_value = HADOOP__YARN__PREEMPTION_CONTRACT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__preemption_contract_proto__get_packed_size
                     (const Hadoop__Yarn__PreemptionContractProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_contract_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__preemption_contract_proto__pack
                     (const Hadoop__Yarn__PreemptionContractProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_contract_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__preemption_contract_proto__pack_to_buffer
                     (const Hadoop__Yarn__PreemptionContractProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_contract_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__PreemptionContractProto *
       hadoop__yarn__preemption_contract_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__PreemptionContractProto *)
     protobuf_c_message_unpack (&hadoop__yarn__preemption_contract_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__preemption_contract_proto__free_unpacked
                     (Hadoop__Yarn__PreemptionContractProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_contract_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__preemption_container_proto__init
                     (Hadoop__Yarn__PreemptionContainerProto         *message)
{
  static Hadoop__Yarn__PreemptionContainerProto init_value = HADOOP__YARN__PREEMPTION_CONTAINER_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__preemption_container_proto__get_packed_size
                     (const Hadoop__Yarn__PreemptionContainerProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_container_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__preemption_container_proto__pack
                     (const Hadoop__Yarn__PreemptionContainerProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_container_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__preemption_container_proto__pack_to_buffer
                     (const Hadoop__Yarn__PreemptionContainerProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_container_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__PreemptionContainerProto *
       hadoop__yarn__preemption_container_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__PreemptionContainerProto *)
     protobuf_c_message_unpack (&hadoop__yarn__preemption_container_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__preemption_container_proto__free_unpacked
                     (Hadoop__Yarn__PreemptionContainerProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_container_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__preemption_resource_request_proto__init
                     (Hadoop__Yarn__PreemptionResourceRequestProto         *message)
{
  static Hadoop__Yarn__PreemptionResourceRequestProto init_value = HADOOP__YARN__PREEMPTION_RESOURCE_REQUEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__preemption_resource_request_proto__get_packed_size
                     (const Hadoop__Yarn__PreemptionResourceRequestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_resource_request_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__preemption_resource_request_proto__pack
                     (const Hadoop__Yarn__PreemptionResourceRequestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_resource_request_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__preemption_resource_request_proto__pack_to_buffer
                     (const Hadoop__Yarn__PreemptionResourceRequestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_resource_request_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__PreemptionResourceRequestProto *
       hadoop__yarn__preemption_resource_request_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__PreemptionResourceRequestProto *)
     protobuf_c_message_unpack (&hadoop__yarn__preemption_resource_request_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__preemption_resource_request_proto__free_unpacked
                     (Hadoop__Yarn__PreemptionResourceRequestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__preemption_resource_request_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__resource_blacklist_request_proto__init
                     (Hadoop__Yarn__ResourceBlacklistRequestProto         *message)
{
  static Hadoop__Yarn__ResourceBlacklistRequestProto init_value = HADOOP__YARN__RESOURCE_BLACKLIST_REQUEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__resource_blacklist_request_proto__get_packed_size
                     (const Hadoop__Yarn__ResourceBlacklistRequestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_blacklist_request_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__resource_blacklist_request_proto__pack
                     (const Hadoop__Yarn__ResourceBlacklistRequestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_blacklist_request_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__resource_blacklist_request_proto__pack_to_buffer
                     (const Hadoop__Yarn__ResourceBlacklistRequestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_blacklist_request_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ResourceBlacklistRequestProto *
       hadoop__yarn__resource_blacklist_request_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ResourceBlacklistRequestProto *)
     protobuf_c_message_unpack (&hadoop__yarn__resource_blacklist_request_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__resource_blacklist_request_proto__free_unpacked
                     (Hadoop__Yarn__ResourceBlacklistRequestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__resource_blacklist_request_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__application_submission_context_proto__init
                     (Hadoop__Yarn__ApplicationSubmissionContextProto         *message)
{
  static Hadoop__Yarn__ApplicationSubmissionContextProto init_value = HADOOP__YARN__APPLICATION_SUBMISSION_CONTEXT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__application_submission_context_proto__get_packed_size
                     (const Hadoop__Yarn__ApplicationSubmissionContextProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_submission_context_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__application_submission_context_proto__pack
                     (const Hadoop__Yarn__ApplicationSubmissionContextProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_submission_context_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__application_submission_context_proto__pack_to_buffer
                     (const Hadoop__Yarn__ApplicationSubmissionContextProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_submission_context_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ApplicationSubmissionContextProto *
       hadoop__yarn__application_submission_context_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ApplicationSubmissionContextProto *)
     protobuf_c_message_unpack (&hadoop__yarn__application_submission_context_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__application_submission_context_proto__free_unpacked
                     (Hadoop__Yarn__ApplicationSubmissionContextProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_submission_context_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__application_aclmap_proto__init
                     (Hadoop__Yarn__ApplicationACLMapProto         *message)
{
  static Hadoop__Yarn__ApplicationACLMapProto init_value = HADOOP__YARN__APPLICATION_ACLMAP_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__application_aclmap_proto__get_packed_size
                     (const Hadoop__Yarn__ApplicationACLMapProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_aclmap_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__application_aclmap_proto__pack
                     (const Hadoop__Yarn__ApplicationACLMapProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_aclmap_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__application_aclmap_proto__pack_to_buffer
                     (const Hadoop__Yarn__ApplicationACLMapProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_aclmap_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ApplicationACLMapProto *
       hadoop__yarn__application_aclmap_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ApplicationACLMapProto *)
     protobuf_c_message_unpack (&hadoop__yarn__application_aclmap_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__application_aclmap_proto__free_unpacked
                     (Hadoop__Yarn__ApplicationACLMapProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__application_aclmap_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__yarn_cluster_metrics_proto__init
                     (Hadoop__Yarn__YarnClusterMetricsProto         *message)
{
  static Hadoop__Yarn__YarnClusterMetricsProto init_value = HADOOP__YARN__YARN_CLUSTER_METRICS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__yarn_cluster_metrics_proto__get_packed_size
                     (const Hadoop__Yarn__YarnClusterMetricsProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__yarn_cluster_metrics_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__yarn_cluster_metrics_proto__pack
                     (const Hadoop__Yarn__YarnClusterMetricsProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__yarn_cluster_metrics_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__yarn_cluster_metrics_proto__pack_to_buffer
                     (const Hadoop__Yarn__YarnClusterMetricsProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__yarn_cluster_metrics_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__YarnClusterMetricsProto *
       hadoop__yarn__yarn_cluster_metrics_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__YarnClusterMetricsProto *)
     protobuf_c_message_unpack (&hadoop__yarn__yarn_cluster_metrics_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__yarn_cluster_metrics_proto__free_unpacked
                     (Hadoop__Yarn__YarnClusterMetricsProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__yarn_cluster_metrics_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__queue_info_proto__init
                     (Hadoop__Yarn__QueueInfoProto         *message)
{
  static Hadoop__Yarn__QueueInfoProto init_value = HADOOP__YARN__QUEUE_INFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__queue_info_proto__get_packed_size
                     (const Hadoop__Yarn__QueueInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_info_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__queue_info_proto__pack
                     (const Hadoop__Yarn__QueueInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_info_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__queue_info_proto__pack_to_buffer
                     (const Hadoop__Yarn__QueueInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_info_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__QueueInfoProto *
       hadoop__yarn__queue_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__QueueInfoProto *)
     protobuf_c_message_unpack (&hadoop__yarn__queue_info_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__queue_info_proto__free_unpacked
                     (Hadoop__Yarn__QueueInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_info_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__queue_user_aclinfo_proto__init
                     (Hadoop__Yarn__QueueUserACLInfoProto         *message)
{
  static Hadoop__Yarn__QueueUserACLInfoProto init_value = HADOOP__YARN__QUEUE_USER_ACLINFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__queue_user_aclinfo_proto__get_packed_size
                     (const Hadoop__Yarn__QueueUserACLInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_user_aclinfo_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__queue_user_aclinfo_proto__pack
                     (const Hadoop__Yarn__QueueUserACLInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_user_aclinfo_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__queue_user_aclinfo_proto__pack_to_buffer
                     (const Hadoop__Yarn__QueueUserACLInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_user_aclinfo_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__QueueUserACLInfoProto *
       hadoop__yarn__queue_user_aclinfo_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__QueueUserACLInfoProto *)
     protobuf_c_message_unpack (&hadoop__yarn__queue_user_aclinfo_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__queue_user_aclinfo_proto__free_unpacked
                     (Hadoop__Yarn__QueueUserACLInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__queue_user_aclinfo_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__container_launch_context_proto__init
                     (Hadoop__Yarn__ContainerLaunchContextProto         *message)
{
  static Hadoop__Yarn__ContainerLaunchContextProto init_value = HADOOP__YARN__CONTAINER_LAUNCH_CONTEXT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__container_launch_context_proto__get_packed_size
                     (const Hadoop__Yarn__ContainerLaunchContextProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_launch_context_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__container_launch_context_proto__pack
                     (const Hadoop__Yarn__ContainerLaunchContextProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_launch_context_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__container_launch_context_proto__pack_to_buffer
                     (const Hadoop__Yarn__ContainerLaunchContextProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_launch_context_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ContainerLaunchContextProto *
       hadoop__yarn__container_launch_context_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ContainerLaunchContextProto *)
     protobuf_c_message_unpack (&hadoop__yarn__container_launch_context_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__container_launch_context_proto__free_unpacked
                     (Hadoop__Yarn__ContainerLaunchContextProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_launch_context_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__container_status_proto__init
                     (Hadoop__Yarn__ContainerStatusProto         *message)
{
  static Hadoop__Yarn__ContainerStatusProto init_value = HADOOP__YARN__CONTAINER_STATUS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__container_status_proto__get_packed_size
                     (const Hadoop__Yarn__ContainerStatusProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_status_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__container_status_proto__pack
                     (const Hadoop__Yarn__ContainerStatusProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_status_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__container_status_proto__pack_to_buffer
                     (const Hadoop__Yarn__ContainerStatusProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_status_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__ContainerStatusProto *
       hadoop__yarn__container_status_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__ContainerStatusProto *)
     protobuf_c_message_unpack (&hadoop__yarn__container_status_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__container_status_proto__free_unpacked
                     (Hadoop__Yarn__ContainerStatusProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__container_status_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__string_local_resource_map_proto__init
                     (Hadoop__Yarn__StringLocalResourceMapProto         *message)
{
  static Hadoop__Yarn__StringLocalResourceMapProto init_value = HADOOP__YARN__STRING_LOCAL_RESOURCE_MAP_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__string_local_resource_map_proto__get_packed_size
                     (const Hadoop__Yarn__StringLocalResourceMapProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_local_resource_map_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__string_local_resource_map_proto__pack
                     (const Hadoop__Yarn__StringLocalResourceMapProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_local_resource_map_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__string_local_resource_map_proto__pack_to_buffer
                     (const Hadoop__Yarn__StringLocalResourceMapProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_local_resource_map_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__StringLocalResourceMapProto *
       hadoop__yarn__string_local_resource_map_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__StringLocalResourceMapProto *)
     protobuf_c_message_unpack (&hadoop__yarn__string_local_resource_map_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__string_local_resource_map_proto__free_unpacked
                     (Hadoop__Yarn__StringLocalResourceMapProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_local_resource_map_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__string_string_map_proto__init
                     (Hadoop__Yarn__StringStringMapProto         *message)
{
  static Hadoop__Yarn__StringStringMapProto init_value = HADOOP__YARN__STRING_STRING_MAP_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__string_string_map_proto__get_packed_size
                     (const Hadoop__Yarn__StringStringMapProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_string_map_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__string_string_map_proto__pack
                     (const Hadoop__Yarn__StringStringMapProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_string_map_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__string_string_map_proto__pack_to_buffer
                     (const Hadoop__Yarn__StringStringMapProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_string_map_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__StringStringMapProto *
       hadoop__yarn__string_string_map_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__StringStringMapProto *)
     protobuf_c_message_unpack (&hadoop__yarn__string_string_map_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__string_string_map_proto__free_unpacked
                     (Hadoop__Yarn__StringStringMapProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_string_map_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__yarn__string_bytes_map_proto__init
                     (Hadoop__Yarn__StringBytesMapProto         *message)
{
  static Hadoop__Yarn__StringBytesMapProto init_value = HADOOP__YARN__STRING_BYTES_MAP_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__yarn__string_bytes_map_proto__get_packed_size
                     (const Hadoop__Yarn__StringBytesMapProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_bytes_map_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__yarn__string_bytes_map_proto__pack
                     (const Hadoop__Yarn__StringBytesMapProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_bytes_map_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__yarn__string_bytes_map_proto__pack_to_buffer
                     (const Hadoop__Yarn__StringBytesMapProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_bytes_map_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Yarn__StringBytesMapProto *
       hadoop__yarn__string_bytes_map_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Yarn__StringBytesMapProto *)
     protobuf_c_message_unpack (&hadoop__yarn__string_bytes_map_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__yarn__string_bytes_map_proto__free_unpacked
                     (Hadoop__Yarn__StringBytesMapProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__yarn__string_bytes_map_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
static const ProtobufCFieldDescriptor hadoop__yarn__serialized_exception_proto__field_descriptors[4] =
{
  {
    "message",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__SerializedExceptionProto, message),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "trace",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__SerializedExceptionProto, trace),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "class_name",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__SerializedExceptionProto, class_name),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "cause",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__SerializedExceptionProto, cause),
    &hadoop__yarn__serialized_exception_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__serialized_exception_proto__field_indices_by_name[] = {
  3,   /* field[3] = cause */
  2,   /* field[2] = class_name */
  0,   /* field[0] = message */
  1,   /* field[1] = trace */
};
static const ProtobufCIntRange hadoop__yarn__serialized_exception_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__yarn__serialized_exception_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.SerializedExceptionProto",
  "SerializedExceptionProto",
  "Hadoop__Yarn__SerializedExceptionProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__SerializedExceptionProto),
  4,
  hadoop__yarn__serialized_exception_proto__field_descriptors,
  hadoop__yarn__serialized_exception_proto__field_indices_by_name,
  1,  hadoop__yarn__serialized_exception_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__serialized_exception_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__application_id_proto__field_descriptors[2] =
{
  {
    "id",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationIdProto, has_id),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationIdProto, id),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "cluster_timestamp",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationIdProto, has_cluster_timestamp),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationIdProto, cluster_timestamp),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__application_id_proto__field_indices_by_name[] = {
  1,   /* field[1] = cluster_timestamp */
  0,   /* field[0] = id */
};
static const ProtobufCIntRange hadoop__yarn__application_id_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__application_id_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ApplicationIdProto",
  "ApplicationIdProto",
  "Hadoop__Yarn__ApplicationIdProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ApplicationIdProto),
  2,
  hadoop__yarn__application_id_proto__field_descriptors,
  hadoop__yarn__application_id_proto__field_indices_by_name,
  1,  hadoop__yarn__application_id_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__application_id_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__application_attempt_id_proto__field_descriptors[2] =
{
  {
    "application_id",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationAttemptIdProto, application_id),
    &hadoop__yarn__application_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "attemptId",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationAttemptIdProto, has_attemptid),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationAttemptIdProto, attemptid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__application_attempt_id_proto__field_indices_by_name[] = {
  0,   /* field[0] = application_id */
  1,   /* field[1] = attemptId */
};
static const ProtobufCIntRange hadoop__yarn__application_attempt_id_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__application_attempt_id_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ApplicationAttemptIdProto",
  "ApplicationAttemptIdProto",
  "Hadoop__Yarn__ApplicationAttemptIdProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ApplicationAttemptIdProto),
  2,
  hadoop__yarn__application_attempt_id_proto__field_descriptors,
  hadoop__yarn__application_attempt_id_proto__field_indices_by_name,
  1,  hadoop__yarn__application_attempt_id_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__application_attempt_id_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__container_id_proto__field_descriptors[3] =
{
  {
    "app_id",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerIdProto, app_id),
    &hadoop__yarn__application_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "app_attempt_id",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerIdProto, app_attempt_id),
    &hadoop__yarn__application_attempt_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "id",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerIdProto, has_id),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerIdProto, id),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__container_id_proto__field_indices_by_name[] = {
  1,   /* field[1] = app_attempt_id */
  0,   /* field[0] = app_id */
  2,   /* field[2] = id */
};
static const ProtobufCIntRange hadoop__yarn__container_id_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__yarn__container_id_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ContainerIdProto",
  "ContainerIdProto",
  "Hadoop__Yarn__ContainerIdProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ContainerIdProto),
  3,
  hadoop__yarn__container_id_proto__field_descriptors,
  hadoop__yarn__container_id_proto__field_indices_by_name,
  1,  hadoop__yarn__container_id_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__container_id_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__resource_proto__field_descriptors[2] =
{
  {
    "memory",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceProto, has_memory),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceProto, memory),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "virtual_cores",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceProto, has_virtual_cores),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceProto, virtual_cores),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__resource_proto__field_indices_by_name[] = {
  0,   /* field[0] = memory */
  1,   /* field[1] = virtual_cores */
};
static const ProtobufCIntRange hadoop__yarn__resource_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__resource_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ResourceProto",
  "ResourceProto",
  "Hadoop__Yarn__ResourceProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ResourceProto),
  2,
  hadoop__yarn__resource_proto__field_descriptors,
  hadoop__yarn__resource_proto__field_indices_by_name,
  1,  hadoop__yarn__resource_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__resource_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__priority_proto__field_descriptors[1] =
{
  {
    "priority",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PriorityProto, has_priority),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PriorityProto, priority),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__priority_proto__field_indices_by_name[] = {
  0,   /* field[0] = priority */
};
static const ProtobufCIntRange hadoop__yarn__priority_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__yarn__priority_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.PriorityProto",
  "PriorityProto",
  "Hadoop__Yarn__PriorityProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__PriorityProto),
  1,
  hadoop__yarn__priority_proto__field_descriptors,
  hadoop__yarn__priority_proto__field_indices_by_name,
  1,  hadoop__yarn__priority_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__priority_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__container_proto__field_descriptors[6] =
{
  {
    "id",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerProto, id),
    &hadoop__yarn__container_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "nodeId",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerProto, nodeid),
    &hadoop__yarn__node_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "node_http_address",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerProto, node_http_address),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "resource",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerProto, resource),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "priority",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerProto, priority),
    &hadoop__yarn__priority_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "container_token",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerProto, container_token),
    &hadoop__common__token_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__container_proto__field_indices_by_name[] = {
  5,   /* field[5] = container_token */
  0,   /* field[0] = id */
  1,   /* field[1] = nodeId */
  2,   /* field[2] = node_http_address */
  4,   /* field[4] = priority */
  3,   /* field[3] = resource */
};
static const ProtobufCIntRange hadoop__yarn__container_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__yarn__container_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ContainerProto",
  "ContainerProto",
  "Hadoop__Yarn__ContainerProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ContainerProto),
  6,
  hadoop__yarn__container_proto__field_descriptors,
  hadoop__yarn__container_proto__field_indices_by_name,
  1,  hadoop__yarn__container_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__container_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__urlproto__field_descriptors[5] =
{
  {
    "scheme",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__URLProto, scheme),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "host",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__URLProto, host),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "port",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__URLProto, has_port),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__URLProto, port),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "file",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__URLProto, file),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "userInfo",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__URLProto, userinfo),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__urlproto__field_indices_by_name[] = {
  3,   /* field[3] = file */
  1,   /* field[1] = host */
  2,   /* field[2] = port */
  0,   /* field[0] = scheme */
  4,   /* field[4] = userInfo */
};
static const ProtobufCIntRange hadoop__yarn__urlproto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__yarn__urlproto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.URLProto",
  "URLProto",
  "Hadoop__Yarn__URLProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__URLProto),
  5,
  hadoop__yarn__urlproto__field_descriptors,
  hadoop__yarn__urlproto__field_indices_by_name,
  1,  hadoop__yarn__urlproto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__urlproto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__local_resource_proto__field_descriptors[6] =
{
  {
    "resource",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, resource),
    &hadoop__yarn__urlproto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "size",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, has_size),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, size),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "timestamp",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, has_timestamp),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, timestamp),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "type",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, has_type),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, type),
    &hadoop__yarn__local_resource_type_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "visibility",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, has_visibility),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, visibility),
    &hadoop__yarn__local_resource_visibility_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "pattern",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__LocalResourceProto, pattern),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__local_resource_proto__field_indices_by_name[] = {
  5,   /* field[5] = pattern */
  0,   /* field[0] = resource */
  1,   /* field[1] = size */
  2,   /* field[2] = timestamp */
  3,   /* field[3] = type */
  4,   /* field[4] = visibility */
};
static const ProtobufCIntRange hadoop__yarn__local_resource_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__yarn__local_resource_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.LocalResourceProto",
  "LocalResourceProto",
  "Hadoop__Yarn__LocalResourceProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__LocalResourceProto),
  6,
  hadoop__yarn__local_resource_proto__field_descriptors,
  hadoop__yarn__local_resource_proto__field_indices_by_name,
  1,  hadoop__yarn__local_resource_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__local_resource_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__application_resource_usage_report_proto__field_descriptors[5] =
{
  {
    "num_used_containers",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationResourceUsageReportProto, has_num_used_containers),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationResourceUsageReportProto, num_used_containers),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "num_reserved_containers",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationResourceUsageReportProto, has_num_reserved_containers),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationResourceUsageReportProto, num_reserved_containers),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "used_resources",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationResourceUsageReportProto, used_resources),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "reserved_resources",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationResourceUsageReportProto, reserved_resources),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "needed_resources",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationResourceUsageReportProto, needed_resources),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__application_resource_usage_report_proto__field_indices_by_name[] = {
  4,   /* field[4] = needed_resources */
  1,   /* field[1] = num_reserved_containers */
  0,   /* field[0] = num_used_containers */
  3,   /* field[3] = reserved_resources */
  2,   /* field[2] = used_resources */
};
static const ProtobufCIntRange hadoop__yarn__application_resource_usage_report_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__yarn__application_resource_usage_report_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ApplicationResourceUsageReportProto",
  "ApplicationResourceUsageReportProto",
  "Hadoop__Yarn__ApplicationResourceUsageReportProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ApplicationResourceUsageReportProto),
  5,
  hadoop__yarn__application_resource_usage_report_proto__field_descriptors,
  hadoop__yarn__application_resource_usage_report_proto__field_indices_by_name,
  1,  hadoop__yarn__application_resource_usage_report_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__application_resource_usage_report_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
char hadoop__yarn__application_report_proto__diagnostics__default_value[] = "N/A";
static const ProtobufCFieldDescriptor hadoop__yarn__application_report_proto__field_descriptors[19] =
{
  {
    "applicationId",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, applicationid),
    &hadoop__yarn__application_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "user",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, user),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "queue",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, queue),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "name",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, name),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "host",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, host),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "rpc_port",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, has_rpc_port),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, rpc_port),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "client_to_am_token",
    7,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, client_to_am_token),
    &hadoop__common__token_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "yarn_application_state",
    8,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, has_yarn_application_state),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, yarn_application_state),
    &hadoop__yarn__yarn_application_state_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "trackingUrl",
    9,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, trackingurl),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "diagnostics",
    10,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, diagnostics),
    NULL,
    &hadoop__yarn__application_report_proto__diagnostics__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "startTime",
    11,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, has_starttime),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, starttime),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "finishTime",
    12,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, has_finishtime),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, finishtime),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "final_application_status",
    13,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, has_final_application_status),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, final_application_status),
    &hadoop__yarn__final_application_status_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "app_resource_Usage",
    14,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, app_resource_usage),
    &hadoop__yarn__application_resource_usage_report_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "originalTrackingUrl",
    15,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, originaltrackingurl),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "currentApplicationAttemptId",
    16,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, currentapplicationattemptid),
    &hadoop__yarn__application_attempt_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "progress",
    17,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_FLOAT,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, has_progress),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, progress),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "applicationType",
    18,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, applicationtype),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "am_rm_token",
    19,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationReportProto, am_rm_token),
    &hadoop__common__token_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__application_report_proto__field_indices_by_name[] = {
  18,   /* field[18] = am_rm_token */
  13,   /* field[13] = app_resource_Usage */
  0,   /* field[0] = applicationId */
  17,   /* field[17] = applicationType */
  6,   /* field[6] = client_to_am_token */
  15,   /* field[15] = currentApplicationAttemptId */
  9,   /* field[9] = diagnostics */
  12,   /* field[12] = final_application_status */
  11,   /* field[11] = finishTime */
  4,   /* field[4] = host */
  3,   /* field[3] = name */
  14,   /* field[14] = originalTrackingUrl */
  16,   /* field[16] = progress */
  2,   /* field[2] = queue */
  5,   /* field[5] = rpc_port */
  10,   /* field[10] = startTime */
  8,   /* field[8] = trackingUrl */
  1,   /* field[1] = user */
  7,   /* field[7] = yarn_application_state */
};
static const ProtobufCIntRange hadoop__yarn__application_report_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 19 }
};
const ProtobufCMessageDescriptor hadoop__yarn__application_report_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ApplicationReportProto",
  "ApplicationReportProto",
  "Hadoop__Yarn__ApplicationReportProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ApplicationReportProto),
  19,
  hadoop__yarn__application_report_proto__field_descriptors,
  hadoop__yarn__application_report_proto__field_indices_by_name,
  1,  hadoop__yarn__application_report_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__application_report_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__node_id_proto__field_descriptors[2] =
{
  {
    "host",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeIdProto, host),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "port",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeIdProto, has_port),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeIdProto, port),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__node_id_proto__field_indices_by_name[] = {
  0,   /* field[0] = host */
  1,   /* field[1] = port */
};
static const ProtobufCIntRange hadoop__yarn__node_id_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__node_id_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.NodeIdProto",
  "NodeIdProto",
  "Hadoop__Yarn__NodeIdProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__NodeIdProto),
  2,
  hadoop__yarn__node_id_proto__field_descriptors,
  hadoop__yarn__node_id_proto__field_indices_by_name,
  1,  hadoop__yarn__node_id_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__node_id_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__node_report_proto__field_descriptors[9] =
{
  {
    "nodeId",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, nodeid),
    &hadoop__yarn__node_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "httpAddress",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, httpaddress),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "rackName",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, rackname),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "used",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, used),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "capability",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, capability),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "numContainers",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, has_numcontainers),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, numcontainers),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "node_state",
    7,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, has_node_state),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, node_state),
    &hadoop__yarn__node_state_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "health_report",
    8,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, health_report),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "last_health_report_time",
    9,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, has_last_health_report_time),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__NodeReportProto, last_health_report_time),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__node_report_proto__field_indices_by_name[] = {
  4,   /* field[4] = capability */
  7,   /* field[7] = health_report */
  1,   /* field[1] = httpAddress */
  8,   /* field[8] = last_health_report_time */
  0,   /* field[0] = nodeId */
  6,   /* field[6] = node_state */
  5,   /* field[5] = numContainers */
  2,   /* field[2] = rackName */
  3,   /* field[3] = used */
};
static const ProtobufCIntRange hadoop__yarn__node_report_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 9 }
};
const ProtobufCMessageDescriptor hadoop__yarn__node_report_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.NodeReportProto",
  "NodeReportProto",
  "Hadoop__Yarn__NodeReportProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__NodeReportProto),
  9,
  hadoop__yarn__node_report_proto__field_descriptors,
  hadoop__yarn__node_report_proto__field_indices_by_name,
  1,  hadoop__yarn__node_report_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__node_report_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const protobuf_c_boolean hadoop__yarn__resource_request_proto__relax_locality__default_value = 1;
static const ProtobufCFieldDescriptor hadoop__yarn__resource_request_proto__field_descriptors[5] =
{
  {
    "priority",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceRequestProto, priority),
    &hadoop__yarn__priority_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "resource_name",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceRequestProto, resource_name),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "capability",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceRequestProto, capability),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "num_containers",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceRequestProto, has_num_containers),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceRequestProto, num_containers),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "relax_locality",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceRequestProto, has_relax_locality),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceRequestProto, relax_locality),
    NULL,
    &hadoop__yarn__resource_request_proto__relax_locality__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__resource_request_proto__field_indices_by_name[] = {
  2,   /* field[2] = capability */
  3,   /* field[3] = num_containers */
  0,   /* field[0] = priority */
  4,   /* field[4] = relax_locality */
  1,   /* field[1] = resource_name */
};
static const ProtobufCIntRange hadoop__yarn__resource_request_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__yarn__resource_request_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ResourceRequestProto",
  "ResourceRequestProto",
  "Hadoop__Yarn__ResourceRequestProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ResourceRequestProto),
  5,
  hadoop__yarn__resource_request_proto__field_descriptors,
  hadoop__yarn__resource_request_proto__field_indices_by_name,
  1,  hadoop__yarn__resource_request_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__resource_request_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__preemption_message_proto__field_descriptors[2] =
{
  {
    "strictContract",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionMessageProto, strictcontract),
    &hadoop__yarn__strict_preemption_contract_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "contract",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionMessageProto, contract),
    &hadoop__yarn__preemption_contract_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__preemption_message_proto__field_indices_by_name[] = {
  1,   /* field[1] = contract */
  0,   /* field[0] = strictContract */
};
static const ProtobufCIntRange hadoop__yarn__preemption_message_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__preemption_message_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.PreemptionMessageProto",
  "PreemptionMessageProto",
  "Hadoop__Yarn__PreemptionMessageProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__PreemptionMessageProto),
  2,
  hadoop__yarn__preemption_message_proto__field_descriptors,
  hadoop__yarn__preemption_message_proto__field_indices_by_name,
  1,  hadoop__yarn__preemption_message_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__preemption_message_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__strict_preemption_contract_proto__field_descriptors[1] =
{
  {
    "container",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StrictPreemptionContractProto, n_container),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StrictPreemptionContractProto, container),
    &hadoop__yarn__preemption_container_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__strict_preemption_contract_proto__field_indices_by_name[] = {
  0,   /* field[0] = container */
};
static const ProtobufCIntRange hadoop__yarn__strict_preemption_contract_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__yarn__strict_preemption_contract_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.StrictPreemptionContractProto",
  "StrictPreemptionContractProto",
  "Hadoop__Yarn__StrictPreemptionContractProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__StrictPreemptionContractProto),
  1,
  hadoop__yarn__strict_preemption_contract_proto__field_descriptors,
  hadoop__yarn__strict_preemption_contract_proto__field_indices_by_name,
  1,  hadoop__yarn__strict_preemption_contract_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__strict_preemption_contract_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__preemption_contract_proto__field_descriptors[2] =
{
  {
    "resource",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionContractProto, n_resource),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionContractProto, resource),
    &hadoop__yarn__preemption_resource_request_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "container",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionContractProto, n_container),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionContractProto, container),
    &hadoop__yarn__preemption_container_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__preemption_contract_proto__field_indices_by_name[] = {
  1,   /* field[1] = container */
  0,   /* field[0] = resource */
};
static const ProtobufCIntRange hadoop__yarn__preemption_contract_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__preemption_contract_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.PreemptionContractProto",
  "PreemptionContractProto",
  "Hadoop__Yarn__PreemptionContractProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__PreemptionContractProto),
  2,
  hadoop__yarn__preemption_contract_proto__field_descriptors,
  hadoop__yarn__preemption_contract_proto__field_indices_by_name,
  1,  hadoop__yarn__preemption_contract_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__preemption_contract_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__preemption_container_proto__field_descriptors[1] =
{
  {
    "id",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionContainerProto, id),
    &hadoop__yarn__container_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__preemption_container_proto__field_indices_by_name[] = {
  0,   /* field[0] = id */
};
static const ProtobufCIntRange hadoop__yarn__preemption_container_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__yarn__preemption_container_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.PreemptionContainerProto",
  "PreemptionContainerProto",
  "Hadoop__Yarn__PreemptionContainerProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__PreemptionContainerProto),
  1,
  hadoop__yarn__preemption_container_proto__field_descriptors,
  hadoop__yarn__preemption_container_proto__field_indices_by_name,
  1,  hadoop__yarn__preemption_container_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__preemption_container_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__preemption_resource_request_proto__field_descriptors[1] =
{
  {
    "resource",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__PreemptionResourceRequestProto, resource),
    &hadoop__yarn__resource_request_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__preemption_resource_request_proto__field_indices_by_name[] = {
  0,   /* field[0] = resource */
};
static const ProtobufCIntRange hadoop__yarn__preemption_resource_request_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__yarn__preemption_resource_request_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.PreemptionResourceRequestProto",
  "PreemptionResourceRequestProto",
  "Hadoop__Yarn__PreemptionResourceRequestProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__PreemptionResourceRequestProto),
  1,
  hadoop__yarn__preemption_resource_request_proto__field_descriptors,
  hadoop__yarn__preemption_resource_request_proto__field_indices_by_name,
  1,  hadoop__yarn__preemption_resource_request_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__preemption_resource_request_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__resource_blacklist_request_proto__field_descriptors[2] =
{
  {
    "blacklist_additions",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_STRING,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceBlacklistRequestProto, n_blacklist_additions),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceBlacklistRequestProto, blacklist_additions),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blacklist_removals",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_STRING,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceBlacklistRequestProto, n_blacklist_removals),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ResourceBlacklistRequestProto, blacklist_removals),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__resource_blacklist_request_proto__field_indices_by_name[] = {
  0,   /* field[0] = blacklist_additions */
  1,   /* field[1] = blacklist_removals */
};
static const ProtobufCIntRange hadoop__yarn__resource_blacklist_request_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__resource_blacklist_request_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ResourceBlacklistRequestProto",
  "ResourceBlacklistRequestProto",
  "Hadoop__Yarn__ResourceBlacklistRequestProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ResourceBlacklistRequestProto),
  2,
  hadoop__yarn__resource_blacklist_request_proto__field_descriptors,
  hadoop__yarn__resource_blacklist_request_proto__field_indices_by_name,
  1,  hadoop__yarn__resource_blacklist_request_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__resource_blacklist_request_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
char hadoop__yarn__application_submission_context_proto__application_name__default_value[] = "N/A";
char hadoop__yarn__application_submission_context_proto__queue__default_value[] = "default";
char hadoop__yarn__application_submission_context_proto__application_type__default_value[] = "YARN";
static const protobuf_c_boolean hadoop__yarn__application_submission_context_proto__cancel_tokens_when_complete__default_value = 1;
static const protobuf_c_boolean hadoop__yarn__application_submission_context_proto__unmanaged_am__default_value = 0;
static const int32_t hadoop__yarn__application_submission_context_proto__max_app_attempts__default_value = 0;
static const ProtobufCFieldDescriptor hadoop__yarn__application_submission_context_proto__field_descriptors[10] =
{
  {
    "application_id",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, application_id),
    &hadoop__yarn__application_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "application_name",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, application_name),
    NULL,
    &hadoop__yarn__application_submission_context_proto__application_name__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "queue",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, queue),
    NULL,
    &hadoop__yarn__application_submission_context_proto__queue__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "priority",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, priority),
    &hadoop__yarn__priority_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "am_container_spec",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, am_container_spec),
    &hadoop__yarn__container_launch_context_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "cancel_tokens_when_complete",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, has_cancel_tokens_when_complete),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, cancel_tokens_when_complete),
    NULL,
    &hadoop__yarn__application_submission_context_proto__cancel_tokens_when_complete__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "unmanaged_am",
    7,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, has_unmanaged_am),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, unmanaged_am),
    NULL,
    &hadoop__yarn__application_submission_context_proto__unmanaged_am__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "maxAppAttempts",
    8,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, has_maxappattempts),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, maxappattempts),
    NULL,
    &hadoop__yarn__application_submission_context_proto__max_app_attempts__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "resource",
    9,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, resource),
    &hadoop__yarn__resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "applicationType",
    10,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationSubmissionContextProto, applicationtype),
    NULL,
    &hadoop__yarn__application_submission_context_proto__application_type__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__application_submission_context_proto__field_indices_by_name[] = {
  4,   /* field[4] = am_container_spec */
  9,   /* field[9] = applicationType */
  0,   /* field[0] = application_id */
  1,   /* field[1] = application_name */
  5,   /* field[5] = cancel_tokens_when_complete */
  7,   /* field[7] = maxAppAttempts */
  3,   /* field[3] = priority */
  2,   /* field[2] = queue */
  8,   /* field[8] = resource */
  6,   /* field[6] = unmanaged_am */
};
static const ProtobufCIntRange hadoop__yarn__application_submission_context_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 10 }
};
const ProtobufCMessageDescriptor hadoop__yarn__application_submission_context_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ApplicationSubmissionContextProto",
  "ApplicationSubmissionContextProto",
  "Hadoop__Yarn__ApplicationSubmissionContextProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ApplicationSubmissionContextProto),
  10,
  hadoop__yarn__application_submission_context_proto__field_descriptors,
  hadoop__yarn__application_submission_context_proto__field_indices_by_name,
  1,  hadoop__yarn__application_submission_context_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__application_submission_context_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
char hadoop__yarn__application_aclmap_proto__acl__default_value[] = " ";
static const ProtobufCFieldDescriptor hadoop__yarn__application_aclmap_proto__field_descriptors[2] =
{
  {
    "accessType",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationACLMapProto, has_accesstype),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationACLMapProto, accesstype),
    &hadoop__yarn__application_access_type_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "acl",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ApplicationACLMapProto, acl),
    NULL,
    &hadoop__yarn__application_aclmap_proto__acl__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__application_aclmap_proto__field_indices_by_name[] = {
  0,   /* field[0] = accessType */
  1,   /* field[1] = acl */
};
static const ProtobufCIntRange hadoop__yarn__application_aclmap_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__application_aclmap_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ApplicationACLMapProto",
  "ApplicationACLMapProto",
  "Hadoop__Yarn__ApplicationACLMapProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ApplicationACLMapProto),
  2,
  hadoop__yarn__application_aclmap_proto__field_descriptors,
  hadoop__yarn__application_aclmap_proto__field_indices_by_name,
  1,  hadoop__yarn__application_aclmap_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__application_aclmap_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__yarn_cluster_metrics_proto__field_descriptors[1] =
{
  {
    "num_node_managers",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__YarnClusterMetricsProto, has_num_node_managers),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__YarnClusterMetricsProto, num_node_managers),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__yarn_cluster_metrics_proto__field_indices_by_name[] = {
  0,   /* field[0] = num_node_managers */
};
static const ProtobufCIntRange hadoop__yarn__yarn_cluster_metrics_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__yarn__yarn_cluster_metrics_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.YarnClusterMetricsProto",
  "YarnClusterMetricsProto",
  "Hadoop__Yarn__YarnClusterMetricsProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__YarnClusterMetricsProto),
  1,
  hadoop__yarn__yarn_cluster_metrics_proto__field_descriptors,
  hadoop__yarn__yarn_cluster_metrics_proto__field_indices_by_name,
  1,  hadoop__yarn__yarn_cluster_metrics_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__yarn_cluster_metrics_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__queue_info_proto__field_descriptors[7] =
{
  {
    "queueName",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, queuename),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "capacity",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_FLOAT,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, has_capacity),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, capacity),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "maximumCapacity",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_FLOAT,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, has_maximumcapacity),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, maximumcapacity),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "currentCapacity",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_FLOAT,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, has_currentcapacity),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, currentcapacity),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "state",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, has_state),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, state),
    &hadoop__yarn__queue_state_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "childQueues",
    6,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, n_childqueues),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, childqueues),
    &hadoop__yarn__queue_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "applications",
    7,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, n_applications),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueInfoProto, applications),
    &hadoop__yarn__application_report_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__queue_info_proto__field_indices_by_name[] = {
  6,   /* field[6] = applications */
  1,   /* field[1] = capacity */
  5,   /* field[5] = childQueues */
  3,   /* field[3] = currentCapacity */
  2,   /* field[2] = maximumCapacity */
  0,   /* field[0] = queueName */
  4,   /* field[4] = state */
};
static const ProtobufCIntRange hadoop__yarn__queue_info_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 7 }
};
const ProtobufCMessageDescriptor hadoop__yarn__queue_info_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.QueueInfoProto",
  "QueueInfoProto",
  "Hadoop__Yarn__QueueInfoProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__QueueInfoProto),
  7,
  hadoop__yarn__queue_info_proto__field_descriptors,
  hadoop__yarn__queue_info_proto__field_indices_by_name,
  1,  hadoop__yarn__queue_info_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__queue_info_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__queue_user_aclinfo_proto__field_descriptors[2] =
{
  {
    "queueName",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueUserACLInfoProto, queuename),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "userAcls",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueUserACLInfoProto, n_useracls),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__QueueUserACLInfoProto, useracls),
    &hadoop__yarn__queue_aclproto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__queue_user_aclinfo_proto__field_indices_by_name[] = {
  0,   /* field[0] = queueName */
  1,   /* field[1] = userAcls */
};
static const ProtobufCIntRange hadoop__yarn__queue_user_aclinfo_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__queue_user_aclinfo_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.QueueUserACLInfoProto",
  "QueueUserACLInfoProto",
  "Hadoop__Yarn__QueueUserACLInfoProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__QueueUserACLInfoProto),
  2,
  hadoop__yarn__queue_user_aclinfo_proto__field_descriptors,
  hadoop__yarn__queue_user_aclinfo_proto__field_indices_by_name,
  1,  hadoop__yarn__queue_user_aclinfo_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__queue_user_aclinfo_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__container_launch_context_proto__field_descriptors[6] =
{
  {
    "localResources",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, n_localresources),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, localresources),
    &hadoop__yarn__string_local_resource_map_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "tokens",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BYTES,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, has_tokens),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, tokens),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "service_data",
    3,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, n_service_data),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, service_data),
    &hadoop__yarn__string_bytes_map_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "environment",
    4,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, n_environment),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, environment),
    &hadoop__yarn__string_string_map_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "command",
    5,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_STRING,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, n_command),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, command),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "application_ACLs",
    6,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, n_application_acls),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerLaunchContextProto, application_acls),
    &hadoop__yarn__application_aclmap_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__container_launch_context_proto__field_indices_by_name[] = {
  5,   /* field[5] = application_ACLs */
  4,   /* field[4] = command */
  3,   /* field[3] = environment */
  0,   /* field[0] = localResources */
  2,   /* field[2] = service_data */
  1,   /* field[1] = tokens */
};
static const ProtobufCIntRange hadoop__yarn__container_launch_context_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__yarn__container_launch_context_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ContainerLaunchContextProto",
  "ContainerLaunchContextProto",
  "Hadoop__Yarn__ContainerLaunchContextProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ContainerLaunchContextProto),
  6,
  hadoop__yarn__container_launch_context_proto__field_descriptors,
  hadoop__yarn__container_launch_context_proto__field_indices_by_name,
  1,  hadoop__yarn__container_launch_context_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__container_launch_context_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
char hadoop__yarn__container_status_proto__diagnostics__default_value[] = "N/A";
static const int32_t hadoop__yarn__container_status_proto__exit_status__default_value = -1000;
static const ProtobufCFieldDescriptor hadoop__yarn__container_status_proto__field_descriptors[4] =
{
  {
    "container_id",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerStatusProto, container_id),
    &hadoop__yarn__container_id_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "state",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerStatusProto, has_state),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerStatusProto, state),
    &hadoop__yarn__container_state_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "diagnostics",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerStatusProto, diagnostics),
    NULL,
    &hadoop__yarn__container_status_proto__diagnostics__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "exit_status",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerStatusProto, has_exit_status),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__ContainerStatusProto, exit_status),
    NULL,
    &hadoop__yarn__container_status_proto__exit_status__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__container_status_proto__field_indices_by_name[] = {
  0,   /* field[0] = container_id */
  2,   /* field[2] = diagnostics */
  3,   /* field[3] = exit_status */
  1,   /* field[1] = state */
};
static const ProtobufCIntRange hadoop__yarn__container_status_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__yarn__container_status_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ContainerStatusProto",
  "ContainerStatusProto",
  "Hadoop__Yarn__ContainerStatusProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__ContainerStatusProto),
  4,
  hadoop__yarn__container_status_proto__field_descriptors,
  hadoop__yarn__container_status_proto__field_indices_by_name,
  1,  hadoop__yarn__container_status_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__container_status_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__string_local_resource_map_proto__field_descriptors[2] =
{
  {
    "key",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StringLocalResourceMapProto, key),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "value",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StringLocalResourceMapProto, value),
    &hadoop__yarn__local_resource_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__string_local_resource_map_proto__field_indices_by_name[] = {
  0,   /* field[0] = key */
  1,   /* field[1] = value */
};
static const ProtobufCIntRange hadoop__yarn__string_local_resource_map_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__string_local_resource_map_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.StringLocalResourceMapProto",
  "StringLocalResourceMapProto",
  "Hadoop__Yarn__StringLocalResourceMapProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__StringLocalResourceMapProto),
  2,
  hadoop__yarn__string_local_resource_map_proto__field_descriptors,
  hadoop__yarn__string_local_resource_map_proto__field_indices_by_name,
  1,  hadoop__yarn__string_local_resource_map_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__string_local_resource_map_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__string_string_map_proto__field_descriptors[2] =
{
  {
    "key",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StringStringMapProto, key),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "value",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StringStringMapProto, value),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__string_string_map_proto__field_indices_by_name[] = {
  0,   /* field[0] = key */
  1,   /* field[1] = value */
};
static const ProtobufCIntRange hadoop__yarn__string_string_map_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__string_string_map_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.StringStringMapProto",
  "StringStringMapProto",
  "Hadoop__Yarn__StringStringMapProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__StringStringMapProto),
  2,
  hadoop__yarn__string_string_map_proto__field_descriptors,
  hadoop__yarn__string_string_map_proto__field_indices_by_name,
  1,  hadoop__yarn__string_string_map_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__string_string_map_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__yarn__string_bytes_map_proto__field_descriptors[2] =
{
  {
    "key",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StringBytesMapProto, key),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "value",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BYTES,
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StringBytesMapProto, has_value),
    PROTOBUF_C_OFFSETOF(Hadoop__Yarn__StringBytesMapProto, value),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__yarn__string_bytes_map_proto__field_indices_by_name[] = {
  0,   /* field[0] = key */
  1,   /* field[1] = value */
};
static const ProtobufCIntRange hadoop__yarn__string_bytes_map_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__yarn__string_bytes_map_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.yarn.StringBytesMapProto",
  "StringBytesMapProto",
  "Hadoop__Yarn__StringBytesMapProto",
  "hadoop.yarn",
  sizeof(Hadoop__Yarn__StringBytesMapProto),
  2,
  hadoop__yarn__string_bytes_map_proto__field_descriptors,
  hadoop__yarn__string_bytes_map_proto__field_indices_by_name,
  1,  hadoop__yarn__string_bytes_map_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__yarn__string_bytes_map_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__yarn__container_state_proto__enum_values_by_number[3] =
{
  { "C_NEW", "HADOOP__YARN__CONTAINER_STATE_PROTO__C_NEW", 1 },
  { "C_RUNNING", "HADOOP__YARN__CONTAINER_STATE_PROTO__C_RUNNING", 2 },
  { "C_COMPLETE", "HADOOP__YARN__CONTAINER_STATE_PROTO__C_COMPLETE", 3 },
};
static const ProtobufCIntRange hadoop__yarn__container_state_proto__value_ranges[] = {
{1, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__yarn__container_state_proto__enum_values_by_name[3] =
{
  { "C_COMPLETE", 2 },
  { "C_NEW", 0 },
  { "C_RUNNING", 1 },
};
const ProtobufCEnumDescriptor hadoop__yarn__container_state_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ContainerStateProto",
  "ContainerStateProto",
  "Hadoop__Yarn__ContainerStateProto",
  "hadoop.yarn",
  3,
  hadoop__yarn__container_state_proto__enum_values_by_number,
  3,
  hadoop__yarn__container_state_proto__enum_values_by_name,
  1,
  hadoop__yarn__container_state_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__yarn_application_state_proto__enum_values_by_number[8] =
{
  { "NEW", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__NEW", 1 },
  { "NEW_SAVING", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__NEW_SAVING", 2 },
  { "SUBMITTED", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__SUBMITTED", 3 },
  { "ACCEPTED", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__ACCEPTED", 4 },
  { "RUNNING", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__RUNNING", 5 },
  { "FINISHED", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__FINISHED", 6 },
  { "FAILED", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__FAILED", 7 },
  { "KILLED", "HADOOP__YARN__YARN_APPLICATION_STATE_PROTO__KILLED", 8 },
};
static const ProtobufCIntRange hadoop__yarn__yarn_application_state_proto__value_ranges[] = {
{1, 0},{0, 8}
};
const ProtobufCEnumValueIndex hadoop__yarn__yarn_application_state_proto__enum_values_by_name[8] =
{
  { "ACCEPTED", 3 },
  { "FAILED", 6 },
  { "FINISHED", 5 },
  { "KILLED", 7 },
  { "NEW", 0 },
  { "NEW_SAVING", 1 },
  { "RUNNING", 4 },
  { "SUBMITTED", 2 },
};
const ProtobufCEnumDescriptor hadoop__yarn__yarn_application_state_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.YarnApplicationStateProto",
  "YarnApplicationStateProto",
  "Hadoop__Yarn__YarnApplicationStateProto",
  "hadoop.yarn",
  8,
  hadoop__yarn__yarn_application_state_proto__enum_values_by_number,
  8,
  hadoop__yarn__yarn_application_state_proto__enum_values_by_name,
  1,
  hadoop__yarn__yarn_application_state_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__final_application_status_proto__enum_values_by_number[4] =
{
  { "APP_UNDEFINED", "HADOOP__YARN__FINAL_APPLICATION_STATUS_PROTO__APP_UNDEFINED", 0 },
  { "APP_SUCCEEDED", "HADOOP__YARN__FINAL_APPLICATION_STATUS_PROTO__APP_SUCCEEDED", 1 },
  { "APP_FAILED", "HADOOP__YARN__FINAL_APPLICATION_STATUS_PROTO__APP_FAILED", 2 },
  { "APP_KILLED", "HADOOP__YARN__FINAL_APPLICATION_STATUS_PROTO__APP_KILLED", 3 },
};
static const ProtobufCIntRange hadoop__yarn__final_application_status_proto__value_ranges[] = {
{0, 0},{0, 4}
};
const ProtobufCEnumValueIndex hadoop__yarn__final_application_status_proto__enum_values_by_name[4] =
{
  { "APP_FAILED", 2 },
  { "APP_KILLED", 3 },
  { "APP_SUCCEEDED", 1 },
  { "APP_UNDEFINED", 0 },
};
const ProtobufCEnumDescriptor hadoop__yarn__final_application_status_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.FinalApplicationStatusProto",
  "FinalApplicationStatusProto",
  "Hadoop__Yarn__FinalApplicationStatusProto",
  "hadoop.yarn",
  4,
  hadoop__yarn__final_application_status_proto__enum_values_by_number,
  4,
  hadoop__yarn__final_application_status_proto__enum_values_by_name,
  1,
  hadoop__yarn__final_application_status_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__local_resource_visibility_proto__enum_values_by_number[3] =
{
  { "PUBLIC", "HADOOP__YARN__LOCAL_RESOURCE_VISIBILITY_PROTO__PUBLIC", 1 },
  { "PRIVATE", "HADOOP__YARN__LOCAL_RESOURCE_VISIBILITY_PROTO__PRIVATE", 2 },
  { "APPLICATION", "HADOOP__YARN__LOCAL_RESOURCE_VISIBILITY_PROTO__APPLICATION", 3 },
};
static const ProtobufCIntRange hadoop__yarn__local_resource_visibility_proto__value_ranges[] = {
{1, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__yarn__local_resource_visibility_proto__enum_values_by_name[3] =
{
  { "APPLICATION", 2 },
  { "PRIVATE", 1 },
  { "PUBLIC", 0 },
};
const ProtobufCEnumDescriptor hadoop__yarn__local_resource_visibility_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.LocalResourceVisibilityProto",
  "LocalResourceVisibilityProto",
  "Hadoop__Yarn__LocalResourceVisibilityProto",
  "hadoop.yarn",
  3,
  hadoop__yarn__local_resource_visibility_proto__enum_values_by_number,
  3,
  hadoop__yarn__local_resource_visibility_proto__enum_values_by_name,
  1,
  hadoop__yarn__local_resource_visibility_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__local_resource_type_proto__enum_values_by_number[3] =
{
  { "ARCHIVE", "HADOOP__YARN__LOCAL_RESOURCE_TYPE_PROTO__ARCHIVE", 1 },
  { "FILE", "HADOOP__YARN__LOCAL_RESOURCE_TYPE_PROTO__FILE", 2 },
  { "PATTERN", "HADOOP__YARN__LOCAL_RESOURCE_TYPE_PROTO__PATTERN", 3 },
};
static const ProtobufCIntRange hadoop__yarn__local_resource_type_proto__value_ranges[] = {
{1, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__yarn__local_resource_type_proto__enum_values_by_name[3] =
{
  { "ARCHIVE", 0 },
  { "FILE", 1 },
  { "PATTERN", 2 },
};
const ProtobufCEnumDescriptor hadoop__yarn__local_resource_type_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.LocalResourceTypeProto",
  "LocalResourceTypeProto",
  "Hadoop__Yarn__LocalResourceTypeProto",
  "hadoop.yarn",
  3,
  hadoop__yarn__local_resource_type_proto__enum_values_by_number,
  3,
  hadoop__yarn__local_resource_type_proto__enum_values_by_name,
  1,
  hadoop__yarn__local_resource_type_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__node_state_proto__enum_values_by_number[6] =
{
  { "NS_NEW", "HADOOP__YARN__NODE_STATE_PROTO__NS_NEW", 1 },
  { "NS_RUNNING", "HADOOP__YARN__NODE_STATE_PROTO__NS_RUNNING", 2 },
  { "NS_UNHEALTHY", "HADOOP__YARN__NODE_STATE_PROTO__NS_UNHEALTHY", 3 },
  { "NS_DECOMMISSIONED", "HADOOP__YARN__NODE_STATE_PROTO__NS_DECOMMISSIONED", 4 },
  { "NS_LOST", "HADOOP__YARN__NODE_STATE_PROTO__NS_LOST", 5 },
  { "NS_REBOOTED", "HADOOP__YARN__NODE_STATE_PROTO__NS_REBOOTED", 6 },
};
static const ProtobufCIntRange hadoop__yarn__node_state_proto__value_ranges[] = {
{1, 0},{0, 6}
};
const ProtobufCEnumValueIndex hadoop__yarn__node_state_proto__enum_values_by_name[6] =
{
  { "NS_DECOMMISSIONED", 3 },
  { "NS_LOST", 4 },
  { "NS_NEW", 0 },
  { "NS_REBOOTED", 5 },
  { "NS_RUNNING", 1 },
  { "NS_UNHEALTHY", 2 },
};
const ProtobufCEnumDescriptor hadoop__yarn__node_state_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.NodeStateProto",
  "NodeStateProto",
  "Hadoop__Yarn__NodeStateProto",
  "hadoop.yarn",
  6,
  hadoop__yarn__node_state_proto__enum_values_by_number,
  6,
  hadoop__yarn__node_state_proto__enum_values_by_name,
  1,
  hadoop__yarn__node_state_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__amcommand_proto__enum_values_by_number[2] =
{
  { "AM_RESYNC", "HADOOP__YARN__AMCOMMAND_PROTO__AM_RESYNC", 1 },
  { "AM_SHUTDOWN", "HADOOP__YARN__AMCOMMAND_PROTO__AM_SHUTDOWN", 2 },
};
static const ProtobufCIntRange hadoop__yarn__amcommand_proto__value_ranges[] = {
{1, 0},{0, 2}
};
const ProtobufCEnumValueIndex hadoop__yarn__amcommand_proto__enum_values_by_name[2] =
{
  { "AM_RESYNC", 0 },
  { "AM_SHUTDOWN", 1 },
};
const ProtobufCEnumDescriptor hadoop__yarn__amcommand_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.AMCommandProto",
  "AMCommandProto",
  "Hadoop__Yarn__AMCommandProto",
  "hadoop.yarn",
  2,
  hadoop__yarn__amcommand_proto__enum_values_by_number,
  2,
  hadoop__yarn__amcommand_proto__enum_values_by_name,
  1,
  hadoop__yarn__amcommand_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__application_access_type_proto__enum_values_by_number[2] =
{
  { "APPACCESS_VIEW_APP", "HADOOP__YARN__APPLICATION_ACCESS_TYPE_PROTO__APPACCESS_VIEW_APP", 1 },
  { "APPACCESS_MODIFY_APP", "HADOOP__YARN__APPLICATION_ACCESS_TYPE_PROTO__APPACCESS_MODIFY_APP", 2 },
};
static const ProtobufCIntRange hadoop__yarn__application_access_type_proto__value_ranges[] = {
{1, 0},{0, 2}
};
const ProtobufCEnumValueIndex hadoop__yarn__application_access_type_proto__enum_values_by_name[2] =
{
  { "APPACCESS_MODIFY_APP", 1 },
  { "APPACCESS_VIEW_APP", 0 },
};
const ProtobufCEnumDescriptor hadoop__yarn__application_access_type_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ApplicationAccessTypeProto",
  "ApplicationAccessTypeProto",
  "Hadoop__Yarn__ApplicationAccessTypeProto",
  "hadoop.yarn",
  2,
  hadoop__yarn__application_access_type_proto__enum_values_by_number,
  2,
  hadoop__yarn__application_access_type_proto__enum_values_by_name,
  1,
  hadoop__yarn__application_access_type_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__queue_state_proto__enum_values_by_number[2] =
{
  { "Q_STOPPED", "HADOOP__YARN__QUEUE_STATE_PROTO__Q_STOPPED", 1 },
  { "Q_RUNNING", "HADOOP__YARN__QUEUE_STATE_PROTO__Q_RUNNING", 2 },
};
static const ProtobufCIntRange hadoop__yarn__queue_state_proto__value_ranges[] = {
{1, 0},{0, 2}
};
const ProtobufCEnumValueIndex hadoop__yarn__queue_state_proto__enum_values_by_name[2] =
{
  { "Q_RUNNING", 1 },
  { "Q_STOPPED", 0 },
};
const ProtobufCEnumDescriptor hadoop__yarn__queue_state_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.QueueStateProto",
  "QueueStateProto",
  "Hadoop__Yarn__QueueStateProto",
  "hadoop.yarn",
  2,
  hadoop__yarn__queue_state_proto__enum_values_by_number,
  2,
  hadoop__yarn__queue_state_proto__enum_values_by_name,
  1,
  hadoop__yarn__queue_state_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__queue_aclproto__enum_values_by_number[2] =
{
  { "QACL_SUBMIT_APPLICATIONS", "HADOOP__YARN__QUEUE_ACLPROTO__QACL_SUBMIT_APPLICATIONS", 1 },
  { "QACL_ADMINISTER_QUEUE", "HADOOP__YARN__QUEUE_ACLPROTO__QACL_ADMINISTER_QUEUE", 2 },
};
static const ProtobufCIntRange hadoop__yarn__queue_aclproto__value_ranges[] = {
{1, 0},{0, 2}
};
const ProtobufCEnumValueIndex hadoop__yarn__queue_aclproto__enum_values_by_name[2] =
{
  { "QACL_ADMINISTER_QUEUE", 1 },
  { "QACL_SUBMIT_APPLICATIONS", 0 },
};
const ProtobufCEnumDescriptor hadoop__yarn__queue_aclproto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.QueueACLProto",
  "QueueACLProto",
  "Hadoop__Yarn__QueueACLProto",
  "hadoop.yarn",
  2,
  hadoop__yarn__queue_aclproto__enum_values_by_number,
  2,
  hadoop__yarn__queue_aclproto__enum_values_by_name,
  1,
  hadoop__yarn__queue_aclproto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__yarn__container_exit_status_proto__enum_values_by_number[4] =
{
  { "INVALID", "HADOOP__YARN__CONTAINER_EXIT_STATUS_PROTO__INVALID", -1000 },
  { "DISKS_FAILED", "HADOOP__YARN__CONTAINER_EXIT_STATUS_PROTO__DISKS_FAILED", -101 },
  { "ABORTED", "HADOOP__YARN__CONTAINER_EXIT_STATUS_PROTO__ABORTED", -100 },
  { "SUCCESS", "HADOOP__YARN__CONTAINER_EXIT_STATUS_PROTO__SUCCESS", 0 },
};
static const ProtobufCIntRange hadoop__yarn__container_exit_status_proto__value_ranges[] = {
{4294966296, 0},{4294967195, 1},{0, 3},{0, 4}
};
const ProtobufCEnumValueIndex hadoop__yarn__container_exit_status_proto__enum_values_by_name[4] =
{
  { "ABORTED", 2 },
  { "DISKS_FAILED", 1 },
  { "INVALID", 0 },
  { "SUCCESS", 3 },
};
const ProtobufCEnumDescriptor hadoop__yarn__container_exit_status_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.yarn.ContainerExitStatusProto",
  "ContainerExitStatusProto",
  "Hadoop__Yarn__ContainerExitStatusProto",
  "hadoop.yarn",
  4,
  hadoop__yarn__container_exit_status_proto__enum_values_by_number,
  4,
  hadoop__yarn__container_exit_status_proto__enum_values_by_name,
  3,
  hadoop__yarn__container_exit_status_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
