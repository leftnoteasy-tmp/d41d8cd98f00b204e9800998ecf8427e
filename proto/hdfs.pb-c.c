/* Generated by the protocol buffer compiler.  DO NOT EDIT! */

/* Do not generate deprecated warnings for self */
#ifndef PROTOBUF_C_NO_DEPRECATED
#define PROTOBUF_C_NO_DEPRECATED
#endif

#include "hdfs.pb-c.h"
void   hadoop__hdfs__extended_block_proto__init
                     (Hadoop__Hdfs__ExtendedBlockProto         *message)
{
  static Hadoop__Hdfs__ExtendedBlockProto init_value = HADOOP__HDFS__EXTENDED_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__extended_block_proto__get_packed_size
                     (const Hadoop__Hdfs__ExtendedBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__extended_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__extended_block_proto__pack
                     (const Hadoop__Hdfs__ExtendedBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__extended_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__extended_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__ExtendedBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__extended_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__ExtendedBlockProto *
       hadoop__hdfs__extended_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__ExtendedBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__extended_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__extended_block_proto__free_unpacked
                     (Hadoop__Hdfs__ExtendedBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__extended_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__datanode_idproto__init
                     (Hadoop__Hdfs__DatanodeIDProto         *message)
{
  static Hadoop__Hdfs__DatanodeIDProto init_value = HADOOP__HDFS__DATANODE_IDPROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__datanode_idproto__get_packed_size
                     (const Hadoop__Hdfs__DatanodeIDProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_idproto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__datanode_idproto__pack
                     (const Hadoop__Hdfs__DatanodeIDProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_idproto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__datanode_idproto__pack_to_buffer
                     (const Hadoop__Hdfs__DatanodeIDProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_idproto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__DatanodeIDProto *
       hadoop__hdfs__datanode_idproto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__DatanodeIDProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__datanode_idproto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__datanode_idproto__free_unpacked
                     (Hadoop__Hdfs__DatanodeIDProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_idproto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__datanode_infos_proto__init
                     (Hadoop__Hdfs__DatanodeInfosProto         *message)
{
  static Hadoop__Hdfs__DatanodeInfosProto init_value = HADOOP__HDFS__DATANODE_INFOS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__datanode_infos_proto__get_packed_size
                     (const Hadoop__Hdfs__DatanodeInfosProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_infos_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__datanode_infos_proto__pack
                     (const Hadoop__Hdfs__DatanodeInfosProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_infos_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__datanode_infos_proto__pack_to_buffer
                     (const Hadoop__Hdfs__DatanodeInfosProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_infos_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__DatanodeInfosProto *
       hadoop__hdfs__datanode_infos_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__DatanodeInfosProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__datanode_infos_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__datanode_infos_proto__free_unpacked
                     (Hadoop__Hdfs__DatanodeInfosProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_infos_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__datanode_info_proto__init
                     (Hadoop__Hdfs__DatanodeInfoProto         *message)
{
  static Hadoop__Hdfs__DatanodeInfoProto init_value = HADOOP__HDFS__DATANODE_INFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__datanode_info_proto__get_packed_size
                     (const Hadoop__Hdfs__DatanodeInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_info_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__datanode_info_proto__pack
                     (const Hadoop__Hdfs__DatanodeInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_info_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__datanode_info_proto__pack_to_buffer
                     (const Hadoop__Hdfs__DatanodeInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_info_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__DatanodeInfoProto *
       hadoop__hdfs__datanode_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__DatanodeInfoProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__datanode_info_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__datanode_info_proto__free_unpacked
                     (Hadoop__Hdfs__DatanodeInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__datanode_info_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__content_summary_proto__init
                     (Hadoop__Hdfs__ContentSummaryProto         *message)
{
  static Hadoop__Hdfs__ContentSummaryProto init_value = HADOOP__HDFS__CONTENT_SUMMARY_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__content_summary_proto__get_packed_size
                     (const Hadoop__Hdfs__ContentSummaryProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__content_summary_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__content_summary_proto__pack
                     (const Hadoop__Hdfs__ContentSummaryProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__content_summary_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__content_summary_proto__pack_to_buffer
                     (const Hadoop__Hdfs__ContentSummaryProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__content_summary_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__ContentSummaryProto *
       hadoop__hdfs__content_summary_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__ContentSummaryProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__content_summary_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__content_summary_proto__free_unpacked
                     (Hadoop__Hdfs__ContentSummaryProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__content_summary_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__corrupt_file_blocks_proto__init
                     (Hadoop__Hdfs__CorruptFileBlocksProto         *message)
{
  static Hadoop__Hdfs__CorruptFileBlocksProto init_value = HADOOP__HDFS__CORRUPT_FILE_BLOCKS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__corrupt_file_blocks_proto__get_packed_size
                     (const Hadoop__Hdfs__CorruptFileBlocksProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__corrupt_file_blocks_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__corrupt_file_blocks_proto__pack
                     (const Hadoop__Hdfs__CorruptFileBlocksProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__corrupt_file_blocks_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__corrupt_file_blocks_proto__pack_to_buffer
                     (const Hadoop__Hdfs__CorruptFileBlocksProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__corrupt_file_blocks_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__CorruptFileBlocksProto *
       hadoop__hdfs__corrupt_file_blocks_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__CorruptFileBlocksProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__corrupt_file_blocks_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__corrupt_file_blocks_proto__free_unpacked
                     (Hadoop__Hdfs__CorruptFileBlocksProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__corrupt_file_blocks_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__fs_permission_proto__init
                     (Hadoop__Hdfs__FsPermissionProto         *message)
{
  static Hadoop__Hdfs__FsPermissionProto init_value = HADOOP__HDFS__FS_PERMISSION_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__fs_permission_proto__get_packed_size
                     (const Hadoop__Hdfs__FsPermissionProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_permission_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__fs_permission_proto__pack
                     (const Hadoop__Hdfs__FsPermissionProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_permission_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__fs_permission_proto__pack_to_buffer
                     (const Hadoop__Hdfs__FsPermissionProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_permission_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__FsPermissionProto *
       hadoop__hdfs__fs_permission_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__FsPermissionProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__fs_permission_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__fs_permission_proto__free_unpacked
                     (Hadoop__Hdfs__FsPermissionProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_permission_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__located_block_proto__init
                     (Hadoop__Hdfs__LocatedBlockProto         *message)
{
  static Hadoop__Hdfs__LocatedBlockProto init_value = HADOOP__HDFS__LOCATED_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__located_block_proto__get_packed_size
                     (const Hadoop__Hdfs__LocatedBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__located_block_proto__pack
                     (const Hadoop__Hdfs__LocatedBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__located_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__LocatedBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__LocatedBlockProto *
       hadoop__hdfs__located_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__LocatedBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__located_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__located_block_proto__free_unpacked
                     (Hadoop__Hdfs__LocatedBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__data_encryption_key_proto__init
                     (Hadoop__Hdfs__DataEncryptionKeyProto         *message)
{
  static Hadoop__Hdfs__DataEncryptionKeyProto init_value = HADOOP__HDFS__DATA_ENCRYPTION_KEY_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__data_encryption_key_proto__get_packed_size
                     (const Hadoop__Hdfs__DataEncryptionKeyProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_encryption_key_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__data_encryption_key_proto__pack
                     (const Hadoop__Hdfs__DataEncryptionKeyProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_encryption_key_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__data_encryption_key_proto__pack_to_buffer
                     (const Hadoop__Hdfs__DataEncryptionKeyProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_encryption_key_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__DataEncryptionKeyProto *
       hadoop__hdfs__data_encryption_key_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__DataEncryptionKeyProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__data_encryption_key_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__data_encryption_key_proto__free_unpacked
                     (Hadoop__Hdfs__DataEncryptionKeyProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_encryption_key_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__located_blocks_proto__init
                     (Hadoop__Hdfs__LocatedBlocksProto         *message)
{
  static Hadoop__Hdfs__LocatedBlocksProto init_value = HADOOP__HDFS__LOCATED_BLOCKS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__located_blocks_proto__get_packed_size
                     (const Hadoop__Hdfs__LocatedBlocksProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_blocks_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__located_blocks_proto__pack
                     (const Hadoop__Hdfs__LocatedBlocksProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_blocks_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__located_blocks_proto__pack_to_buffer
                     (const Hadoop__Hdfs__LocatedBlocksProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_blocks_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__LocatedBlocksProto *
       hadoop__hdfs__located_blocks_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__LocatedBlocksProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__located_blocks_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__located_blocks_proto__free_unpacked
                     (Hadoop__Hdfs__LocatedBlocksProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__located_blocks_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__hdfs_file_status_proto__init
                     (Hadoop__Hdfs__HdfsFileStatusProto         *message)
{
  static Hadoop__Hdfs__HdfsFileStatusProto init_value = HADOOP__HDFS__HDFS_FILE_STATUS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__hdfs_file_status_proto__get_packed_size
                     (const Hadoop__Hdfs__HdfsFileStatusProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__hdfs_file_status_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__hdfs_file_status_proto__pack
                     (const Hadoop__Hdfs__HdfsFileStatusProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__hdfs_file_status_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__hdfs_file_status_proto__pack_to_buffer
                     (const Hadoop__Hdfs__HdfsFileStatusProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__hdfs_file_status_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__HdfsFileStatusProto *
       hadoop__hdfs__hdfs_file_status_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__HdfsFileStatusProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__hdfs_file_status_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__hdfs_file_status_proto__free_unpacked
                     (Hadoop__Hdfs__HdfsFileStatusProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__hdfs_file_status_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__fs_server_defaults_proto__init
                     (Hadoop__Hdfs__FsServerDefaultsProto         *message)
{
  static Hadoop__Hdfs__FsServerDefaultsProto init_value = HADOOP__HDFS__FS_SERVER_DEFAULTS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__fs_server_defaults_proto__get_packed_size
                     (const Hadoop__Hdfs__FsServerDefaultsProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_server_defaults_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__fs_server_defaults_proto__pack
                     (const Hadoop__Hdfs__FsServerDefaultsProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_server_defaults_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__fs_server_defaults_proto__pack_to_buffer
                     (const Hadoop__Hdfs__FsServerDefaultsProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_server_defaults_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__FsServerDefaultsProto *
       hadoop__hdfs__fs_server_defaults_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__FsServerDefaultsProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__fs_server_defaults_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__fs_server_defaults_proto__free_unpacked
                     (Hadoop__Hdfs__FsServerDefaultsProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fs_server_defaults_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__directory_listing_proto__init
                     (Hadoop__Hdfs__DirectoryListingProto         *message)
{
  static Hadoop__Hdfs__DirectoryListingProto init_value = HADOOP__HDFS__DIRECTORY_LISTING_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__directory_listing_proto__get_packed_size
                     (const Hadoop__Hdfs__DirectoryListingProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__directory_listing_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__directory_listing_proto__pack
                     (const Hadoop__Hdfs__DirectoryListingProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__directory_listing_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__directory_listing_proto__pack_to_buffer
                     (const Hadoop__Hdfs__DirectoryListingProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__directory_listing_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__DirectoryListingProto *
       hadoop__hdfs__directory_listing_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__DirectoryListingProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__directory_listing_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__directory_listing_proto__free_unpacked
                     (Hadoop__Hdfs__DirectoryListingProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__directory_listing_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__snapshottable_directory_status_proto__init
                     (Hadoop__Hdfs__SnapshottableDirectoryStatusProto         *message)
{
  static Hadoop__Hdfs__SnapshottableDirectoryStatusProto init_value = HADOOP__HDFS__SNAPSHOTTABLE_DIRECTORY_STATUS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__snapshottable_directory_status_proto__get_packed_size
                     (const Hadoop__Hdfs__SnapshottableDirectoryStatusProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_status_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__snapshottable_directory_status_proto__pack
                     (const Hadoop__Hdfs__SnapshottableDirectoryStatusProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_status_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__snapshottable_directory_status_proto__pack_to_buffer
                     (const Hadoop__Hdfs__SnapshottableDirectoryStatusProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_status_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__SnapshottableDirectoryStatusProto *
       hadoop__hdfs__snapshottable_directory_status_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__SnapshottableDirectoryStatusProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__snapshottable_directory_status_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__snapshottable_directory_status_proto__free_unpacked
                     (Hadoop__Hdfs__SnapshottableDirectoryStatusProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_status_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__snapshottable_directory_listing_proto__init
                     (Hadoop__Hdfs__SnapshottableDirectoryListingProto         *message)
{
  static Hadoop__Hdfs__SnapshottableDirectoryListingProto init_value = HADOOP__HDFS__SNAPSHOTTABLE_DIRECTORY_LISTING_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__snapshottable_directory_listing_proto__get_packed_size
                     (const Hadoop__Hdfs__SnapshottableDirectoryListingProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_listing_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__snapshottable_directory_listing_proto__pack
                     (const Hadoop__Hdfs__SnapshottableDirectoryListingProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_listing_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__snapshottable_directory_listing_proto__pack_to_buffer
                     (const Hadoop__Hdfs__SnapshottableDirectoryListingProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_listing_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__SnapshottableDirectoryListingProto *
       hadoop__hdfs__snapshottable_directory_listing_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__SnapshottableDirectoryListingProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__snapshottable_directory_listing_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__snapshottable_directory_listing_proto__free_unpacked
                     (Hadoop__Hdfs__SnapshottableDirectoryListingProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshottable_directory_listing_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__snapshot_diff_report_entry_proto__init
                     (Hadoop__Hdfs__SnapshotDiffReportEntryProto         *message)
{
  static Hadoop__Hdfs__SnapshotDiffReportEntryProto init_value = HADOOP__HDFS__SNAPSHOT_DIFF_REPORT_ENTRY_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__snapshot_diff_report_entry_proto__get_packed_size
                     (const Hadoop__Hdfs__SnapshotDiffReportEntryProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_entry_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__snapshot_diff_report_entry_proto__pack
                     (const Hadoop__Hdfs__SnapshotDiffReportEntryProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_entry_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__snapshot_diff_report_entry_proto__pack_to_buffer
                     (const Hadoop__Hdfs__SnapshotDiffReportEntryProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_entry_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__SnapshotDiffReportEntryProto *
       hadoop__hdfs__snapshot_diff_report_entry_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__SnapshotDiffReportEntryProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__snapshot_diff_report_entry_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__snapshot_diff_report_entry_proto__free_unpacked
                     (Hadoop__Hdfs__SnapshotDiffReportEntryProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_entry_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__snapshot_diff_report_proto__init
                     (Hadoop__Hdfs__SnapshotDiffReportProto         *message)
{
  static Hadoop__Hdfs__SnapshotDiffReportProto init_value = HADOOP__HDFS__SNAPSHOT_DIFF_REPORT_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__snapshot_diff_report_proto__get_packed_size
                     (const Hadoop__Hdfs__SnapshotDiffReportProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__snapshot_diff_report_proto__pack
                     (const Hadoop__Hdfs__SnapshotDiffReportProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__snapshot_diff_report_proto__pack_to_buffer
                     (const Hadoop__Hdfs__SnapshotDiffReportProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__SnapshotDiffReportProto *
       hadoop__hdfs__snapshot_diff_report_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__SnapshotDiffReportProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__snapshot_diff_report_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__snapshot_diff_report_proto__free_unpacked
                     (Hadoop__Hdfs__SnapshotDiffReportProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_diff_report_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__storage_info_proto__init
                     (Hadoop__Hdfs__StorageInfoProto         *message)
{
  static Hadoop__Hdfs__StorageInfoProto init_value = HADOOP__HDFS__STORAGE_INFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__storage_info_proto__get_packed_size
                     (const Hadoop__Hdfs__StorageInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__storage_info_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__storage_info_proto__pack
                     (const Hadoop__Hdfs__StorageInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__storage_info_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__storage_info_proto__pack_to_buffer
                     (const Hadoop__Hdfs__StorageInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__storage_info_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__StorageInfoProto *
       hadoop__hdfs__storage_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__StorageInfoProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__storage_info_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__storage_info_proto__free_unpacked
                     (Hadoop__Hdfs__StorageInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__storage_info_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__namenode_registration_proto__init
                     (Hadoop__Hdfs__NamenodeRegistrationProto         *message)
{
  static Hadoop__Hdfs__NamenodeRegistrationProto init_value = HADOOP__HDFS__NAMENODE_REGISTRATION_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__namenode_registration_proto__get_packed_size
                     (const Hadoop__Hdfs__NamenodeRegistrationProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_registration_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__namenode_registration_proto__pack
                     (const Hadoop__Hdfs__NamenodeRegistrationProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_registration_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__namenode_registration_proto__pack_to_buffer
                     (const Hadoop__Hdfs__NamenodeRegistrationProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_registration_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__NamenodeRegistrationProto *
       hadoop__hdfs__namenode_registration_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__NamenodeRegistrationProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__namenode_registration_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__namenode_registration_proto__free_unpacked
                     (Hadoop__Hdfs__NamenodeRegistrationProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_registration_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__checkpoint_signature_proto__init
                     (Hadoop__Hdfs__CheckpointSignatureProto         *message)
{
  static Hadoop__Hdfs__CheckpointSignatureProto init_value = HADOOP__HDFS__CHECKPOINT_SIGNATURE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__checkpoint_signature_proto__get_packed_size
                     (const Hadoop__Hdfs__CheckpointSignatureProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_signature_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__checkpoint_signature_proto__pack
                     (const Hadoop__Hdfs__CheckpointSignatureProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_signature_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__checkpoint_signature_proto__pack_to_buffer
                     (const Hadoop__Hdfs__CheckpointSignatureProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_signature_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__CheckpointSignatureProto *
       hadoop__hdfs__checkpoint_signature_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__CheckpointSignatureProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__checkpoint_signature_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__checkpoint_signature_proto__free_unpacked
                     (Hadoop__Hdfs__CheckpointSignatureProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_signature_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__namenode_command_proto__init
                     (Hadoop__Hdfs__NamenodeCommandProto         *message)
{
  static Hadoop__Hdfs__NamenodeCommandProto init_value = HADOOP__HDFS__NAMENODE_COMMAND_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__namenode_command_proto__get_packed_size
                     (const Hadoop__Hdfs__NamenodeCommandProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_command_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__namenode_command_proto__pack
                     (const Hadoop__Hdfs__NamenodeCommandProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_command_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__namenode_command_proto__pack_to_buffer
                     (const Hadoop__Hdfs__NamenodeCommandProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_command_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__NamenodeCommandProto *
       hadoop__hdfs__namenode_command_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__NamenodeCommandProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__namenode_command_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__namenode_command_proto__free_unpacked
                     (Hadoop__Hdfs__NamenodeCommandProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namenode_command_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__checkpoint_command_proto__init
                     (Hadoop__Hdfs__CheckpointCommandProto         *message)
{
  static Hadoop__Hdfs__CheckpointCommandProto init_value = HADOOP__HDFS__CHECKPOINT_COMMAND_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__checkpoint_command_proto__get_packed_size
                     (const Hadoop__Hdfs__CheckpointCommandProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_command_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__checkpoint_command_proto__pack
                     (const Hadoop__Hdfs__CheckpointCommandProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_command_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__checkpoint_command_proto__pack_to_buffer
                     (const Hadoop__Hdfs__CheckpointCommandProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_command_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__CheckpointCommandProto *
       hadoop__hdfs__checkpoint_command_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__CheckpointCommandProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__checkpoint_command_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__checkpoint_command_proto__free_unpacked
                     (Hadoop__Hdfs__CheckpointCommandProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checkpoint_command_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__block_proto__init
                     (Hadoop__Hdfs__BlockProto         *message)
{
  static Hadoop__Hdfs__BlockProto init_value = HADOOP__HDFS__BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__block_proto__get_packed_size
                     (const Hadoop__Hdfs__BlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__block_proto__pack
                     (const Hadoop__Hdfs__BlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__BlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__BlockProto *
       hadoop__hdfs__block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__BlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__block_proto__free_unpacked
                     (Hadoop__Hdfs__BlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__block_with_locations_proto__init
                     (Hadoop__Hdfs__BlockWithLocationsProto         *message)
{
  static Hadoop__Hdfs__BlockWithLocationsProto init_value = HADOOP__HDFS__BLOCK_WITH_LOCATIONS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__block_with_locations_proto__get_packed_size
                     (const Hadoop__Hdfs__BlockWithLocationsProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_with_locations_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__block_with_locations_proto__pack
                     (const Hadoop__Hdfs__BlockWithLocationsProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_with_locations_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__block_with_locations_proto__pack_to_buffer
                     (const Hadoop__Hdfs__BlockWithLocationsProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_with_locations_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__BlockWithLocationsProto *
       hadoop__hdfs__block_with_locations_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__BlockWithLocationsProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__block_with_locations_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__block_with_locations_proto__free_unpacked
                     (Hadoop__Hdfs__BlockWithLocationsProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_with_locations_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__blocks_with_locations_proto__init
                     (Hadoop__Hdfs__BlocksWithLocationsProto         *message)
{
  static Hadoop__Hdfs__BlocksWithLocationsProto init_value = HADOOP__HDFS__BLOCKS_WITH_LOCATIONS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__blocks_with_locations_proto__get_packed_size
                     (const Hadoop__Hdfs__BlocksWithLocationsProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__blocks_with_locations_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__blocks_with_locations_proto__pack
                     (const Hadoop__Hdfs__BlocksWithLocationsProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__blocks_with_locations_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__blocks_with_locations_proto__pack_to_buffer
                     (const Hadoop__Hdfs__BlocksWithLocationsProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__blocks_with_locations_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__BlocksWithLocationsProto *
       hadoop__hdfs__blocks_with_locations_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__BlocksWithLocationsProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__blocks_with_locations_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__blocks_with_locations_proto__free_unpacked
                     (Hadoop__Hdfs__BlocksWithLocationsProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__blocks_with_locations_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__remote_edit_log_proto__init
                     (Hadoop__Hdfs__RemoteEditLogProto         *message)
{
  static Hadoop__Hdfs__RemoteEditLogProto init_value = HADOOP__HDFS__REMOTE_EDIT_LOG_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__remote_edit_log_proto__get_packed_size
                     (const Hadoop__Hdfs__RemoteEditLogProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__remote_edit_log_proto__pack
                     (const Hadoop__Hdfs__RemoteEditLogProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__remote_edit_log_proto__pack_to_buffer
                     (const Hadoop__Hdfs__RemoteEditLogProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__RemoteEditLogProto *
       hadoop__hdfs__remote_edit_log_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__RemoteEditLogProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__remote_edit_log_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__remote_edit_log_proto__free_unpacked
                     (Hadoop__Hdfs__RemoteEditLogProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__remote_edit_log_manifest_proto__init
                     (Hadoop__Hdfs__RemoteEditLogManifestProto         *message)
{
  static Hadoop__Hdfs__RemoteEditLogManifestProto init_value = HADOOP__HDFS__REMOTE_EDIT_LOG_MANIFEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__remote_edit_log_manifest_proto__get_packed_size
                     (const Hadoop__Hdfs__RemoteEditLogManifestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_manifest_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__remote_edit_log_manifest_proto__pack
                     (const Hadoop__Hdfs__RemoteEditLogManifestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_manifest_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__remote_edit_log_manifest_proto__pack_to_buffer
                     (const Hadoop__Hdfs__RemoteEditLogManifestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_manifest_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__RemoteEditLogManifestProto *
       hadoop__hdfs__remote_edit_log_manifest_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__RemoteEditLogManifestProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__remote_edit_log_manifest_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__remote_edit_log_manifest_proto__free_unpacked
                     (Hadoop__Hdfs__RemoteEditLogManifestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__remote_edit_log_manifest_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__namespace_info_proto__init
                     (Hadoop__Hdfs__NamespaceInfoProto         *message)
{
  static Hadoop__Hdfs__NamespaceInfoProto init_value = HADOOP__HDFS__NAMESPACE_INFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__namespace_info_proto__get_packed_size
                     (const Hadoop__Hdfs__NamespaceInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namespace_info_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__namespace_info_proto__pack
                     (const Hadoop__Hdfs__NamespaceInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namespace_info_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__namespace_info_proto__pack_to_buffer
                     (const Hadoop__Hdfs__NamespaceInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namespace_info_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__NamespaceInfoProto *
       hadoop__hdfs__namespace_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__NamespaceInfoProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__namespace_info_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__namespace_info_proto__free_unpacked
                     (Hadoop__Hdfs__NamespaceInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__namespace_info_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__block_key_proto__init
                     (Hadoop__Hdfs__BlockKeyProto         *message)
{
  static Hadoop__Hdfs__BlockKeyProto init_value = HADOOP__HDFS__BLOCK_KEY_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__block_key_proto__get_packed_size
                     (const Hadoop__Hdfs__BlockKeyProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_key_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__block_key_proto__pack
                     (const Hadoop__Hdfs__BlockKeyProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_key_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__block_key_proto__pack_to_buffer
                     (const Hadoop__Hdfs__BlockKeyProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_key_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__BlockKeyProto *
       hadoop__hdfs__block_key_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__BlockKeyProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__block_key_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__block_key_proto__free_unpacked
                     (Hadoop__Hdfs__BlockKeyProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_key_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__exported_block_keys_proto__init
                     (Hadoop__Hdfs__ExportedBlockKeysProto         *message)
{
  static Hadoop__Hdfs__ExportedBlockKeysProto init_value = HADOOP__HDFS__EXPORTED_BLOCK_KEYS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__exported_block_keys_proto__get_packed_size
                     (const Hadoop__Hdfs__ExportedBlockKeysProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__exported_block_keys_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__exported_block_keys_proto__pack
                     (const Hadoop__Hdfs__ExportedBlockKeysProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__exported_block_keys_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__exported_block_keys_proto__pack_to_buffer
                     (const Hadoop__Hdfs__ExportedBlockKeysProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__exported_block_keys_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__ExportedBlockKeysProto *
       hadoop__hdfs__exported_block_keys_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__ExportedBlockKeysProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__exported_block_keys_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__exported_block_keys_proto__free_unpacked
                     (Hadoop__Hdfs__ExportedBlockKeysProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__exported_block_keys_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__recovering_block_proto__init
                     (Hadoop__Hdfs__RecoveringBlockProto         *message)
{
  static Hadoop__Hdfs__RecoveringBlockProto init_value = HADOOP__HDFS__RECOVERING_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__recovering_block_proto__get_packed_size
                     (const Hadoop__Hdfs__RecoveringBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__recovering_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__recovering_block_proto__pack
                     (const Hadoop__Hdfs__RecoveringBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__recovering_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__recovering_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__RecoveringBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__recovering_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__RecoveringBlockProto *
       hadoop__hdfs__recovering_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__RecoveringBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__recovering_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__recovering_block_proto__free_unpacked
                     (Hadoop__Hdfs__RecoveringBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__recovering_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__version_request_proto__init
                     (Hadoop__Hdfs__VersionRequestProto         *message)
{
  static Hadoop__Hdfs__VersionRequestProto init_value = HADOOP__HDFS__VERSION_REQUEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__version_request_proto__get_packed_size
                     (const Hadoop__Hdfs__VersionRequestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_request_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__version_request_proto__pack
                     (const Hadoop__Hdfs__VersionRequestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_request_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__version_request_proto__pack_to_buffer
                     (const Hadoop__Hdfs__VersionRequestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_request_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__VersionRequestProto *
       hadoop__hdfs__version_request_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__VersionRequestProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__version_request_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__version_request_proto__free_unpacked
                     (Hadoop__Hdfs__VersionRequestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_request_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__version_response_proto__init
                     (Hadoop__Hdfs__VersionResponseProto         *message)
{
  static Hadoop__Hdfs__VersionResponseProto init_value = HADOOP__HDFS__VERSION_RESPONSE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__version_response_proto__get_packed_size
                     (const Hadoop__Hdfs__VersionResponseProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_response_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__version_response_proto__pack
                     (const Hadoop__Hdfs__VersionResponseProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_response_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__version_response_proto__pack_to_buffer
                     (const Hadoop__Hdfs__VersionResponseProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_response_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__VersionResponseProto *
       hadoop__hdfs__version_response_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__VersionResponseProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__version_response_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__version_response_proto__free_unpacked
                     (Hadoop__Hdfs__VersionResponseProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_response_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__snapshot_info_proto__init
                     (Hadoop__Hdfs__SnapshotInfoProto         *message)
{
  static Hadoop__Hdfs__SnapshotInfoProto init_value = HADOOP__HDFS__SNAPSHOT_INFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__snapshot_info_proto__get_packed_size
                     (const Hadoop__Hdfs__SnapshotInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_info_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__snapshot_info_proto__pack
                     (const Hadoop__Hdfs__SnapshotInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_info_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__snapshot_info_proto__pack_to_buffer
                     (const Hadoop__Hdfs__SnapshotInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_info_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__SnapshotInfoProto *
       hadoop__hdfs__snapshot_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__SnapshotInfoProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__snapshot_info_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__snapshot_info_proto__free_unpacked
                     (Hadoop__Hdfs__SnapshotInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__snapshot_info_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
static const uint64_t hadoop__hdfs__extended_block_proto__num_bytes__default_value = 0;
static const ProtobufCFieldDescriptor hadoop__hdfs__extended_block_proto__field_descriptors[4] =
{
  {
    "poolId",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExtendedBlockProto, poolid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blockId",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExtendedBlockProto, blockid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "generationStamp",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExtendedBlockProto, generationstamp),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "numBytes",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExtendedBlockProto, has_numbytes),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExtendedBlockProto, numbytes),
    NULL,
    &hadoop__hdfs__extended_block_proto__num_bytes__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__extended_block_proto__field_indices_by_name[] = {
  1,   /* field[1] = blockId */
  2,   /* field[2] = generationStamp */
  3,   /* field[3] = numBytes */
  0,   /* field[0] = poolId */
};
static const ProtobufCIntRange hadoop__hdfs__extended_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__extended_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ExtendedBlockProto",
  "ExtendedBlockProto",
  "Hadoop__Hdfs__ExtendedBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__ExtendedBlockProto),
  4,
  hadoop__hdfs__extended_block_proto__field_descriptors,
  hadoop__hdfs__extended_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__extended_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__extended_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__datanode_idproto__field_descriptors[6] =
{
  {
    "ipAddr",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeIDProto, ipaddr),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "hostName",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeIDProto, hostname),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "storageID",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeIDProto, storageid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "xferPort",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeIDProto, xferport),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "infoPort",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeIDProto, infoport),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "ipcPort",
    6,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeIDProto, ipcport),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__datanode_idproto__field_indices_by_name[] = {
  1,   /* field[1] = hostName */
  4,   /* field[4] = infoPort */
  0,   /* field[0] = ipAddr */
  5,   /* field[5] = ipcPort */
  2,   /* field[2] = storageID */
  3,   /* field[3] = xferPort */
};
static const ProtobufCIntRange hadoop__hdfs__datanode_idproto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__datanode_idproto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DatanodeIDProto",
  "DatanodeIDProto",
  "Hadoop__Hdfs__DatanodeIDProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__DatanodeIDProto),
  6,
  hadoop__hdfs__datanode_idproto__field_descriptors,
  hadoop__hdfs__datanode_idproto__field_indices_by_name,
  1,  hadoop__hdfs__datanode_idproto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__datanode_idproto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__datanode_infos_proto__field_descriptors[1] =
{
  {
    "datanodes",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfosProto, n_datanodes),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfosProto, datanodes),
    &hadoop__hdfs__datanode_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__datanode_infos_proto__field_indices_by_name[] = {
  0,   /* field[0] = datanodes */
};
static const ProtobufCIntRange hadoop__hdfs__datanode_infos_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__datanode_infos_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DatanodeInfosProto",
  "DatanodeInfosProto",
  "Hadoop__Hdfs__DatanodeInfosProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__DatanodeInfosProto),
  1,
  hadoop__hdfs__datanode_infos_proto__field_descriptors,
  hadoop__hdfs__datanode_infos_proto__field_indices_by_name,
  1,  hadoop__hdfs__datanode_infos_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__datanode_infos_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__hdfs__datanode_info_proto__admin_state__enum_values_by_number[3] =
{
  { "NORMAL", "HADOOP__HDFS__DATANODE_INFO_PROTO__ADMIN_STATE__NORMAL", 0 },
  { "DECOMMISSION_INPROGRESS", "HADOOP__HDFS__DATANODE_INFO_PROTO__ADMIN_STATE__DECOMMISSION_INPROGRESS", 1 },
  { "DECOMMISSIONED", "HADOOP__HDFS__DATANODE_INFO_PROTO__ADMIN_STATE__DECOMMISSIONED", 2 },
};
static const ProtobufCIntRange hadoop__hdfs__datanode_info_proto__admin_state__value_ranges[] = {
{0, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__hdfs__datanode_info_proto__admin_state__enum_values_by_name[3] =
{
  { "DECOMMISSIONED", 2 },
  { "DECOMMISSION_INPROGRESS", 1 },
  { "NORMAL", 0 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__datanode_info_proto__admin_state__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DatanodeInfoProto.AdminState",
  "AdminState",
  "Hadoop__Hdfs__DatanodeInfoProto__AdminState",
  "hadoop.hdfs",
  3,
  hadoop__hdfs__datanode_info_proto__admin_state__enum_values_by_number,
  3,
  hadoop__hdfs__datanode_info_proto__admin_state__enum_values_by_name,
  1,
  hadoop__hdfs__datanode_info_proto__admin_state__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
static const uint64_t hadoop__hdfs__datanode_info_proto__capacity__default_value = 0;
static const uint64_t hadoop__hdfs__datanode_info_proto__dfs_used__default_value = 0;
static const uint64_t hadoop__hdfs__datanode_info_proto__remaining__default_value = 0;
static const uint64_t hadoop__hdfs__datanode_info_proto__block_pool_used__default_value = 0;
static const uint64_t hadoop__hdfs__datanode_info_proto__last_update__default_value = 0;
static const uint32_t hadoop__hdfs__datanode_info_proto__xceiver_count__default_value = 0;
static const Hadoop__Hdfs__DatanodeInfoProto__AdminState hadoop__hdfs__datanode_info_proto__admin_state__default_value = HADOOP__HDFS__DATANODE_INFO_PROTO__ADMIN_STATE__NORMAL;
static const ProtobufCFieldDescriptor hadoop__hdfs__datanode_info_proto__field_descriptors[9] =
{
  {
    "id",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, id),
    &hadoop__hdfs__datanode_idproto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "capacity",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, has_capacity),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, capacity),
    NULL,
    &hadoop__hdfs__datanode_info_proto__capacity__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "dfsUsed",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, has_dfsused),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, dfsused),
    NULL,
    &hadoop__hdfs__datanode_info_proto__dfs_used__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "remaining",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, has_remaining),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, remaining),
    NULL,
    &hadoop__hdfs__datanode_info_proto__remaining__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blockPoolUsed",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, has_blockpoolused),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, blockpoolused),
    NULL,
    &hadoop__hdfs__datanode_info_proto__block_pool_used__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "lastUpdate",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, has_lastupdate),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, lastupdate),
    NULL,
    &hadoop__hdfs__datanode_info_proto__last_update__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "xceiverCount",
    7,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, has_xceivercount),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, xceivercount),
    NULL,
    &hadoop__hdfs__datanode_info_proto__xceiver_count__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "location",
    8,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, location),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "adminState",
    10,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, has_adminstate),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DatanodeInfoProto, adminstate),
    &hadoop__hdfs__datanode_info_proto__admin_state__descriptor,
    &hadoop__hdfs__datanode_info_proto__admin_state__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__datanode_info_proto__field_indices_by_name[] = {
  8,   /* field[8] = adminState */
  4,   /* field[4] = blockPoolUsed */
  1,   /* field[1] = capacity */
  2,   /* field[2] = dfsUsed */
  0,   /* field[0] = id */
  5,   /* field[5] = lastUpdate */
  7,   /* field[7] = location */
  3,   /* field[3] = remaining */
  6,   /* field[6] = xceiverCount */
};
static const ProtobufCIntRange hadoop__hdfs__datanode_info_proto__number_ranges[2 + 1] =
{
  { 1, 0 },
  { 10, 8 },
  { 0, 9 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__datanode_info_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DatanodeInfoProto",
  "DatanodeInfoProto",
  "Hadoop__Hdfs__DatanodeInfoProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__DatanodeInfoProto),
  9,
  hadoop__hdfs__datanode_info_proto__field_descriptors,
  hadoop__hdfs__datanode_info_proto__field_indices_by_name,
  2,  hadoop__hdfs__datanode_info_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__datanode_info_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__content_summary_proto__field_descriptors[6] =
{
  {
    "length",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ContentSummaryProto, length),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "fileCount",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ContentSummaryProto, filecount),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "directoryCount",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ContentSummaryProto, directorycount),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "quota",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ContentSummaryProto, quota),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "spaceConsumed",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ContentSummaryProto, spaceconsumed),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "spaceQuota",
    6,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ContentSummaryProto, spacequota),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__content_summary_proto__field_indices_by_name[] = {
  2,   /* field[2] = directoryCount */
  1,   /* field[1] = fileCount */
  0,   /* field[0] = length */
  3,   /* field[3] = quota */
  4,   /* field[4] = spaceConsumed */
  5,   /* field[5] = spaceQuota */
};
static const ProtobufCIntRange hadoop__hdfs__content_summary_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__content_summary_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ContentSummaryProto",
  "ContentSummaryProto",
  "Hadoop__Hdfs__ContentSummaryProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__ContentSummaryProto),
  6,
  hadoop__hdfs__content_summary_proto__field_descriptors,
  hadoop__hdfs__content_summary_proto__field_indices_by_name,
  1,  hadoop__hdfs__content_summary_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__content_summary_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__corrupt_file_blocks_proto__field_descriptors[2] =
{
  {
    "files",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_STRING,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CorruptFileBlocksProto, n_files),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CorruptFileBlocksProto, files),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "cookie",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CorruptFileBlocksProto, cookie),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__corrupt_file_blocks_proto__field_indices_by_name[] = {
  1,   /* field[1] = cookie */
  0,   /* field[0] = files */
};
static const ProtobufCIntRange hadoop__hdfs__corrupt_file_blocks_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__corrupt_file_blocks_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.CorruptFileBlocksProto",
  "CorruptFileBlocksProto",
  "Hadoop__Hdfs__CorruptFileBlocksProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__CorruptFileBlocksProto),
  2,
  hadoop__hdfs__corrupt_file_blocks_proto__field_descriptors,
  hadoop__hdfs__corrupt_file_blocks_proto__field_indices_by_name,
  1,  hadoop__hdfs__corrupt_file_blocks_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__corrupt_file_blocks_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__fs_permission_proto__field_descriptors[1] =
{
  {
    "perm",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsPermissionProto, perm),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__fs_permission_proto__field_indices_by_name[] = {
  0,   /* field[0] = perm */
};
static const ProtobufCIntRange hadoop__hdfs__fs_permission_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__fs_permission_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.FsPermissionProto",
  "FsPermissionProto",
  "Hadoop__Hdfs__FsPermissionProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__FsPermissionProto),
  1,
  hadoop__hdfs__fs_permission_proto__field_descriptors,
  hadoop__hdfs__fs_permission_proto__field_indices_by_name,
  1,  hadoop__hdfs__fs_permission_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__fs_permission_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__located_block_proto__field_descriptors[5] =
{
  {
    "b",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlockProto, b),
    &hadoop__hdfs__extended_block_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "offset",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlockProto, offset),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "locs",
    3,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlockProto, n_locs),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlockProto, locs),
    &hadoop__hdfs__datanode_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "corrupt",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BOOL,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlockProto, corrupt),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blockToken",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlockProto, blocktoken),
    &hadoop__common__token_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__located_block_proto__field_indices_by_name[] = {
  0,   /* field[0] = b */
  4,   /* field[4] = blockToken */
  3,   /* field[3] = corrupt */
  2,   /* field[2] = locs */
  1,   /* field[1] = offset */
};
static const ProtobufCIntRange hadoop__hdfs__located_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__located_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.LocatedBlockProto",
  "LocatedBlockProto",
  "Hadoop__Hdfs__LocatedBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__LocatedBlockProto),
  5,
  hadoop__hdfs__located_block_proto__field_descriptors,
  hadoop__hdfs__located_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__located_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__located_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__data_encryption_key_proto__field_descriptors[6] =
{
  {
    "keyId",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataEncryptionKeyProto, keyid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blockPoolId",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataEncryptionKeyProto, blockpoolid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "nonce",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataEncryptionKeyProto, nonce),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "encryptionKey",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataEncryptionKeyProto, encryptionkey),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "expiryDate",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataEncryptionKeyProto, expirydate),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "encryptionAlgorithm",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataEncryptionKeyProto, encryptionalgorithm),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__data_encryption_key_proto__field_indices_by_name[] = {
  1,   /* field[1] = blockPoolId */
  5,   /* field[5] = encryptionAlgorithm */
  3,   /* field[3] = encryptionKey */
  4,   /* field[4] = expiryDate */
  0,   /* field[0] = keyId */
  2,   /* field[2] = nonce */
};
static const ProtobufCIntRange hadoop__hdfs__data_encryption_key_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__data_encryption_key_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DataEncryptionKeyProto",
  "DataEncryptionKeyProto",
  "Hadoop__Hdfs__DataEncryptionKeyProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__DataEncryptionKeyProto),
  6,
  hadoop__hdfs__data_encryption_key_proto__field_descriptors,
  hadoop__hdfs__data_encryption_key_proto__field_indices_by_name,
  1,  hadoop__hdfs__data_encryption_key_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__data_encryption_key_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__located_blocks_proto__field_descriptors[5] =
{
  {
    "fileLength",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlocksProto, filelength),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blocks",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlocksProto, n_blocks),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlocksProto, blocks),
    &hadoop__hdfs__located_block_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "underConstruction",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BOOL,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlocksProto, underconstruction),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "lastBlock",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlocksProto, lastblock),
    &hadoop__hdfs__located_block_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "isLastBlockComplete",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BOOL,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__LocatedBlocksProto, islastblockcomplete),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__located_blocks_proto__field_indices_by_name[] = {
  1,   /* field[1] = blocks */
  0,   /* field[0] = fileLength */
  4,   /* field[4] = isLastBlockComplete */
  3,   /* field[3] = lastBlock */
  2,   /* field[2] = underConstruction */
};
static const ProtobufCIntRange hadoop__hdfs__located_blocks_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__located_blocks_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.LocatedBlocksProto",
  "LocatedBlocksProto",
  "Hadoop__Hdfs__LocatedBlocksProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__LocatedBlocksProto),
  5,
  hadoop__hdfs__located_blocks_proto__field_descriptors,
  hadoop__hdfs__located_blocks_proto__field_indices_by_name,
  1,  hadoop__hdfs__located_blocks_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__located_blocks_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__hdfs__hdfs_file_status_proto__file_type__enum_values_by_number[3] =
{
  { "IS_DIR", "HADOOP__HDFS__HDFS_FILE_STATUS_PROTO__FILE_TYPE__IS_DIR", 1 },
  { "IS_FILE", "HADOOP__HDFS__HDFS_FILE_STATUS_PROTO__FILE_TYPE__IS_FILE", 2 },
  { "IS_SYMLINK", "HADOOP__HDFS__HDFS_FILE_STATUS_PROTO__FILE_TYPE__IS_SYMLINK", 3 },
};
static const ProtobufCIntRange hadoop__hdfs__hdfs_file_status_proto__file_type__value_ranges[] = {
{1, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__hdfs__hdfs_file_status_proto__file_type__enum_values_by_name[3] =
{
  { "IS_DIR", 0 },
  { "IS_FILE", 1 },
  { "IS_SYMLINK", 2 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__hdfs_file_status_proto__file_type__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.HdfsFileStatusProto.FileType",
  "FileType",
  "Hadoop__Hdfs__HdfsFileStatusProto__FileType",
  "hadoop.hdfs",
  3,
  hadoop__hdfs__hdfs_file_status_proto__file_type__enum_values_by_number,
  3,
  hadoop__hdfs__hdfs_file_status_proto__file_type__enum_values_by_name,
  1,
  hadoop__hdfs__hdfs_file_status_proto__file_type__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
static const uint32_t hadoop__hdfs__hdfs_file_status_proto__block_replication__default_value = 0;
static const uint64_t hadoop__hdfs__hdfs_file_status_proto__blocksize__default_value = 0;
static const uint64_t hadoop__hdfs__hdfs_file_status_proto__file_id__default_value = 0;
static const uint32_t hadoop__hdfs__hdfs_file_status_proto__children_num__default_value = 0;
static const ProtobufCFieldDescriptor hadoop__hdfs__hdfs_file_status_proto__field_descriptors[14] =
{
  {
    "fileType",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, filetype),
    &hadoop__hdfs__hdfs_file_status_proto__file_type__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "path",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, path),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "length",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, length),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "permission",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, permission),
    &hadoop__hdfs__fs_permission_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "owner",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, owner),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "group",
    6,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, group),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "modification_time",
    7,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, modification_time),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "access_time",
    8,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, access_time),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "symlink",
    9,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BYTES,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, has_symlink),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, symlink),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "block_replication",
    10,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, has_block_replication),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, block_replication),
    NULL,
    &hadoop__hdfs__hdfs_file_status_proto__block_replication__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blocksize",
    11,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, has_blocksize),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, blocksize),
    NULL,
    &hadoop__hdfs__hdfs_file_status_proto__blocksize__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "locations",
    12,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, locations),
    &hadoop__hdfs__located_blocks_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "fileId",
    13,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, has_fileid),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, fileid),
    NULL,
    &hadoop__hdfs__hdfs_file_status_proto__file_id__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "childrenNum",
    14,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, has_childrennum),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__HdfsFileStatusProto, childrennum),
    NULL,
    &hadoop__hdfs__hdfs_file_status_proto__children_num__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__hdfs_file_status_proto__field_indices_by_name[] = {
  7,   /* field[7] = access_time */
  9,   /* field[9] = block_replication */
  10,   /* field[10] = blocksize */
  13,   /* field[13] = childrenNum */
  12,   /* field[12] = fileId */
  0,   /* field[0] = fileType */
  5,   /* field[5] = group */
  2,   /* field[2] = length */
  11,   /* field[11] = locations */
  6,   /* field[6] = modification_time */
  4,   /* field[4] = owner */
  1,   /* field[1] = path */
  3,   /* field[3] = permission */
  8,   /* field[8] = symlink */
};
static const ProtobufCIntRange hadoop__hdfs__hdfs_file_status_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 14 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__hdfs_file_status_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.HdfsFileStatusProto",
  "HdfsFileStatusProto",
  "Hadoop__Hdfs__HdfsFileStatusProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__HdfsFileStatusProto),
  14,
  hadoop__hdfs__hdfs_file_status_proto__field_descriptors,
  hadoop__hdfs__hdfs_file_status_proto__field_indices_by_name,
  1,  hadoop__hdfs__hdfs_file_status_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__hdfs_file_status_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const protobuf_c_boolean hadoop__hdfs__fs_server_defaults_proto__encrypt_data_transfer__default_value = 0;
static const uint64_t hadoop__hdfs__fs_server_defaults_proto__trash_interval__default_value = 0;
static const Hadoop__Hdfs__ChecksumTypeProto hadoop__hdfs__fs_server_defaults_proto__checksum_type__default_value = HADOOP__HDFS__CHECKSUM_TYPE_PROTO__CHECKSUM_CRC32;
static const ProtobufCFieldDescriptor hadoop__hdfs__fs_server_defaults_proto__field_descriptors[8] =
{
  {
    "blockSize",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, blocksize),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "bytesPerChecksum",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, bytesperchecksum),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "writePacketSize",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, writepacketsize),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "replication",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, replication),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "fileBufferSize",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, filebuffersize),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "encryptDataTransfer",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, has_encryptdatatransfer),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, encryptdatatransfer),
    NULL,
    &hadoop__hdfs__fs_server_defaults_proto__encrypt_data_transfer__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "trashInterval",
    7,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, has_trashinterval),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, trashinterval),
    NULL,
    &hadoop__hdfs__fs_server_defaults_proto__trash_interval__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "checksumType",
    8,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, has_checksumtype),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FsServerDefaultsProto, checksumtype),
    &hadoop__hdfs__checksum_type_proto__descriptor,
    &hadoop__hdfs__fs_server_defaults_proto__checksum_type__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__fs_server_defaults_proto__field_indices_by_name[] = {
  0,   /* field[0] = blockSize */
  1,   /* field[1] = bytesPerChecksum */
  7,   /* field[7] = checksumType */
  5,   /* field[5] = encryptDataTransfer */
  4,   /* field[4] = fileBufferSize */
  3,   /* field[3] = replication */
  6,   /* field[6] = trashInterval */
  2,   /* field[2] = writePacketSize */
};
static const ProtobufCIntRange hadoop__hdfs__fs_server_defaults_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 8 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__fs_server_defaults_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.FsServerDefaultsProto",
  "FsServerDefaultsProto",
  "Hadoop__Hdfs__FsServerDefaultsProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__FsServerDefaultsProto),
  8,
  hadoop__hdfs__fs_server_defaults_proto__field_descriptors,
  hadoop__hdfs__fs_server_defaults_proto__field_indices_by_name,
  1,  hadoop__hdfs__fs_server_defaults_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__fs_server_defaults_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__directory_listing_proto__field_descriptors[2] =
{
  {
    "partialListing",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DirectoryListingProto, n_partiallisting),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DirectoryListingProto, partiallisting),
    &hadoop__hdfs__hdfs_file_status_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "remainingEntries",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DirectoryListingProto, remainingentries),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__directory_listing_proto__field_indices_by_name[] = {
  0,   /* field[0] = partialListing */
  1,   /* field[1] = remainingEntries */
};
static const ProtobufCIntRange hadoop__hdfs__directory_listing_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__directory_listing_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DirectoryListingProto",
  "DirectoryListingProto",
  "Hadoop__Hdfs__DirectoryListingProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__DirectoryListingProto),
  2,
  hadoop__hdfs__directory_listing_proto__field_descriptors,
  hadoop__hdfs__directory_listing_proto__field_indices_by_name,
  1,  hadoop__hdfs__directory_listing_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__directory_listing_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__snapshottable_directory_status_proto__field_descriptors[4] =
{
  {
    "dirStatus",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshottableDirectoryStatusProto, dirstatus),
    &hadoop__hdfs__hdfs_file_status_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "snapshot_quota",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshottableDirectoryStatusProto, snapshot_quota),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "snapshot_number",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshottableDirectoryStatusProto, snapshot_number),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "parent_fullpath",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshottableDirectoryStatusProto, parent_fullpath),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__snapshottable_directory_status_proto__field_indices_by_name[] = {
  0,   /* field[0] = dirStatus */
  3,   /* field[3] = parent_fullpath */
  2,   /* field[2] = snapshot_number */
  1,   /* field[1] = snapshot_quota */
};
static const ProtobufCIntRange hadoop__hdfs__snapshottable_directory_status_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__snapshottable_directory_status_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.SnapshottableDirectoryStatusProto",
  "SnapshottableDirectoryStatusProto",
  "Hadoop__Hdfs__SnapshottableDirectoryStatusProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__SnapshottableDirectoryStatusProto),
  4,
  hadoop__hdfs__snapshottable_directory_status_proto__field_descriptors,
  hadoop__hdfs__snapshottable_directory_status_proto__field_indices_by_name,
  1,  hadoop__hdfs__snapshottable_directory_status_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__snapshottable_directory_status_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__snapshottable_directory_listing_proto__field_descriptors[1] =
{
  {
    "snapshottableDirListing",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshottableDirectoryListingProto, n_snapshottabledirlisting),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshottableDirectoryListingProto, snapshottabledirlisting),
    &hadoop__hdfs__snapshottable_directory_status_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__snapshottable_directory_listing_proto__field_indices_by_name[] = {
  0,   /* field[0] = snapshottableDirListing */
};
static const ProtobufCIntRange hadoop__hdfs__snapshottable_directory_listing_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__snapshottable_directory_listing_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.SnapshottableDirectoryListingProto",
  "SnapshottableDirectoryListingProto",
  "Hadoop__Hdfs__SnapshottableDirectoryListingProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__SnapshottableDirectoryListingProto),
  1,
  hadoop__hdfs__snapshottable_directory_listing_proto__field_descriptors,
  hadoop__hdfs__snapshottable_directory_listing_proto__field_indices_by_name,
  1,  hadoop__hdfs__snapshottable_directory_listing_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__snapshottable_directory_listing_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__snapshot_diff_report_entry_proto__field_descriptors[2] =
{
  {
    "fullpath",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotDiffReportEntryProto, fullpath),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "modificationLabel",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotDiffReportEntryProto, modificationlabel),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__snapshot_diff_report_entry_proto__field_indices_by_name[] = {
  0,   /* field[0] = fullpath */
  1,   /* field[1] = modificationLabel */
};
static const ProtobufCIntRange hadoop__hdfs__snapshot_diff_report_entry_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__snapshot_diff_report_entry_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.SnapshotDiffReportEntryProto",
  "SnapshotDiffReportEntryProto",
  "Hadoop__Hdfs__SnapshotDiffReportEntryProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__SnapshotDiffReportEntryProto),
  2,
  hadoop__hdfs__snapshot_diff_report_entry_proto__field_descriptors,
  hadoop__hdfs__snapshot_diff_report_entry_proto__field_indices_by_name,
  1,  hadoop__hdfs__snapshot_diff_report_entry_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__snapshot_diff_report_entry_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__snapshot_diff_report_proto__field_descriptors[4] =
{
  {
    "snapshotRoot",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotDiffReportProto, snapshotroot),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "fromSnapshot",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotDiffReportProto, fromsnapshot),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "toSnapshot",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotDiffReportProto, tosnapshot),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "diffReportEntries",
    4,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotDiffReportProto, n_diffreportentries),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotDiffReportProto, diffreportentries),
    &hadoop__hdfs__snapshot_diff_report_entry_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__snapshot_diff_report_proto__field_indices_by_name[] = {
  3,   /* field[3] = diffReportEntries */
  1,   /* field[1] = fromSnapshot */
  0,   /* field[0] = snapshotRoot */
  2,   /* field[2] = toSnapshot */
};
static const ProtobufCIntRange hadoop__hdfs__snapshot_diff_report_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__snapshot_diff_report_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.SnapshotDiffReportProto",
  "SnapshotDiffReportProto",
  "Hadoop__Hdfs__SnapshotDiffReportProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__SnapshotDiffReportProto),
  4,
  hadoop__hdfs__snapshot_diff_report_proto__field_descriptors,
  hadoop__hdfs__snapshot_diff_report_proto__field_indices_by_name,
  1,  hadoop__hdfs__snapshot_diff_report_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__snapshot_diff_report_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__storage_info_proto__field_descriptors[4] =
{
  {
    "layoutVersion",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__StorageInfoProto, layoutversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "namespceID",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__StorageInfoProto, namespceid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "clusterID",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__StorageInfoProto, clusterid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "cTime",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__StorageInfoProto, ctime),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__storage_info_proto__field_indices_by_name[] = {
  3,   /* field[3] = cTime */
  2,   /* field[2] = clusterID */
  0,   /* field[0] = layoutVersion */
  1,   /* field[1] = namespceID */
};
static const ProtobufCIntRange hadoop__hdfs__storage_info_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__storage_info_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.StorageInfoProto",
  "StorageInfoProto",
  "Hadoop__Hdfs__StorageInfoProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__StorageInfoProto),
  4,
  hadoop__hdfs__storage_info_proto__field_descriptors,
  hadoop__hdfs__storage_info_proto__field_indices_by_name,
  1,  hadoop__hdfs__storage_info_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__storage_info_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__hdfs__namenode_registration_proto__namenode_role_proto__enum_values_by_number[3] =
{
  { "NAMENODE", "HADOOP__HDFS__NAMENODE_REGISTRATION_PROTO__NAMENODE_ROLE_PROTO__NAMENODE", 1 },
  { "BACKUP", "HADOOP__HDFS__NAMENODE_REGISTRATION_PROTO__NAMENODE_ROLE_PROTO__BACKUP", 2 },
  { "CHECKPOINT", "HADOOP__HDFS__NAMENODE_REGISTRATION_PROTO__NAMENODE_ROLE_PROTO__CHECKPOINT", 3 },
};
static const ProtobufCIntRange hadoop__hdfs__namenode_registration_proto__namenode_role_proto__value_ranges[] = {
{1, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__hdfs__namenode_registration_proto__namenode_role_proto__enum_values_by_name[3] =
{
  { "BACKUP", 1 },
  { "CHECKPOINT", 2 },
  { "NAMENODE", 0 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__namenode_registration_proto__namenode_role_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.NamenodeRegistrationProto.NamenodeRoleProto",
  "NamenodeRoleProto",
  "Hadoop__Hdfs__NamenodeRegistrationProto__NamenodeRoleProto",
  "hadoop.hdfs",
  3,
  hadoop__hdfs__namenode_registration_proto__namenode_role_proto__enum_values_by_number,
  3,
  hadoop__hdfs__namenode_registration_proto__namenode_role_proto__enum_values_by_name,
  1,
  hadoop__hdfs__namenode_registration_proto__namenode_role_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
static const Hadoop__Hdfs__NamenodeRegistrationProto__NamenodeRoleProto hadoop__hdfs__namenode_registration_proto__role__default_value = HADOOP__HDFS__NAMENODE_REGISTRATION_PROTO__NAMENODE_ROLE_PROTO__NAMENODE;
static const ProtobufCFieldDescriptor hadoop__hdfs__namenode_registration_proto__field_descriptors[4] =
{
  {
    "rpcAddress",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeRegistrationProto, rpcaddress),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "httpAddress",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeRegistrationProto, httpaddress),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "storageInfo",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeRegistrationProto, storageinfo),
    &hadoop__hdfs__storage_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "role",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeRegistrationProto, has_role),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeRegistrationProto, role),
    &hadoop__hdfs__namenode_registration_proto__namenode_role_proto__descriptor,
    &hadoop__hdfs__namenode_registration_proto__role__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__namenode_registration_proto__field_indices_by_name[] = {
  1,   /* field[1] = httpAddress */
  3,   /* field[3] = role */
  0,   /* field[0] = rpcAddress */
  2,   /* field[2] = storageInfo */
};
static const ProtobufCIntRange hadoop__hdfs__namenode_registration_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__namenode_registration_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.NamenodeRegistrationProto",
  "NamenodeRegistrationProto",
  "Hadoop__Hdfs__NamenodeRegistrationProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__NamenodeRegistrationProto),
  4,
  hadoop__hdfs__namenode_registration_proto__field_descriptors,
  hadoop__hdfs__namenode_registration_proto__field_indices_by_name,
  1,  hadoop__hdfs__namenode_registration_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__namenode_registration_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__checkpoint_signature_proto__field_descriptors[4] =
{
  {
    "blockPoolId",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CheckpointSignatureProto, blockpoolid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "mostRecentCheckpointTxId",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CheckpointSignatureProto, mostrecentcheckpointtxid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "curSegmentTxId",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CheckpointSignatureProto, cursegmenttxid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "storageInfo",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CheckpointSignatureProto, storageinfo),
    &hadoop__hdfs__storage_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__checkpoint_signature_proto__field_indices_by_name[] = {
  0,   /* field[0] = blockPoolId */
  2,   /* field[2] = curSegmentTxId */
  1,   /* field[1] = mostRecentCheckpointTxId */
  3,   /* field[3] = storageInfo */
};
static const ProtobufCIntRange hadoop__hdfs__checkpoint_signature_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__checkpoint_signature_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.CheckpointSignatureProto",
  "CheckpointSignatureProto",
  "Hadoop__Hdfs__CheckpointSignatureProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__CheckpointSignatureProto),
  4,
  hadoop__hdfs__checkpoint_signature_proto__field_descriptors,
  hadoop__hdfs__checkpoint_signature_proto__field_indices_by_name,
  1,  hadoop__hdfs__checkpoint_signature_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__checkpoint_signature_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__hdfs__namenode_command_proto__type__enum_values_by_number[2] =
{
  { "NamenodeCommand", "HADOOP__HDFS__NAMENODE_COMMAND_PROTO__TYPE__NAMENODECOMMAND", 0 },
  { "CheckPointCommand", "HADOOP__HDFS__NAMENODE_COMMAND_PROTO__TYPE__CHECKPOINTCOMMAND", 1 },
};
static const ProtobufCIntRange hadoop__hdfs__namenode_command_proto__type__value_ranges[] = {
{0, 0},{0, 2}
};
const ProtobufCEnumValueIndex hadoop__hdfs__namenode_command_proto__type__enum_values_by_name[2] =
{
  { "CheckPointCommand", 1 },
  { "NamenodeCommand", 0 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__namenode_command_proto__type__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.NamenodeCommandProto.Type",
  "Type",
  "Hadoop__Hdfs__NamenodeCommandProto__Type",
  "hadoop.hdfs",
  2,
  hadoop__hdfs__namenode_command_proto__type__enum_values_by_number,
  2,
  hadoop__hdfs__namenode_command_proto__type__enum_values_by_name,
  1,
  hadoop__hdfs__namenode_command_proto__type__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__namenode_command_proto__field_descriptors[3] =
{
  {
    "action",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeCommandProto, action),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "type",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeCommandProto, type),
    &hadoop__hdfs__namenode_command_proto__type__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "checkpointCmd",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamenodeCommandProto, checkpointcmd),
    &hadoop__hdfs__checkpoint_command_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__namenode_command_proto__field_indices_by_name[] = {
  0,   /* field[0] = action */
  2,   /* field[2] = checkpointCmd */
  1,   /* field[1] = type */
};
static const ProtobufCIntRange hadoop__hdfs__namenode_command_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__namenode_command_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.NamenodeCommandProto",
  "NamenodeCommandProto",
  "Hadoop__Hdfs__NamenodeCommandProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__NamenodeCommandProto),
  3,
  hadoop__hdfs__namenode_command_proto__field_descriptors,
  hadoop__hdfs__namenode_command_proto__field_indices_by_name,
  1,  hadoop__hdfs__namenode_command_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__namenode_command_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__checkpoint_command_proto__field_descriptors[2] =
{
  {
    "signature",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CheckpointCommandProto, signature),
    &hadoop__hdfs__checkpoint_signature_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "needToReturnImage",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BOOL,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CheckpointCommandProto, needtoreturnimage),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__checkpoint_command_proto__field_indices_by_name[] = {
  1,   /* field[1] = needToReturnImage */
  0,   /* field[0] = signature */
};
static const ProtobufCIntRange hadoop__hdfs__checkpoint_command_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__checkpoint_command_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.CheckpointCommandProto",
  "CheckpointCommandProto",
  "Hadoop__Hdfs__CheckpointCommandProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__CheckpointCommandProto),
  2,
  hadoop__hdfs__checkpoint_command_proto__field_descriptors,
  hadoop__hdfs__checkpoint_command_proto__field_indices_by_name,
  1,  hadoop__hdfs__checkpoint_command_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__checkpoint_command_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const uint64_t hadoop__hdfs__block_proto__num_bytes__default_value = 0;
static const ProtobufCFieldDescriptor hadoop__hdfs__block_proto__field_descriptors[3] =
{
  {
    "blockId",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockProto, blockid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "genStamp",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockProto, genstamp),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "numBytes",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockProto, has_numbytes),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockProto, numbytes),
    NULL,
    &hadoop__hdfs__block_proto__num_bytes__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__block_proto__field_indices_by_name[] = {
  0,   /* field[0] = blockId */
  1,   /* field[1] = genStamp */
  2,   /* field[2] = numBytes */
};
static const ProtobufCIntRange hadoop__hdfs__block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.BlockProto",
  "BlockProto",
  "Hadoop__Hdfs__BlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__BlockProto),
  3,
  hadoop__hdfs__block_proto__field_descriptors,
  hadoop__hdfs__block_proto__field_indices_by_name,
  1,  hadoop__hdfs__block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__block_with_locations_proto__field_descriptors[2] =
{
  {
    "block",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockWithLocationsProto, block),
    &hadoop__hdfs__block_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "storageIDs",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_STRING,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockWithLocationsProto, n_storageids),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockWithLocationsProto, storageids),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__block_with_locations_proto__field_indices_by_name[] = {
  0,   /* field[0] = block */
  1,   /* field[1] = storageIDs */
};
static const ProtobufCIntRange hadoop__hdfs__block_with_locations_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__block_with_locations_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.BlockWithLocationsProto",
  "BlockWithLocationsProto",
  "Hadoop__Hdfs__BlockWithLocationsProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__BlockWithLocationsProto),
  2,
  hadoop__hdfs__block_with_locations_proto__field_descriptors,
  hadoop__hdfs__block_with_locations_proto__field_indices_by_name,
  1,  hadoop__hdfs__block_with_locations_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__block_with_locations_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__blocks_with_locations_proto__field_descriptors[1] =
{
  {
    "blocks",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlocksWithLocationsProto, n_blocks),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlocksWithLocationsProto, blocks),
    &hadoop__hdfs__block_with_locations_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__blocks_with_locations_proto__field_indices_by_name[] = {
  0,   /* field[0] = blocks */
};
static const ProtobufCIntRange hadoop__hdfs__blocks_with_locations_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__blocks_with_locations_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.BlocksWithLocationsProto",
  "BlocksWithLocationsProto",
  "Hadoop__Hdfs__BlocksWithLocationsProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__BlocksWithLocationsProto),
  1,
  hadoop__hdfs__blocks_with_locations_proto__field_descriptors,
  hadoop__hdfs__blocks_with_locations_proto__field_indices_by_name,
  1,  hadoop__hdfs__blocks_with_locations_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__blocks_with_locations_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const protobuf_c_boolean hadoop__hdfs__remote_edit_log_proto__is_in_progress__default_value = 0;
static const ProtobufCFieldDescriptor hadoop__hdfs__remote_edit_log_proto__field_descriptors[3] =
{
  {
    "startTxId",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RemoteEditLogProto, starttxid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "endTxId",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RemoteEditLogProto, endtxid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "isInProgress",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RemoteEditLogProto, has_isinprogress),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RemoteEditLogProto, isinprogress),
    NULL,
    &hadoop__hdfs__remote_edit_log_proto__is_in_progress__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__remote_edit_log_proto__field_indices_by_name[] = {
  1,   /* field[1] = endTxId */
  2,   /* field[2] = isInProgress */
  0,   /* field[0] = startTxId */
};
static const ProtobufCIntRange hadoop__hdfs__remote_edit_log_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__remote_edit_log_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.RemoteEditLogProto",
  "RemoteEditLogProto",
  "Hadoop__Hdfs__RemoteEditLogProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__RemoteEditLogProto),
  3,
  hadoop__hdfs__remote_edit_log_proto__field_descriptors,
  hadoop__hdfs__remote_edit_log_proto__field_indices_by_name,
  1,  hadoop__hdfs__remote_edit_log_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__remote_edit_log_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__remote_edit_log_manifest_proto__field_descriptors[1] =
{
  {
    "logs",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RemoteEditLogManifestProto, n_logs),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RemoteEditLogManifestProto, logs),
    &hadoop__hdfs__remote_edit_log_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__remote_edit_log_manifest_proto__field_indices_by_name[] = {
  0,   /* field[0] = logs */
};
static const ProtobufCIntRange hadoop__hdfs__remote_edit_log_manifest_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__remote_edit_log_manifest_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.RemoteEditLogManifestProto",
  "RemoteEditLogManifestProto",
  "Hadoop__Hdfs__RemoteEditLogManifestProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__RemoteEditLogManifestProto),
  1,
  hadoop__hdfs__remote_edit_log_manifest_proto__field_descriptors,
  hadoop__hdfs__remote_edit_log_manifest_proto__field_indices_by_name,
  1,  hadoop__hdfs__remote_edit_log_manifest_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__remote_edit_log_manifest_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__namespace_info_proto__field_descriptors[5] =
{
  {
    "buildVersion",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamespaceInfoProto, buildversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "unused",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamespaceInfoProto, unused),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "blockPoolID",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamespaceInfoProto, blockpoolid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "storageInfo",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamespaceInfoProto, storageinfo),
    &hadoop__hdfs__storage_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "softwareVersion",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__NamespaceInfoProto, softwareversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__namespace_info_proto__field_indices_by_name[] = {
  2,   /* field[2] = blockPoolID */
  0,   /* field[0] = buildVersion */
  4,   /* field[4] = softwareVersion */
  3,   /* field[3] = storageInfo */
  1,   /* field[1] = unused */
};
static const ProtobufCIntRange hadoop__hdfs__namespace_info_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__namespace_info_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.NamespaceInfoProto",
  "NamespaceInfoProto",
  "Hadoop__Hdfs__NamespaceInfoProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__NamespaceInfoProto),
  5,
  hadoop__hdfs__namespace_info_proto__field_descriptors,
  hadoop__hdfs__namespace_info_proto__field_indices_by_name,
  1,  hadoop__hdfs__namespace_info_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__namespace_info_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__block_key_proto__field_descriptors[3] =
{
  {
    "keyId",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockKeyProto, keyid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "expiryDate",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockKeyProto, expirydate),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "keyBytes",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BYTES,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockKeyProto, has_keybytes),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockKeyProto, keybytes),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__block_key_proto__field_indices_by_name[] = {
  1,   /* field[1] = expiryDate */
  2,   /* field[2] = keyBytes */
  0,   /* field[0] = keyId */
};
static const ProtobufCIntRange hadoop__hdfs__block_key_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__block_key_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.BlockKeyProto",
  "BlockKeyProto",
  "Hadoop__Hdfs__BlockKeyProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__BlockKeyProto),
  3,
  hadoop__hdfs__block_key_proto__field_descriptors,
  hadoop__hdfs__block_key_proto__field_indices_by_name,
  1,  hadoop__hdfs__block_key_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__block_key_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__exported_block_keys_proto__field_descriptors[5] =
{
  {
    "isBlockTokenEnabled",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BOOL,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExportedBlockKeysProto, isblocktokenenabled),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "keyUpdateInterval",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExportedBlockKeysProto, keyupdateinterval),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "tokenLifeTime",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExportedBlockKeysProto, tokenlifetime),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "currentKey",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExportedBlockKeysProto, currentkey),
    &hadoop__hdfs__block_key_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "allKeys",
    5,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExportedBlockKeysProto, n_allkeys),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ExportedBlockKeysProto, allkeys),
    &hadoop__hdfs__block_key_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__exported_block_keys_proto__field_indices_by_name[] = {
  4,   /* field[4] = allKeys */
  3,   /* field[3] = currentKey */
  0,   /* field[0] = isBlockTokenEnabled */
  1,   /* field[1] = keyUpdateInterval */
  2,   /* field[2] = tokenLifeTime */
};
static const ProtobufCIntRange hadoop__hdfs__exported_block_keys_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__exported_block_keys_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ExportedBlockKeysProto",
  "ExportedBlockKeysProto",
  "Hadoop__Hdfs__ExportedBlockKeysProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__ExportedBlockKeysProto),
  5,
  hadoop__hdfs__exported_block_keys_proto__field_descriptors,
  hadoop__hdfs__exported_block_keys_proto__field_indices_by_name,
  1,  hadoop__hdfs__exported_block_keys_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__exported_block_keys_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__recovering_block_proto__field_descriptors[2] =
{
  {
    "newGenStamp",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RecoveringBlockProto, newgenstamp),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "block",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__RecoveringBlockProto, block),
    &hadoop__hdfs__located_block_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__recovering_block_proto__field_indices_by_name[] = {
  1,   /* field[1] = block */
  0,   /* field[0] = newGenStamp */
};
static const ProtobufCIntRange hadoop__hdfs__recovering_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__recovering_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.RecoveringBlockProto",
  "RecoveringBlockProto",
  "Hadoop__Hdfs__RecoveringBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__RecoveringBlockProto),
  2,
  hadoop__hdfs__recovering_block_proto__field_descriptors,
  hadoop__hdfs__recovering_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__recovering_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__recovering_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
#define hadoop__hdfs__version_request_proto__field_descriptors NULL
#define hadoop__hdfs__version_request_proto__field_indices_by_name NULL
#define hadoop__hdfs__version_request_proto__number_ranges NULL
const ProtobufCMessageDescriptor hadoop__hdfs__version_request_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.VersionRequestProto",
  "VersionRequestProto",
  "Hadoop__Hdfs__VersionRequestProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__VersionRequestProto),
  0,
  hadoop__hdfs__version_request_proto__field_descriptors,
  hadoop__hdfs__version_request_proto__field_indices_by_name,
  0,  hadoop__hdfs__version_request_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__version_request_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__version_response_proto__field_descriptors[1] =
{
  {
    "info",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__VersionResponseProto, info),
    &hadoop__hdfs__namespace_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__version_response_proto__field_indices_by_name[] = {
  0,   /* field[0] = info */
};
static const ProtobufCIntRange hadoop__hdfs__version_response_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__version_response_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.VersionResponseProto",
  "VersionResponseProto",
  "Hadoop__Hdfs__VersionResponseProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__VersionResponseProto),
  1,
  hadoop__hdfs__version_response_proto__field_descriptors,
  hadoop__hdfs__version_response_proto__field_indices_by_name,
  1,  hadoop__hdfs__version_response_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__version_response_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__snapshot_info_proto__field_descriptors[6] =
{
  {
    "snapshotName",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotInfoProto, snapshotname),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "snapshotRoot",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotInfoProto, snapshotroot),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "permission",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotInfoProto, permission),
    &hadoop__hdfs__fs_permission_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "owner",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotInfoProto, owner),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "group",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotInfoProto, group),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "createTime",
    6,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__SnapshotInfoProto, createtime),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__snapshot_info_proto__field_indices_by_name[] = {
  5,   /* field[5] = createTime */
  4,   /* field[4] = group */
  3,   /* field[3] = owner */
  2,   /* field[2] = permission */
  0,   /* field[0] = snapshotName */
  1,   /* field[1] = snapshotRoot */
};
static const ProtobufCIntRange hadoop__hdfs__snapshot_info_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__snapshot_info_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.SnapshotInfoProto",
  "SnapshotInfoProto",
  "Hadoop__Hdfs__SnapshotInfoProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__SnapshotInfoProto),
  6,
  hadoop__hdfs__snapshot_info_proto__field_descriptors,
  hadoop__hdfs__snapshot_info_proto__field_indices_by_name,
  1,  hadoop__hdfs__snapshot_info_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__snapshot_info_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__hdfs__checksum_type_proto__enum_values_by_number[3] =
{
  { "CHECKSUM_NULL", "HADOOP__HDFS__CHECKSUM_TYPE_PROTO__CHECKSUM_NULL", 0 },
  { "CHECKSUM_CRC32", "HADOOP__HDFS__CHECKSUM_TYPE_PROTO__CHECKSUM_CRC32", 1 },
  { "CHECKSUM_CRC32C", "HADOOP__HDFS__CHECKSUM_TYPE_PROTO__CHECKSUM_CRC32C", 2 },
};
static const ProtobufCIntRange hadoop__hdfs__checksum_type_proto__value_ranges[] = {
{0, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__hdfs__checksum_type_proto__enum_values_by_name[3] =
{
  { "CHECKSUM_CRC32", 1 },
  { "CHECKSUM_CRC32C", 2 },
  { "CHECKSUM_NULL", 0 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__checksum_type_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ChecksumTypeProto",
  "ChecksumTypeProto",
  "Hadoop__Hdfs__ChecksumTypeProto",
  "hadoop.hdfs",
  3,
  hadoop__hdfs__checksum_type_proto__enum_values_by_number,
  3,
  hadoop__hdfs__checksum_type_proto__enum_values_by_name,
  1,
  hadoop__hdfs__checksum_type_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
const ProtobufCEnumValue hadoop__hdfs__replica_state_proto__enum_values_by_number[5] =
{
  { "FINALIZED", "HADOOP__HDFS__REPLICA_STATE_PROTO__FINALIZED", 0 },
  { "RBW", "HADOOP__HDFS__REPLICA_STATE_PROTO__RBW", 1 },
  { "RWR", "HADOOP__HDFS__REPLICA_STATE_PROTO__RWR", 2 },
  { "RUR", "HADOOP__HDFS__REPLICA_STATE_PROTO__RUR", 3 },
  { "TEMPORARY", "HADOOP__HDFS__REPLICA_STATE_PROTO__TEMPORARY", 4 },
};
static const ProtobufCIntRange hadoop__hdfs__replica_state_proto__value_ranges[] = {
{0, 0},{0, 5}
};
const ProtobufCEnumValueIndex hadoop__hdfs__replica_state_proto__enum_values_by_name[5] =
{
  { "FINALIZED", 0 },
  { "RBW", 1 },
  { "RUR", 3 },
  { "RWR", 2 },
  { "TEMPORARY", 4 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__replica_state_proto__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ReplicaStateProto",
  "ReplicaStateProto",
  "Hadoop__Hdfs__ReplicaStateProto",
  "hadoop.hdfs",
  5,
  hadoop__hdfs__replica_state_proto__enum_values_by_number,
  5,
  hadoop__hdfs__replica_state_proto__enum_values_by_name,
  1,
  hadoop__hdfs__replica_state_proto__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
