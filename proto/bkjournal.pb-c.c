/* Generated by the protocol buffer compiler.  DO NOT EDIT! */

/* Do not generate deprecated warnings for self */
#ifndef PROTOBUF_C_NO_DEPRECATED
#define PROTOBUF_C_NO_DEPRECATED
#endif

#include "bkjournal.pb-c.h"
void   hadoop__hdfs__version_proto__init
                     (Hadoop__Hdfs__VersionProto         *message)
{
  static Hadoop__Hdfs__VersionProto init_value = HADOOP__HDFS__VERSION_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__version_proto__get_packed_size
                     (const Hadoop__Hdfs__VersionProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__version_proto__pack
                     (const Hadoop__Hdfs__VersionProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__version_proto__pack_to_buffer
                     (const Hadoop__Hdfs__VersionProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__VersionProto *
       hadoop__hdfs__version_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__VersionProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__version_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__version_proto__free_unpacked
                     (Hadoop__Hdfs__VersionProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__version_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__edit_log_ledger_proto__init
                     (Hadoop__Hdfs__EditLogLedgerProto         *message)
{
  static Hadoop__Hdfs__EditLogLedgerProto init_value = HADOOP__HDFS__EDIT_LOG_LEDGER_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__edit_log_ledger_proto__get_packed_size
                     (const Hadoop__Hdfs__EditLogLedgerProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__edit_log_ledger_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__edit_log_ledger_proto__pack
                     (const Hadoop__Hdfs__EditLogLedgerProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__edit_log_ledger_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__edit_log_ledger_proto__pack_to_buffer
                     (const Hadoop__Hdfs__EditLogLedgerProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__edit_log_ledger_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__EditLogLedgerProto *
       hadoop__hdfs__edit_log_ledger_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__EditLogLedgerProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__edit_log_ledger_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__edit_log_ledger_proto__free_unpacked
                     (Hadoop__Hdfs__EditLogLedgerProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__edit_log_ledger_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__max_tx_id_proto__init
                     (Hadoop__Hdfs__MaxTxIdProto         *message)
{
  static Hadoop__Hdfs__MaxTxIdProto init_value = HADOOP__HDFS__MAX_TX_ID_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__max_tx_id_proto__get_packed_size
                     (const Hadoop__Hdfs__MaxTxIdProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__max_tx_id_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__max_tx_id_proto__pack
                     (const Hadoop__Hdfs__MaxTxIdProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__max_tx_id_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__max_tx_id_proto__pack_to_buffer
                     (const Hadoop__Hdfs__MaxTxIdProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__max_tx_id_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__MaxTxIdProto *
       hadoop__hdfs__max_tx_id_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__MaxTxIdProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__max_tx_id_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__max_tx_id_proto__free_unpacked
                     (Hadoop__Hdfs__MaxTxIdProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__max_tx_id_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__current_inprogress_proto__init
                     (Hadoop__Hdfs__CurrentInprogressProto         *message)
{
  static Hadoop__Hdfs__CurrentInprogressProto init_value = HADOOP__HDFS__CURRENT_INPROGRESS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__current_inprogress_proto__get_packed_size
                     (const Hadoop__Hdfs__CurrentInprogressProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__current_inprogress_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__current_inprogress_proto__pack
                     (const Hadoop__Hdfs__CurrentInprogressProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__current_inprogress_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__current_inprogress_proto__pack_to_buffer
                     (const Hadoop__Hdfs__CurrentInprogressProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__current_inprogress_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__CurrentInprogressProto *
       hadoop__hdfs__current_inprogress_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__CurrentInprogressProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__current_inprogress_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__current_inprogress_proto__free_unpacked
                     (Hadoop__Hdfs__CurrentInprogressProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__current_inprogress_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
static const ProtobufCFieldDescriptor hadoop__hdfs__version_proto__field_descriptors[2] =
{
  {
    "layoutVersion",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_INT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__VersionProto, layoutversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "namespaceInfo",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__VersionProto, namespaceinfo),
    &hadoop__hdfs__namespace_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__version_proto__field_indices_by_name[] = {
  0,   /* field[0] = layoutVersion */
  1,   /* field[1] = namespaceInfo */
};
static const ProtobufCIntRange hadoop__hdfs__version_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__version_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.VersionProto",
  "VersionProto",
  "Hadoop__Hdfs__VersionProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__VersionProto),
  2,
  hadoop__hdfs__version_proto__field_descriptors,
  hadoop__hdfs__version_proto__field_indices_by_name,
  1,  hadoop__hdfs__version_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__version_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__edit_log_ledger_proto__field_descriptors[4] =
{
  {
    "dataLayoutVersion",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_INT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__EditLogLedgerProto, datalayoutversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "ledgerId",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__EditLogLedgerProto, ledgerid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "firstTxId",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__EditLogLedgerProto, firsttxid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "lastTxId",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_INT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__EditLogLedgerProto, has_lasttxid),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__EditLogLedgerProto, lasttxid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__edit_log_ledger_proto__field_indices_by_name[] = {
  0,   /* field[0] = dataLayoutVersion */
  2,   /* field[2] = firstTxId */
  3,   /* field[3] = lastTxId */
  1,   /* field[1] = ledgerId */
};
static const ProtobufCIntRange hadoop__hdfs__edit_log_ledger_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__edit_log_ledger_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.EditLogLedgerProto",
  "EditLogLedgerProto",
  "Hadoop__Hdfs__EditLogLedgerProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__EditLogLedgerProto),
  4,
  hadoop__hdfs__edit_log_ledger_proto__field_descriptors,
  hadoop__hdfs__edit_log_ledger_proto__field_indices_by_name,
  1,  hadoop__hdfs__edit_log_ledger_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__edit_log_ledger_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__max_tx_id_proto__field_descriptors[1] =
{
  {
    "txId",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__MaxTxIdProto, txid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__max_tx_id_proto__field_indices_by_name[] = {
  0,   /* field[0] = txId */
};
static const ProtobufCIntRange hadoop__hdfs__max_tx_id_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__max_tx_id_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.MaxTxIdProto",
  "MaxTxIdProto",
  "Hadoop__Hdfs__MaxTxIdProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__MaxTxIdProto),
  1,
  hadoop__hdfs__max_tx_id_proto__field_descriptors,
  hadoop__hdfs__max_tx_id_proto__field_indices_by_name,
  1,  hadoop__hdfs__max_tx_id_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__max_tx_id_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__current_inprogress_proto__field_descriptors[2] =
{
  {
    "path",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CurrentInprogressProto, path),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "hostname",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__CurrentInprogressProto, hostname),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__current_inprogress_proto__field_indices_by_name[] = {
  1,   /* field[1] = hostname */
  0,   /* field[0] = path */
};
static const ProtobufCIntRange hadoop__hdfs__current_inprogress_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__current_inprogress_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.CurrentInprogressProto",
  "CurrentInprogressProto",
  "Hadoop__Hdfs__CurrentInprogressProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__CurrentInprogressProto),
  2,
  hadoop__hdfs__current_inprogress_proto__field_descriptors,
  hadoop__hdfs__current_inprogress_proto__field_indices_by_name,
  1,  hadoop__hdfs__current_inprogress_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__current_inprogress_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
