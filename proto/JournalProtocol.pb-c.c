/* Generated by the protocol buffer compiler.  DO NOT EDIT! */

/* Do not generate deprecated warnings for self */
#ifndef PROTOBUF_C_NO_DEPRECATED
#define PROTOBUF_C_NO_DEPRECATED
#endif

#include "JournalProtocol.pb-c.h"
void   hadoop__hdfs__journal_info_proto__init
                     (Hadoop__Hdfs__JournalInfoProto         *message)
{
  static Hadoop__Hdfs__JournalInfoProto init_value = HADOOP__HDFS__JOURNAL_INFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__journal_info_proto__get_packed_size
                     (const Hadoop__Hdfs__JournalInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_info_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__journal_info_proto__pack
                     (const Hadoop__Hdfs__JournalInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_info_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__journal_info_proto__pack_to_buffer
                     (const Hadoop__Hdfs__JournalInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_info_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__JournalInfoProto *
       hadoop__hdfs__journal_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__JournalInfoProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__journal_info_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__journal_info_proto__free_unpacked
                     (Hadoop__Hdfs__JournalInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_info_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__journal_request_proto__init
                     (Hadoop__Hdfs__JournalRequestProto         *message)
{
  static Hadoop__Hdfs__JournalRequestProto init_value = HADOOP__HDFS__JOURNAL_REQUEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__journal_request_proto__get_packed_size
                     (const Hadoop__Hdfs__JournalRequestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_request_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__journal_request_proto__pack
                     (const Hadoop__Hdfs__JournalRequestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_request_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__journal_request_proto__pack_to_buffer
                     (const Hadoop__Hdfs__JournalRequestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_request_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__JournalRequestProto *
       hadoop__hdfs__journal_request_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__JournalRequestProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__journal_request_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__journal_request_proto__free_unpacked
                     (Hadoop__Hdfs__JournalRequestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_request_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__journal_response_proto__init
                     (Hadoop__Hdfs__JournalResponseProto         *message)
{
  static Hadoop__Hdfs__JournalResponseProto init_value = HADOOP__HDFS__JOURNAL_RESPONSE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__journal_response_proto__get_packed_size
                     (const Hadoop__Hdfs__JournalResponseProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_response_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__journal_response_proto__pack
                     (const Hadoop__Hdfs__JournalResponseProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_response_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__journal_response_proto__pack_to_buffer
                     (const Hadoop__Hdfs__JournalResponseProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_response_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__JournalResponseProto *
       hadoop__hdfs__journal_response_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__JournalResponseProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__journal_response_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__journal_response_proto__free_unpacked
                     (Hadoop__Hdfs__JournalResponseProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__journal_response_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__start_log_segment_request_proto__init
                     (Hadoop__Hdfs__StartLogSegmentRequestProto         *message)
{
  static Hadoop__Hdfs__StartLogSegmentRequestProto init_value = HADOOP__HDFS__START_LOG_SEGMENT_REQUEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__start_log_segment_request_proto__get_packed_size
                     (const Hadoop__Hdfs__StartLogSegmentRequestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_request_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__start_log_segment_request_proto__pack
                     (const Hadoop__Hdfs__StartLogSegmentRequestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_request_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__start_log_segment_request_proto__pack_to_buffer
                     (const Hadoop__Hdfs__StartLogSegmentRequestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_request_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__StartLogSegmentRequestProto *
       hadoop__hdfs__start_log_segment_request_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__StartLogSegmentRequestProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__start_log_segment_request_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__start_log_segment_request_proto__free_unpacked
                     (Hadoop__Hdfs__StartLogSegmentRequestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_request_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__start_log_segment_response_proto__init
                     (Hadoop__Hdfs__StartLogSegmentResponseProto         *message)
{
  static Hadoop__Hdfs__StartLogSegmentResponseProto init_value = HADOOP__HDFS__START_LOG_SEGMENT_RESPONSE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__start_log_segment_response_proto__get_packed_size
                     (const Hadoop__Hdfs__StartLogSegmentResponseProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_response_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__start_log_segment_response_proto__pack
                     (const Hadoop__Hdfs__StartLogSegmentResponseProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_response_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__start_log_segment_response_proto__pack_to_buffer
                     (const Hadoop__Hdfs__StartLogSegmentResponseProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_response_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__StartLogSegmentResponseProto *
       hadoop__hdfs__start_log_segment_response_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__StartLogSegmentResponseProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__start_log_segment_response_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__start_log_segment_response_proto__free_unpacked
                     (Hadoop__Hdfs__StartLogSegmentResponseProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__start_log_segment_response_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__fence_request_proto__init
                     (Hadoop__Hdfs__FenceRequestProto         *message)
{
  static Hadoop__Hdfs__FenceRequestProto init_value = HADOOP__HDFS__FENCE_REQUEST_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__fence_request_proto__get_packed_size
                     (const Hadoop__Hdfs__FenceRequestProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_request_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__fence_request_proto__pack
                     (const Hadoop__Hdfs__FenceRequestProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_request_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__fence_request_proto__pack_to_buffer
                     (const Hadoop__Hdfs__FenceRequestProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_request_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__FenceRequestProto *
       hadoop__hdfs__fence_request_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__FenceRequestProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__fence_request_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__fence_request_proto__free_unpacked
                     (Hadoop__Hdfs__FenceRequestProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_request_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__fence_response_proto__init
                     (Hadoop__Hdfs__FenceResponseProto         *message)
{
  static Hadoop__Hdfs__FenceResponseProto init_value = HADOOP__HDFS__FENCE_RESPONSE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__fence_response_proto__get_packed_size
                     (const Hadoop__Hdfs__FenceResponseProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_response_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__fence_response_proto__pack
                     (const Hadoop__Hdfs__FenceResponseProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_response_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__fence_response_proto__pack_to_buffer
                     (const Hadoop__Hdfs__FenceResponseProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_response_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__FenceResponseProto *
       hadoop__hdfs__fence_response_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__FenceResponseProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__fence_response_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__fence_response_proto__free_unpacked
                     (Hadoop__Hdfs__FenceResponseProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__fence_response_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
static const ProtobufCFieldDescriptor hadoop__hdfs__journal_info_proto__field_descriptors[3] =
{
  {
    "clusterID",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalInfoProto, clusterid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "layoutVersion",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalInfoProto, has_layoutversion),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalInfoProto, layoutversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "namespaceID",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalInfoProto, has_namespaceid),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalInfoProto, namespaceid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__journal_info_proto__field_indices_by_name[] = {
  0,   /* field[0] = clusterID */
  1,   /* field[1] = layoutVersion */
  2,   /* field[2] = namespaceID */
};
static const ProtobufCIntRange hadoop__hdfs__journal_info_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__journal_info_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.JournalInfoProto",
  "JournalInfoProto",
  "Hadoop__Hdfs__JournalInfoProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__JournalInfoProto),
  3,
  hadoop__hdfs__journal_info_proto__field_descriptors,
  hadoop__hdfs__journal_info_proto__field_indices_by_name,
  1,  hadoop__hdfs__journal_info_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__journal_info_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__journal_request_proto__field_descriptors[5] =
{
  {
    "journalInfo",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalRequestProto, journalinfo),
    &hadoop__hdfs__journal_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "firstTxnId",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalRequestProto, firsttxnid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "numTxns",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalRequestProto, numtxns),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "records",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalRequestProto, records),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "epoch",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__JournalRequestProto, epoch),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__journal_request_proto__field_indices_by_name[] = {
  4,   /* field[4] = epoch */
  1,   /* field[1] = firstTxnId */
  0,   /* field[0] = journalInfo */
  2,   /* field[2] = numTxns */
  3,   /* field[3] = records */
};
static const ProtobufCIntRange hadoop__hdfs__journal_request_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__journal_request_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.JournalRequestProto",
  "JournalRequestProto",
  "Hadoop__Hdfs__JournalRequestProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__JournalRequestProto),
  5,
  hadoop__hdfs__journal_request_proto__field_descriptors,
  hadoop__hdfs__journal_request_proto__field_indices_by_name,
  1,  hadoop__hdfs__journal_request_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__journal_request_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
#define hadoop__hdfs__journal_response_proto__field_descriptors NULL
#define hadoop__hdfs__journal_response_proto__field_indices_by_name NULL
#define hadoop__hdfs__journal_response_proto__number_ranges NULL
const ProtobufCMessageDescriptor hadoop__hdfs__journal_response_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.JournalResponseProto",
  "JournalResponseProto",
  "Hadoop__Hdfs__JournalResponseProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__JournalResponseProto),
  0,
  hadoop__hdfs__journal_response_proto__field_descriptors,
  hadoop__hdfs__journal_response_proto__field_indices_by_name,
  0,  hadoop__hdfs__journal_response_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__journal_response_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__start_log_segment_request_proto__field_descriptors[3] =
{
  {
    "journalInfo",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__StartLogSegmentRequestProto, journalinfo),
    &hadoop__hdfs__journal_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "txid",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__StartLogSegmentRequestProto, txid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "epoch",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__StartLogSegmentRequestProto, epoch),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__start_log_segment_request_proto__field_indices_by_name[] = {
  2,   /* field[2] = epoch */
  0,   /* field[0] = journalInfo */
  1,   /* field[1] = txid */
};
static const ProtobufCIntRange hadoop__hdfs__start_log_segment_request_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__start_log_segment_request_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.StartLogSegmentRequestProto",
  "StartLogSegmentRequestProto",
  "Hadoop__Hdfs__StartLogSegmentRequestProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__StartLogSegmentRequestProto),
  3,
  hadoop__hdfs__start_log_segment_request_proto__field_descriptors,
  hadoop__hdfs__start_log_segment_request_proto__field_indices_by_name,
  1,  hadoop__hdfs__start_log_segment_request_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__start_log_segment_request_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
#define hadoop__hdfs__start_log_segment_response_proto__field_descriptors NULL
#define hadoop__hdfs__start_log_segment_response_proto__field_indices_by_name NULL
#define hadoop__hdfs__start_log_segment_response_proto__number_ranges NULL
const ProtobufCMessageDescriptor hadoop__hdfs__start_log_segment_response_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.StartLogSegmentResponseProto",
  "StartLogSegmentResponseProto",
  "Hadoop__Hdfs__StartLogSegmentResponseProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__StartLogSegmentResponseProto),
  0,
  hadoop__hdfs__start_log_segment_response_proto__field_descriptors,
  hadoop__hdfs__start_log_segment_response_proto__field_indices_by_name,
  0,  hadoop__hdfs__start_log_segment_response_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__start_log_segment_response_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__fence_request_proto__field_descriptors[3] =
{
  {
    "journalInfo",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceRequestProto, journalinfo),
    &hadoop__hdfs__journal_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "epoch",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceRequestProto, epoch),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "fencerInfo",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceRequestProto, fencerinfo),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__fence_request_proto__field_indices_by_name[] = {
  1,   /* field[1] = epoch */
  2,   /* field[2] = fencerInfo */
  0,   /* field[0] = journalInfo */
};
static const ProtobufCIntRange hadoop__hdfs__fence_request_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__fence_request_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.FenceRequestProto",
  "FenceRequestProto",
  "Hadoop__Hdfs__FenceRequestProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__FenceRequestProto),
  3,
  hadoop__hdfs__fence_request_proto__field_descriptors,
  hadoop__hdfs__fence_request_proto__field_indices_by_name,
  1,  hadoop__hdfs__fence_request_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__fence_request_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__fence_response_proto__field_descriptors[3] =
{
  {
    "previousEpoch",
    1,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceResponseProto, has_previousepoch),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceResponseProto, previousepoch),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "lastTransactionId",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceResponseProto, has_lasttransactionid),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceResponseProto, lasttransactionid),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "inSync",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceResponseProto, has_insync),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__FenceResponseProto, insync),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__fence_response_proto__field_indices_by_name[] = {
  2,   /* field[2] = inSync */
  1,   /* field[1] = lastTransactionId */
  0,   /* field[0] = previousEpoch */
};
static const ProtobufCIntRange hadoop__hdfs__fence_response_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__fence_response_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.FenceResponseProto",
  "FenceResponseProto",
  "Hadoop__Hdfs__FenceResponseProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__FenceResponseProto),
  3,
  hadoop__hdfs__fence_response_proto__field_descriptors,
  hadoop__hdfs__fence_response_proto__field_indices_by_name,
  1,  hadoop__hdfs__fence_response_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__fence_response_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCMethodDescriptor hadoop__hdfs__journal_protocol_service__method_descriptors[3] =
{
  { "journal", &hadoop__hdfs__journal_request_proto__descriptor, &hadoop__hdfs__journal_response_proto__descriptor },
  { "startLogSegment", &hadoop__hdfs__start_log_segment_request_proto__descriptor, &hadoop__hdfs__start_log_segment_response_proto__descriptor },
  { "fence", &hadoop__hdfs__fence_request_proto__descriptor, &hadoop__hdfs__fence_response_proto__descriptor },
};
const unsigned hadoop__hdfs__journal_protocol_service__method_indices_by_name[] = {
  2,        /* fence */
  0,        /* journal */
  1         /* startLogSegment */
};
const ProtobufCServiceDescriptor hadoop__hdfs__journal_protocol_service__descriptor =
{
  PROTOBUF_C_SERVICE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.JournalProtocolService",
  "startLogSegment",
  "Hadoop__Hdfs__JournalProtocolService",
  "hadoop.hdfs",
  3,
  hadoop__hdfs__journal_protocol_service__method_descriptors,
  hadoop__hdfs__journal_protocol_service__method_indices_by_name
};
void hadoop__hdfs__journal_protocol_service__journal(ProtobufCService *service,
                                                     const Hadoop__Hdfs__JournalRequestProto *input,
                                                     Hadoop__Hdfs__JournalResponseProto_Closure closure,
                                                     void *closure_data)
{
  PROTOBUF_C_ASSERT (service->descriptor == &hadoop__hdfs__journal_protocol_service__descriptor);
  service->invoke(service, 0, (const ProtobufCMessage *) input, (ProtobufCClosure) closure, closure_data);
}
void hadoop__hdfs__journal_protocol_service__start_log_segment(ProtobufCService *service,
                                                               const Hadoop__Hdfs__StartLogSegmentRequestProto *input,
                                                               Hadoop__Hdfs__StartLogSegmentResponseProto_Closure closure,
                                                               void *closure_data)
{
  PROTOBUF_C_ASSERT (service->descriptor == &hadoop__hdfs__journal_protocol_service__descriptor);
  service->invoke(service, 1, (const ProtobufCMessage *) input, (ProtobufCClosure) closure, closure_data);
}
void hadoop__hdfs__journal_protocol_service__fence(ProtobufCService *service,
                                                   const Hadoop__Hdfs__FenceRequestProto *input,
                                                   Hadoop__Hdfs__FenceResponseProto_Closure closure,
                                                   void *closure_data)
{
  PROTOBUF_C_ASSERT (service->descriptor == &hadoop__hdfs__journal_protocol_service__descriptor);
  service->invoke(service, 2, (const ProtobufCMessage *) input, (ProtobufCClosure) closure, closure_data);
}
void hadoop__hdfs__journal_protocol_service__init (Hadoop__Hdfs__JournalProtocolService_Service *service,
                                                   Hadoop__Hdfs__JournalProtocolService_ServiceDestroy destroy)
{
  protobuf_c_service_generated_init (&service->base,
                                     &hadoop__hdfs__journal_protocol_service__descriptor,
                                     (ProtobufCServiceDestroy) destroy);
}
