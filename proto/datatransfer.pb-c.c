/* Generated by the protocol buffer compiler.  DO NOT EDIT! */

/* Do not generate deprecated warnings for self */
#ifndef PROTOBUF_C_NO_DEPRECATED
#define PROTOBUF_C_NO_DEPRECATED
#endif

#include "datatransfer.pb-c.h"
void   hadoop__hdfs__data_transfer_encryptor_message_proto__init
                     (Hadoop__Hdfs__DataTransferEncryptorMessageProto         *message)
{
  static Hadoop__Hdfs__DataTransferEncryptorMessageProto init_value = HADOOP__HDFS__DATA_TRANSFER_ENCRYPTOR_MESSAGE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__data_transfer_encryptor_message_proto__get_packed_size
                     (const Hadoop__Hdfs__DataTransferEncryptorMessageProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_transfer_encryptor_message_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__data_transfer_encryptor_message_proto__pack
                     (const Hadoop__Hdfs__DataTransferEncryptorMessageProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_transfer_encryptor_message_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__data_transfer_encryptor_message_proto__pack_to_buffer
                     (const Hadoop__Hdfs__DataTransferEncryptorMessageProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_transfer_encryptor_message_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__DataTransferEncryptorMessageProto *
       hadoop__hdfs__data_transfer_encryptor_message_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__DataTransferEncryptorMessageProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__data_transfer_encryptor_message_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__data_transfer_encryptor_message_proto__free_unpacked
                     (Hadoop__Hdfs__DataTransferEncryptorMessageProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__data_transfer_encryptor_message_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__base_header_proto__init
                     (Hadoop__Hdfs__BaseHeaderProto         *message)
{
  static Hadoop__Hdfs__BaseHeaderProto init_value = HADOOP__HDFS__BASE_HEADER_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__base_header_proto__get_packed_size
                     (const Hadoop__Hdfs__BaseHeaderProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__base_header_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__base_header_proto__pack
                     (const Hadoop__Hdfs__BaseHeaderProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__base_header_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__base_header_proto__pack_to_buffer
                     (const Hadoop__Hdfs__BaseHeaderProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__base_header_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__BaseHeaderProto *
       hadoop__hdfs__base_header_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__BaseHeaderProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__base_header_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__base_header_proto__free_unpacked
                     (Hadoop__Hdfs__BaseHeaderProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__base_header_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__client_operation_header_proto__init
                     (Hadoop__Hdfs__ClientOperationHeaderProto         *message)
{
  static Hadoop__Hdfs__ClientOperationHeaderProto init_value = HADOOP__HDFS__CLIENT_OPERATION_HEADER_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__client_operation_header_proto__get_packed_size
                     (const Hadoop__Hdfs__ClientOperationHeaderProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_operation_header_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__client_operation_header_proto__pack
                     (const Hadoop__Hdfs__ClientOperationHeaderProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_operation_header_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__client_operation_header_proto__pack_to_buffer
                     (const Hadoop__Hdfs__ClientOperationHeaderProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_operation_header_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__ClientOperationHeaderProto *
       hadoop__hdfs__client_operation_header_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__ClientOperationHeaderProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__client_operation_header_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__client_operation_header_proto__free_unpacked
                     (Hadoop__Hdfs__ClientOperationHeaderProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_operation_header_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_read_block_proto__init
                     (Hadoop__Hdfs__OpReadBlockProto         *message)
{
  static Hadoop__Hdfs__OpReadBlockProto init_value = HADOOP__HDFS__OP_READ_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_read_block_proto__get_packed_size
                     (const Hadoop__Hdfs__OpReadBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_read_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_read_block_proto__pack
                     (const Hadoop__Hdfs__OpReadBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_read_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_read_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpReadBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_read_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpReadBlockProto *
       hadoop__hdfs__op_read_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpReadBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_read_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_read_block_proto__free_unpacked
                     (Hadoop__Hdfs__OpReadBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_read_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__checksum_proto__init
                     (Hadoop__Hdfs__ChecksumProto         *message)
{
  static Hadoop__Hdfs__ChecksumProto init_value = HADOOP__HDFS__CHECKSUM_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__checksum_proto__get_packed_size
                     (const Hadoop__Hdfs__ChecksumProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checksum_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__checksum_proto__pack
                     (const Hadoop__Hdfs__ChecksumProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checksum_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__checksum_proto__pack_to_buffer
                     (const Hadoop__Hdfs__ChecksumProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checksum_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__ChecksumProto *
       hadoop__hdfs__checksum_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__ChecksumProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__checksum_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__checksum_proto__free_unpacked
                     (Hadoop__Hdfs__ChecksumProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__checksum_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_write_block_proto__init
                     (Hadoop__Hdfs__OpWriteBlockProto         *message)
{
  static Hadoop__Hdfs__OpWriteBlockProto init_value = HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_write_block_proto__get_packed_size
                     (const Hadoop__Hdfs__OpWriteBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_write_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_write_block_proto__pack
                     (const Hadoop__Hdfs__OpWriteBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_write_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_write_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpWriteBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_write_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpWriteBlockProto *
       hadoop__hdfs__op_write_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpWriteBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_write_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_write_block_proto__free_unpacked
                     (Hadoop__Hdfs__OpWriteBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_write_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_transfer_block_proto__init
                     (Hadoop__Hdfs__OpTransferBlockProto         *message)
{
  static Hadoop__Hdfs__OpTransferBlockProto init_value = HADOOP__HDFS__OP_TRANSFER_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_transfer_block_proto__get_packed_size
                     (const Hadoop__Hdfs__OpTransferBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_transfer_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_transfer_block_proto__pack
                     (const Hadoop__Hdfs__OpTransferBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_transfer_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_transfer_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpTransferBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_transfer_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpTransferBlockProto *
       hadoop__hdfs__op_transfer_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpTransferBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_transfer_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_transfer_block_proto__free_unpacked
                     (Hadoop__Hdfs__OpTransferBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_transfer_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_replace_block_proto__init
                     (Hadoop__Hdfs__OpReplaceBlockProto         *message)
{
  static Hadoop__Hdfs__OpReplaceBlockProto init_value = HADOOP__HDFS__OP_REPLACE_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_replace_block_proto__get_packed_size
                     (const Hadoop__Hdfs__OpReplaceBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_replace_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_replace_block_proto__pack
                     (const Hadoop__Hdfs__OpReplaceBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_replace_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_replace_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpReplaceBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_replace_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpReplaceBlockProto *
       hadoop__hdfs__op_replace_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpReplaceBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_replace_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_replace_block_proto__free_unpacked
                     (Hadoop__Hdfs__OpReplaceBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_replace_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_copy_block_proto__init
                     (Hadoop__Hdfs__OpCopyBlockProto         *message)
{
  static Hadoop__Hdfs__OpCopyBlockProto init_value = HADOOP__HDFS__OP_COPY_BLOCK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_copy_block_proto__get_packed_size
                     (const Hadoop__Hdfs__OpCopyBlockProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_copy_block_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_copy_block_proto__pack
                     (const Hadoop__Hdfs__OpCopyBlockProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_copy_block_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_copy_block_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpCopyBlockProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_copy_block_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpCopyBlockProto *
       hadoop__hdfs__op_copy_block_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpCopyBlockProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_copy_block_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_copy_block_proto__free_unpacked
                     (Hadoop__Hdfs__OpCopyBlockProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_copy_block_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_block_checksum_proto__init
                     (Hadoop__Hdfs__OpBlockChecksumProto         *message)
{
  static Hadoop__Hdfs__OpBlockChecksumProto init_value = HADOOP__HDFS__OP_BLOCK_CHECKSUM_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_block_checksum_proto__get_packed_size
                     (const Hadoop__Hdfs__OpBlockChecksumProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_block_checksum_proto__pack
                     (const Hadoop__Hdfs__OpBlockChecksumProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_block_checksum_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpBlockChecksumProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpBlockChecksumProto *
       hadoop__hdfs__op_block_checksum_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpBlockChecksumProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_block_checksum_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_block_checksum_proto__free_unpacked
                     (Hadoop__Hdfs__OpBlockChecksumProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_request_short_circuit_access_proto__init
                     (Hadoop__Hdfs__OpRequestShortCircuitAccessProto         *message)
{
  static Hadoop__Hdfs__OpRequestShortCircuitAccessProto init_value = HADOOP__HDFS__OP_REQUEST_SHORT_CIRCUIT_ACCESS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_request_short_circuit_access_proto__get_packed_size
                     (const Hadoop__Hdfs__OpRequestShortCircuitAccessProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_request_short_circuit_access_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_request_short_circuit_access_proto__pack
                     (const Hadoop__Hdfs__OpRequestShortCircuitAccessProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_request_short_circuit_access_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_request_short_circuit_access_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpRequestShortCircuitAccessProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_request_short_circuit_access_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpRequestShortCircuitAccessProto *
       hadoop__hdfs__op_request_short_circuit_access_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpRequestShortCircuitAccessProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_request_short_circuit_access_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_request_short_circuit_access_proto__free_unpacked
                     (Hadoop__Hdfs__OpRequestShortCircuitAccessProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_request_short_circuit_access_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__packet_header_proto__init
                     (Hadoop__Hdfs__PacketHeaderProto         *message)
{
  static Hadoop__Hdfs__PacketHeaderProto init_value = HADOOP__HDFS__PACKET_HEADER_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__packet_header_proto__get_packed_size
                     (const Hadoop__Hdfs__PacketHeaderProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__packet_header_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__packet_header_proto__pack
                     (const Hadoop__Hdfs__PacketHeaderProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__packet_header_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__packet_header_proto__pack_to_buffer
                     (const Hadoop__Hdfs__PacketHeaderProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__packet_header_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__PacketHeaderProto *
       hadoop__hdfs__packet_header_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__PacketHeaderProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__packet_header_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__packet_header_proto__free_unpacked
                     (Hadoop__Hdfs__PacketHeaderProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__packet_header_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__pipeline_ack_proto__init
                     (Hadoop__Hdfs__PipelineAckProto         *message)
{
  static Hadoop__Hdfs__PipelineAckProto init_value = HADOOP__HDFS__PIPELINE_ACK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__pipeline_ack_proto__get_packed_size
                     (const Hadoop__Hdfs__PipelineAckProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__pipeline_ack_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__pipeline_ack_proto__pack
                     (const Hadoop__Hdfs__PipelineAckProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__pipeline_ack_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__pipeline_ack_proto__pack_to_buffer
                     (const Hadoop__Hdfs__PipelineAckProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__pipeline_ack_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__PipelineAckProto *
       hadoop__hdfs__pipeline_ack_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__PipelineAckProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__pipeline_ack_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__pipeline_ack_proto__free_unpacked
                     (Hadoop__Hdfs__PipelineAckProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__pipeline_ack_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__read_op_checksum_info_proto__init
                     (Hadoop__Hdfs__ReadOpChecksumInfoProto         *message)
{
  static Hadoop__Hdfs__ReadOpChecksumInfoProto init_value = HADOOP__HDFS__READ_OP_CHECKSUM_INFO_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__read_op_checksum_info_proto__get_packed_size
                     (const Hadoop__Hdfs__ReadOpChecksumInfoProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__read_op_checksum_info_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__read_op_checksum_info_proto__pack
                     (const Hadoop__Hdfs__ReadOpChecksumInfoProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__read_op_checksum_info_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__read_op_checksum_info_proto__pack_to_buffer
                     (const Hadoop__Hdfs__ReadOpChecksumInfoProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__read_op_checksum_info_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__ReadOpChecksumInfoProto *
       hadoop__hdfs__read_op_checksum_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__ReadOpChecksumInfoProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__read_op_checksum_info_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__read_op_checksum_info_proto__free_unpacked
                     (Hadoop__Hdfs__ReadOpChecksumInfoProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__read_op_checksum_info_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__block_op_response_proto__init
                     (Hadoop__Hdfs__BlockOpResponseProto         *message)
{
  static Hadoop__Hdfs__BlockOpResponseProto init_value = HADOOP__HDFS__BLOCK_OP_RESPONSE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__block_op_response_proto__get_packed_size
                     (const Hadoop__Hdfs__BlockOpResponseProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_op_response_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__block_op_response_proto__pack
                     (const Hadoop__Hdfs__BlockOpResponseProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_op_response_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__block_op_response_proto__pack_to_buffer
                     (const Hadoop__Hdfs__BlockOpResponseProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_op_response_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__BlockOpResponseProto *
       hadoop__hdfs__block_op_response_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__BlockOpResponseProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__block_op_response_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__block_op_response_proto__free_unpacked
                     (Hadoop__Hdfs__BlockOpResponseProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__block_op_response_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__client_read_status_proto__init
                     (Hadoop__Hdfs__ClientReadStatusProto         *message)
{
  static Hadoop__Hdfs__ClientReadStatusProto init_value = HADOOP__HDFS__CLIENT_READ_STATUS_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__client_read_status_proto__get_packed_size
                     (const Hadoop__Hdfs__ClientReadStatusProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_read_status_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__client_read_status_proto__pack
                     (const Hadoop__Hdfs__ClientReadStatusProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_read_status_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__client_read_status_proto__pack_to_buffer
                     (const Hadoop__Hdfs__ClientReadStatusProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_read_status_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__ClientReadStatusProto *
       hadoop__hdfs__client_read_status_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__ClientReadStatusProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__client_read_status_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__client_read_status_proto__free_unpacked
                     (Hadoop__Hdfs__ClientReadStatusProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__client_read_status_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__dntransfer_ack_proto__init
                     (Hadoop__Hdfs__DNTransferAckProto         *message)
{
  static Hadoop__Hdfs__DNTransferAckProto init_value = HADOOP__HDFS__DNTRANSFER_ACK_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__dntransfer_ack_proto__get_packed_size
                     (const Hadoop__Hdfs__DNTransferAckProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__dntransfer_ack_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__dntransfer_ack_proto__pack
                     (const Hadoop__Hdfs__DNTransferAckProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__dntransfer_ack_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__dntransfer_ack_proto__pack_to_buffer
                     (const Hadoop__Hdfs__DNTransferAckProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__dntransfer_ack_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__DNTransferAckProto *
       hadoop__hdfs__dntransfer_ack_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__DNTransferAckProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__dntransfer_ack_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__dntransfer_ack_proto__free_unpacked
                     (Hadoop__Hdfs__DNTransferAckProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__dntransfer_ack_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   hadoop__hdfs__op_block_checksum_response_proto__init
                     (Hadoop__Hdfs__OpBlockChecksumResponseProto         *message)
{
  static Hadoop__Hdfs__OpBlockChecksumResponseProto init_value = HADOOP__HDFS__OP_BLOCK_CHECKSUM_RESPONSE_PROTO__INIT;
  *message = init_value;
}
size_t hadoop__hdfs__op_block_checksum_response_proto__get_packed_size
                     (const Hadoop__Hdfs__OpBlockChecksumResponseProto *message)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_response_proto__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t hadoop__hdfs__op_block_checksum_response_proto__pack
                     (const Hadoop__Hdfs__OpBlockChecksumResponseProto *message,
                      uint8_t       *out)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_response_proto__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t hadoop__hdfs__op_block_checksum_response_proto__pack_to_buffer
                     (const Hadoop__Hdfs__OpBlockChecksumResponseProto *message,
                      ProtobufCBuffer *buffer)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_response_proto__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Hadoop__Hdfs__OpBlockChecksumResponseProto *
       hadoop__hdfs__op_block_checksum_response_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Hadoop__Hdfs__OpBlockChecksumResponseProto *)
     protobuf_c_message_unpack (&hadoop__hdfs__op_block_checksum_response_proto__descriptor,
                                allocator, len, data);
}
void   hadoop__hdfs__op_block_checksum_response_proto__free_unpacked
                     (Hadoop__Hdfs__OpBlockChecksumResponseProto *message,
                      ProtobufCAllocator *allocator)
{
  PROTOBUF_C_ASSERT (message->base.descriptor == &hadoop__hdfs__op_block_checksum_response_proto__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
const ProtobufCEnumValue hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__enum_values_by_number[3] =
{
  { "SUCCESS", "HADOOP__HDFS__DATA_TRANSFER_ENCRYPTOR_MESSAGE_PROTO__DATA_TRANSFER_ENCRYPTOR_STATUS__SUCCESS", 0 },
  { "ERROR_UNKNOWN_KEY", "HADOOP__HDFS__DATA_TRANSFER_ENCRYPTOR_MESSAGE_PROTO__DATA_TRANSFER_ENCRYPTOR_STATUS__ERROR_UNKNOWN_KEY", 1 },
  { "ERROR", "HADOOP__HDFS__DATA_TRANSFER_ENCRYPTOR_MESSAGE_PROTO__DATA_TRANSFER_ENCRYPTOR_STATUS__ERROR", 2 },
};
static const ProtobufCIntRange hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__value_ranges[] = {
{0, 0},{0, 3}
};
const ProtobufCEnumValueIndex hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__enum_values_by_name[3] =
{
  { "ERROR", 2 },
  { "ERROR_UNKNOWN_KEY", 1 },
  { "SUCCESS", 0 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DataTransferEncryptorMessageProto.DataTransferEncryptorStatus",
  "DataTransferEncryptorStatus",
  "Hadoop__Hdfs__DataTransferEncryptorMessageProto__DataTransferEncryptorStatus",
  "hadoop.hdfs",
  3,
  hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__enum_values_by_number,
  3,
  hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__enum_values_by_name,
  1,
  hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__data_transfer_encryptor_message_proto__field_descriptors[3] =
{
  {
    "status",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataTransferEncryptorMessageProto, status),
    &hadoop__hdfs__data_transfer_encryptor_message_proto__data_transfer_encryptor_status__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "payload",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BYTES,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataTransferEncryptorMessageProto, has_payload),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataTransferEncryptorMessageProto, payload),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "message",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DataTransferEncryptorMessageProto, message),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__data_transfer_encryptor_message_proto__field_indices_by_name[] = {
  2,   /* field[2] = message */
  1,   /* field[1] = payload */
  0,   /* field[0] = status */
};
static const ProtobufCIntRange hadoop__hdfs__data_transfer_encryptor_message_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__data_transfer_encryptor_message_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DataTransferEncryptorMessageProto",
  "DataTransferEncryptorMessageProto",
  "Hadoop__Hdfs__DataTransferEncryptorMessageProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__DataTransferEncryptorMessageProto),
  3,
  hadoop__hdfs__data_transfer_encryptor_message_proto__field_descriptors,
  hadoop__hdfs__data_transfer_encryptor_message_proto__field_indices_by_name,
  1,  hadoop__hdfs__data_transfer_encryptor_message_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__data_transfer_encryptor_message_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__base_header_proto__field_descriptors[2] =
{
  {
    "block",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BaseHeaderProto, block),
    &hadoop__hdfs__extended_block_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "token",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BaseHeaderProto, token),
    &hadoop__common__token_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__base_header_proto__field_indices_by_name[] = {
  0,   /* field[0] = block */
  1,   /* field[1] = token */
};
static const ProtobufCIntRange hadoop__hdfs__base_header_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__base_header_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.BaseHeaderProto",
  "BaseHeaderProto",
  "Hadoop__Hdfs__BaseHeaderProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__BaseHeaderProto),
  2,
  hadoop__hdfs__base_header_proto__field_descriptors,
  hadoop__hdfs__base_header_proto__field_indices_by_name,
  1,  hadoop__hdfs__base_header_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__base_header_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__client_operation_header_proto__field_descriptors[2] =
{
  {
    "baseHeader",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ClientOperationHeaderProto, baseheader),
    &hadoop__hdfs__base_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "clientName",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ClientOperationHeaderProto, clientname),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__client_operation_header_proto__field_indices_by_name[] = {
  0,   /* field[0] = baseHeader */
  1,   /* field[1] = clientName */
};
static const ProtobufCIntRange hadoop__hdfs__client_operation_header_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__client_operation_header_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ClientOperationHeaderProto",
  "ClientOperationHeaderProto",
  "Hadoop__Hdfs__ClientOperationHeaderProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__ClientOperationHeaderProto),
  2,
  hadoop__hdfs__client_operation_header_proto__field_descriptors,
  hadoop__hdfs__client_operation_header_proto__field_indices_by_name,
  1,  hadoop__hdfs__client_operation_header_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__client_operation_header_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const protobuf_c_boolean hadoop__hdfs__op_read_block_proto__send_checksums__default_value = 1;
static const ProtobufCFieldDescriptor hadoop__hdfs__op_read_block_proto__field_descriptors[4] =
{
  {
    "header",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReadBlockProto, header),
    &hadoop__hdfs__client_operation_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "offset",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReadBlockProto, offset),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "len",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReadBlockProto, len),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "sendChecksums",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReadBlockProto, has_sendchecksums),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReadBlockProto, sendchecksums),
    NULL,
    &hadoop__hdfs__op_read_block_proto__send_checksums__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_read_block_proto__field_indices_by_name[] = {
  0,   /* field[0] = header */
  2,   /* field[2] = len */
  1,   /* field[1] = offset */
  3,   /* field[3] = sendChecksums */
};
static const ProtobufCIntRange hadoop__hdfs__op_read_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_read_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpReadBlockProto",
  "OpReadBlockProto",
  "Hadoop__Hdfs__OpReadBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpReadBlockProto),
  4,
  hadoop__hdfs__op_read_block_proto__field_descriptors,
  hadoop__hdfs__op_read_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_read_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_read_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__checksum_proto__field_descriptors[2] =
{
  {
    "type",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ChecksumProto, type),
    &hadoop__hdfs__checksum_type_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "bytesPerChecksum",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ChecksumProto, bytesperchecksum),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__checksum_proto__field_indices_by_name[] = {
  1,   /* field[1] = bytesPerChecksum */
  0,   /* field[0] = type */
};
static const ProtobufCIntRange hadoop__hdfs__checksum_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__checksum_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ChecksumProto",
  "ChecksumProto",
  "Hadoop__Hdfs__ChecksumProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__ChecksumProto),
  2,
  hadoop__hdfs__checksum_proto__field_descriptors,
  hadoop__hdfs__checksum_proto__field_indices_by_name,
  1,  hadoop__hdfs__checksum_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__checksum_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__hdfs__op_write_block_proto__block_construction_stage__enum_values_by_number[9] =
{
  { "PIPELINE_SETUP_APPEND", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__PIPELINE_SETUP_APPEND", 0 },
  { "PIPELINE_SETUP_APPEND_RECOVERY", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__PIPELINE_SETUP_APPEND_RECOVERY", 1 },
  { "DATA_STREAMING", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__DATA_STREAMING", 2 },
  { "PIPELINE_SETUP_STREAMING_RECOVERY", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__PIPELINE_SETUP_STREAMING_RECOVERY", 3 },
  { "PIPELINE_CLOSE", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__PIPELINE_CLOSE", 4 },
  { "PIPELINE_CLOSE_RECOVERY", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__PIPELINE_CLOSE_RECOVERY", 5 },
  { "PIPELINE_SETUP_CREATE", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__PIPELINE_SETUP_CREATE", 6 },
  { "TRANSFER_RBW", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__TRANSFER_RBW", 7 },
  { "TRANSFER_FINALIZED", "HADOOP__HDFS__OP_WRITE_BLOCK_PROTO__BLOCK_CONSTRUCTION_STAGE__TRANSFER_FINALIZED", 8 },
};
static const ProtobufCIntRange hadoop__hdfs__op_write_block_proto__block_construction_stage__value_ranges[] = {
{0, 0},{0, 9}
};
const ProtobufCEnumValueIndex hadoop__hdfs__op_write_block_proto__block_construction_stage__enum_values_by_name[9] =
{
  { "DATA_STREAMING", 2 },
  { "PIPELINE_CLOSE", 4 },
  { "PIPELINE_CLOSE_RECOVERY", 5 },
  { "PIPELINE_SETUP_APPEND", 0 },
  { "PIPELINE_SETUP_APPEND_RECOVERY", 1 },
  { "PIPELINE_SETUP_CREATE", 6 },
  { "PIPELINE_SETUP_STREAMING_RECOVERY", 3 },
  { "TRANSFER_FINALIZED", 8 },
  { "TRANSFER_RBW", 7 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__op_write_block_proto__block_construction_stage__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpWriteBlockProto.BlockConstructionStage",
  "BlockConstructionStage",
  "Hadoop__Hdfs__OpWriteBlockProto__BlockConstructionStage",
  "hadoop.hdfs",
  9,
  hadoop__hdfs__op_write_block_proto__block_construction_stage__enum_values_by_number,
  9,
  hadoop__hdfs__op_write_block_proto__block_construction_stage__enum_values_by_name,
  1,
  hadoop__hdfs__op_write_block_proto__block_construction_stage__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__op_write_block_proto__field_descriptors[9] =
{
  {
    "header",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, header),
    &hadoop__hdfs__client_operation_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "targets",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, n_targets),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, targets),
    &hadoop__hdfs__datanode_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "source",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, source),
    &hadoop__hdfs__datanode_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "stage",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, stage),
    &hadoop__hdfs__op_write_block_proto__block_construction_stage__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "pipelineSize",
    5,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, pipelinesize),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "minBytesRcvd",
    6,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, minbytesrcvd),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "maxBytesRcvd",
    7,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, maxbytesrcvd),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "latestGenerationStamp",
    8,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, latestgenerationstamp),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "requestedChecksum",
    9,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpWriteBlockProto, requestedchecksum),
    &hadoop__hdfs__checksum_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_write_block_proto__field_indices_by_name[] = {
  0,   /* field[0] = header */
  7,   /* field[7] = latestGenerationStamp */
  6,   /* field[6] = maxBytesRcvd */
  5,   /* field[5] = minBytesRcvd */
  4,   /* field[4] = pipelineSize */
  8,   /* field[8] = requestedChecksum */
  2,   /* field[2] = source */
  3,   /* field[3] = stage */
  1,   /* field[1] = targets */
};
static const ProtobufCIntRange hadoop__hdfs__op_write_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 9 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_write_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpWriteBlockProto",
  "OpWriteBlockProto",
  "Hadoop__Hdfs__OpWriteBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpWriteBlockProto),
  9,
  hadoop__hdfs__op_write_block_proto__field_descriptors,
  hadoop__hdfs__op_write_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_write_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_write_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__op_transfer_block_proto__field_descriptors[2] =
{
  {
    "header",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpTransferBlockProto, header),
    &hadoop__hdfs__client_operation_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "targets",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpTransferBlockProto, n_targets),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpTransferBlockProto, targets),
    &hadoop__hdfs__datanode_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_transfer_block_proto__field_indices_by_name[] = {
  0,   /* field[0] = header */
  1,   /* field[1] = targets */
};
static const ProtobufCIntRange hadoop__hdfs__op_transfer_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_transfer_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpTransferBlockProto",
  "OpTransferBlockProto",
  "Hadoop__Hdfs__OpTransferBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpTransferBlockProto),
  2,
  hadoop__hdfs__op_transfer_block_proto__field_descriptors,
  hadoop__hdfs__op_transfer_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_transfer_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_transfer_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__op_replace_block_proto__field_descriptors[3] =
{
  {
    "header",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReplaceBlockProto, header),
    &hadoop__hdfs__base_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "delHint",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReplaceBlockProto, delhint),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "source",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpReplaceBlockProto, source),
    &hadoop__hdfs__datanode_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_replace_block_proto__field_indices_by_name[] = {
  1,   /* field[1] = delHint */
  0,   /* field[0] = header */
  2,   /* field[2] = source */
};
static const ProtobufCIntRange hadoop__hdfs__op_replace_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_replace_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpReplaceBlockProto",
  "OpReplaceBlockProto",
  "Hadoop__Hdfs__OpReplaceBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpReplaceBlockProto),
  3,
  hadoop__hdfs__op_replace_block_proto__field_descriptors,
  hadoop__hdfs__op_replace_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_replace_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_replace_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__op_copy_block_proto__field_descriptors[1] =
{
  {
    "header",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpCopyBlockProto, header),
    &hadoop__hdfs__base_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_copy_block_proto__field_indices_by_name[] = {
  0,   /* field[0] = header */
};
static const ProtobufCIntRange hadoop__hdfs__op_copy_block_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_copy_block_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpCopyBlockProto",
  "OpCopyBlockProto",
  "Hadoop__Hdfs__OpCopyBlockProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpCopyBlockProto),
  1,
  hadoop__hdfs__op_copy_block_proto__field_descriptors,
  hadoop__hdfs__op_copy_block_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_copy_block_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_copy_block_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__op_block_checksum_proto__field_descriptors[1] =
{
  {
    "header",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpBlockChecksumProto, header),
    &hadoop__hdfs__base_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_block_checksum_proto__field_indices_by_name[] = {
  0,   /* field[0] = header */
};
static const ProtobufCIntRange hadoop__hdfs__op_block_checksum_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_block_checksum_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpBlockChecksumProto",
  "OpBlockChecksumProto",
  "Hadoop__Hdfs__OpBlockChecksumProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpBlockChecksumProto),
  1,
  hadoop__hdfs__op_block_checksum_proto__field_descriptors,
  hadoop__hdfs__op_block_checksum_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_block_checksum_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_block_checksum_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__op_request_short_circuit_access_proto__field_descriptors[2] =
{
  {
    "header",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpRequestShortCircuitAccessProto, header),
    &hadoop__hdfs__base_header_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "maxVersion",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpRequestShortCircuitAccessProto, maxversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_request_short_circuit_access_proto__field_indices_by_name[] = {
  0,   /* field[0] = header */
  1,   /* field[1] = maxVersion */
};
static const ProtobufCIntRange hadoop__hdfs__op_request_short_circuit_access_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_request_short_circuit_access_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpRequestShortCircuitAccessProto",
  "OpRequestShortCircuitAccessProto",
  "Hadoop__Hdfs__OpRequestShortCircuitAccessProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpRequestShortCircuitAccessProto),
  2,
  hadoop__hdfs__op_request_short_circuit_access_proto__field_descriptors,
  hadoop__hdfs__op_request_short_circuit_access_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_request_short_circuit_access_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_request_short_circuit_access_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const protobuf_c_boolean hadoop__hdfs__packet_header_proto__sync_block__default_value = 0;
static const ProtobufCFieldDescriptor hadoop__hdfs__packet_header_proto__field_descriptors[5] =
{
  {
    "offsetInBlock",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_SFIXED64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PacketHeaderProto, offsetinblock),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "seqno",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_SFIXED64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PacketHeaderProto, seqno),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "lastPacketInBlock",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BOOL,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PacketHeaderProto, lastpacketinblock),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "dataLen",
    4,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_SFIXED32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PacketHeaderProto, datalen),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "syncBlock",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_BOOL,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PacketHeaderProto, has_syncblock),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PacketHeaderProto, syncblock),
    NULL,
    &hadoop__hdfs__packet_header_proto__sync_block__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__packet_header_proto__field_indices_by_name[] = {
  3,   /* field[3] = dataLen */
  2,   /* field[2] = lastPacketInBlock */
  0,   /* field[0] = offsetInBlock */
  1,   /* field[1] = seqno */
  4,   /* field[4] = syncBlock */
};
static const ProtobufCIntRange hadoop__hdfs__packet_header_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 5 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__packet_header_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.PacketHeaderProto",
  "PacketHeaderProto",
  "Hadoop__Hdfs__PacketHeaderProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__PacketHeaderProto),
  5,
  hadoop__hdfs__packet_header_proto__field_descriptors,
  hadoop__hdfs__packet_header_proto__field_indices_by_name,
  1,  hadoop__hdfs__packet_header_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__packet_header_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const uint64_t hadoop__hdfs__pipeline_ack_proto__downstream_ack_time_nanos__default_value = 0;
static const ProtobufCFieldDescriptor hadoop__hdfs__pipeline_ack_proto__field_descriptors[3] =
{
  {
    "seqno",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_SINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PipelineAckProto, seqno),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "status",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PipelineAckProto, n_status),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PipelineAckProto, status),
    &hadoop__hdfs__status__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "downstreamAckTimeNanos",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT64,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PipelineAckProto, has_downstreamacktimenanos),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__PipelineAckProto, downstreamacktimenanos),
    NULL,
    &hadoop__hdfs__pipeline_ack_proto__downstream_ack_time_nanos__default_value,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__pipeline_ack_proto__field_indices_by_name[] = {
  2,   /* field[2] = downstreamAckTimeNanos */
  0,   /* field[0] = seqno */
  1,   /* field[1] = status */
};
static const ProtobufCIntRange hadoop__hdfs__pipeline_ack_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__pipeline_ack_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.PipelineAckProto",
  "PipelineAckProto",
  "Hadoop__Hdfs__PipelineAckProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__PipelineAckProto),
  3,
  hadoop__hdfs__pipeline_ack_proto__field_descriptors,
  hadoop__hdfs__pipeline_ack_proto__field_indices_by_name,
  1,  hadoop__hdfs__pipeline_ack_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__pipeline_ack_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__read_op_checksum_info_proto__field_descriptors[2] =
{
  {
    "checksum",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ReadOpChecksumInfoProto, checksum),
    &hadoop__hdfs__checksum_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "chunkOffset",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ReadOpChecksumInfoProto, chunkoffset),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__read_op_checksum_info_proto__field_indices_by_name[] = {
  0,   /* field[0] = checksum */
  1,   /* field[1] = chunkOffset */
};
static const ProtobufCIntRange hadoop__hdfs__read_op_checksum_info_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__read_op_checksum_info_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ReadOpChecksumInfoProto",
  "ReadOpChecksumInfoProto",
  "Hadoop__Hdfs__ReadOpChecksumInfoProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__ReadOpChecksumInfoProto),
  2,
  hadoop__hdfs__read_op_checksum_info_proto__field_descriptors,
  hadoop__hdfs__read_op_checksum_info_proto__field_indices_by_name,
  1,  hadoop__hdfs__read_op_checksum_info_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__read_op_checksum_info_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__block_op_response_proto__field_descriptors[6] =
{
  {
    "status",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockOpResponseProto, status),
    &hadoop__hdfs__status__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "firstBadLink",
    2,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockOpResponseProto, firstbadlink),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "checksumResponse",
    3,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockOpResponseProto, checksumresponse),
    &hadoop__hdfs__op_block_checksum_response_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "readOpChecksumInfo",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockOpResponseProto, readopchecksuminfo),
    &hadoop__hdfs__read_op_checksum_info_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "message",
    5,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockOpResponseProto, message),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "shortCircuitAccessVersion",
    6,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_UINT32,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockOpResponseProto, has_shortcircuitaccessversion),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__BlockOpResponseProto, shortcircuitaccessversion),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__block_op_response_proto__field_indices_by_name[] = {
  2,   /* field[2] = checksumResponse */
  1,   /* field[1] = firstBadLink */
  4,   /* field[4] = message */
  3,   /* field[3] = readOpChecksumInfo */
  5,   /* field[5] = shortCircuitAccessVersion */
  0,   /* field[0] = status */
};
static const ProtobufCIntRange hadoop__hdfs__block_op_response_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__block_op_response_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.BlockOpResponseProto",
  "BlockOpResponseProto",
  "Hadoop__Hdfs__BlockOpResponseProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__BlockOpResponseProto),
  6,
  hadoop__hdfs__block_op_response_proto__field_descriptors,
  hadoop__hdfs__block_op_response_proto__field_indices_by_name,
  1,  hadoop__hdfs__block_op_response_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__block_op_response_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__client_read_status_proto__field_descriptors[1] =
{
  {
    "status",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__ClientReadStatusProto, status),
    &hadoop__hdfs__status__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__client_read_status_proto__field_indices_by_name[] = {
  0,   /* field[0] = status */
};
static const ProtobufCIntRange hadoop__hdfs__client_read_status_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__client_read_status_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.ClientReadStatusProto",
  "ClientReadStatusProto",
  "Hadoop__Hdfs__ClientReadStatusProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__ClientReadStatusProto),
  1,
  hadoop__hdfs__client_read_status_proto__field_descriptors,
  hadoop__hdfs__client_read_status_proto__field_indices_by_name,
  1,  hadoop__hdfs__client_read_status_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__client_read_status_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__dntransfer_ack_proto__field_descriptors[1] =
{
  {
    "status",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__DNTransferAckProto, status),
    &hadoop__hdfs__status__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__dntransfer_ack_proto__field_indices_by_name[] = {
  0,   /* field[0] = status */
};
static const ProtobufCIntRange hadoop__hdfs__dntransfer_ack_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__dntransfer_ack_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.DNTransferAckProto",
  "DNTransferAckProto",
  "Hadoop__Hdfs__DNTransferAckProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__DNTransferAckProto),
  1,
  hadoop__hdfs__dntransfer_ack_proto__field_descriptors,
  hadoop__hdfs__dntransfer_ack_proto__field_indices_by_name,
  1,  hadoop__hdfs__dntransfer_ack_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__dntransfer_ack_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor hadoop__hdfs__op_block_checksum_response_proto__field_descriptors[4] =
{
  {
    "bytesPerCrc",
    1,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT32,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpBlockChecksumResponseProto, bytespercrc),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "crcPerBlock",
    2,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_UINT64,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpBlockChecksumResponseProto, crcperblock),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "md5",
    3,
    PROTOBUF_C_LABEL_REQUIRED,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpBlockChecksumResponseProto, md5),
    NULL,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "crcType",
    4,
    PROTOBUF_C_LABEL_OPTIONAL,
    PROTOBUF_C_TYPE_ENUM,
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpBlockChecksumResponseProto, has_crctype),
    PROTOBUF_C_OFFSETOF(Hadoop__Hdfs__OpBlockChecksumResponseProto, crctype),
    &hadoop__hdfs__checksum_type_proto__descriptor,
    NULL,
    0,            /* packed */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned hadoop__hdfs__op_block_checksum_response_proto__field_indices_by_name[] = {
  0,   /* field[0] = bytesPerCrc */
  1,   /* field[1] = crcPerBlock */
  3,   /* field[3] = crcType */
  2,   /* field[2] = md5 */
};
static const ProtobufCIntRange hadoop__hdfs__op_block_checksum_response_proto__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 4 }
};
const ProtobufCMessageDescriptor hadoop__hdfs__op_block_checksum_response_proto__descriptor =
{
  PROTOBUF_C_MESSAGE_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.OpBlockChecksumResponseProto",
  "OpBlockChecksumResponseProto",
  "Hadoop__Hdfs__OpBlockChecksumResponseProto",
  "hadoop.hdfs",
  sizeof(Hadoop__Hdfs__OpBlockChecksumResponseProto),
  4,
  hadoop__hdfs__op_block_checksum_response_proto__field_descriptors,
  hadoop__hdfs__op_block_checksum_response_proto__field_indices_by_name,
  1,  hadoop__hdfs__op_block_checksum_response_proto__number_ranges,
  (ProtobufCMessageInit) hadoop__hdfs__op_block_checksum_response_proto__init,
  NULL,NULL,NULL    /* reserved[123] */
};
const ProtobufCEnumValue hadoop__hdfs__status__enum_values_by_number[8] =
{
  { "SUCCESS", "HADOOP__HDFS__STATUS__SUCCESS", 0 },
  { "ERROR", "HADOOP__HDFS__STATUS__ERROR", 1 },
  { "ERROR_CHECKSUM", "HADOOP__HDFS__STATUS__ERROR_CHECKSUM", 2 },
  { "ERROR_INVALID", "HADOOP__HDFS__STATUS__ERROR_INVALID", 3 },
  { "ERROR_EXISTS", "HADOOP__HDFS__STATUS__ERROR_EXISTS", 4 },
  { "ERROR_ACCESS_TOKEN", "HADOOP__HDFS__STATUS__ERROR_ACCESS_TOKEN", 5 },
  { "CHECKSUM_OK", "HADOOP__HDFS__STATUS__CHECKSUM_OK", 6 },
  { "ERROR_UNSUPPORTED", "HADOOP__HDFS__STATUS__ERROR_UNSUPPORTED", 7 },
};
static const ProtobufCIntRange hadoop__hdfs__status__value_ranges[] = {
{0, 0},{0, 8}
};
const ProtobufCEnumValueIndex hadoop__hdfs__status__enum_values_by_name[8] =
{
  { "CHECKSUM_OK", 6 },
  { "ERROR", 1 },
  { "ERROR_ACCESS_TOKEN", 5 },
  { "ERROR_CHECKSUM", 2 },
  { "ERROR_EXISTS", 4 },
  { "ERROR_INVALID", 3 },
  { "ERROR_UNSUPPORTED", 7 },
  { "SUCCESS", 0 },
};
const ProtobufCEnumDescriptor hadoop__hdfs__status__descriptor =
{
  PROTOBUF_C_ENUM_DESCRIPTOR_MAGIC,
  "hadoop.hdfs.Status",
  "Status",
  "Hadoop__Hdfs__Status",
  "hadoop.hdfs",
  8,
  hadoop__hdfs__status__enum_values_by_number,
  8,
  hadoop__hdfs__status__enum_values_by_name,
  1,
  hadoop__hdfs__status__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
